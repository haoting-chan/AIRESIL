{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ff231391",
   "metadata": {},
   "source": [
    "# Extraction of studies via Databases & Registers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3f488c12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c:\\Python313\\python.exe\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "print(sys.executable)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a4bc2ed",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'Python 3.13.5' requires the ipykernel package.\n",
      "\u001b[1;31mInstall 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: '\"c:/Users/chanho/Documents/A - Work Projects/AIRESIL/.venv/Scripts/python.exe\" -m pip install ipykernel -U --user --force-reinstall'"
     ]
    }
   ],
   "source": [
    "# Standard Packages \n",
    "import pandas as pd\n",
    "import unicodedata\n",
    "import time\n",
    "import re\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from datetime import datetime\n",
    "from typing import Dict, List, Optional, Iterable, Tuple\n",
    "import unicodedata\n",
    "\n",
    "# API Call Packages\n",
    "import urllib\n",
    "import requests\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98675b6f",
   "metadata": {},
   "source": [
    "## Load API Keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5b1149dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Web of Science API Key: 7c0...\n",
      "Semantic Scholar API Key: eU3...\n"
     ]
    }
   ],
   "source": [
    "load_dotenv()\n",
    "\n",
    "# load api keys from .env\n",
    "api_key_WoS = os.getenv('WEB_OF_SCIENCE_API_KEY')\n",
    "api_key_SS = os.getenv('SEMANTIC_SCHOLAR_API_KEY')\n",
    "\n",
    "# Check if API keys are loaded\n",
    "print(f\"Web of Science API Key: {api_key_WoS[:3]}...\")  # Print first 4 characters\n",
    "print(f\"Semantic Scholar API Key: {api_key_SS[:3]}...\")  # Print first 4 characters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f925dea7",
   "metadata": {},
   "source": [
    "## Web of Science API Call"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75f41b36",
   "metadata": {},
   "source": [
    "**Search and field tags for Web of Science documents**\n",
    "- `sort_field`: Order by field(s). \n",
    "    - Field name and order by clause separated by '+', use A for ASC and D for DESC, \n",
    "    - Example: `PY+D`. Multiple values are separated by comma. \n",
    "    - Supported fields:  * **LD** - Load Date * **PY** - Publication Year * **RS** - Relevance * **TC** - Times Cited  (optional)\n",
    "- `...time_span`: Beginning and end dates must be specified in the yyyy-mm-dd format separated by '+' or ' ', e.g. 2023-01-01+2023-12-31. This parameter is not compatible with the all databases search, i.e. db=WOK is not compatible with this parameter. (optional)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "04aeb5c2",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# Import WoS API client\n",
    "import clarivate.wos_starter.client\n",
    "from clarivate.wos_starter.client.rest import ApiException\n",
    "from pprint import pprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "522fb5e6",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# Set up Web of Science API client\n",
    "BASE_WoS = \"https://api.clarivate.com/apis/wos-starter/v1\"\n",
    "configuration = clarivate.wos_starter.client.Configuration(host = BASE_WoS)\n",
    "configuration.api_key['ClarivateApiKeyAuth'] = api_key_WoS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c0651d1",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# Define Functions\n",
    "# -------------- Function to run API query --------------\n",
    "def run_wos_api(\n",
    "        q,                          # Search query in WOS search syntax\n",
    "        db='WOS',                       # Choice of Database\n",
    "        limit=50,                       # Set limit of records on page (1-50) (default to 10)\n",
    "        page=1,                         # Set the result page \n",
    "        sort_field='RS+D',              # Order by Field(s), option: LD, PY, RS, TC\n",
    "        modified_time_span=None,        # Date range in which results were most recently modified.\n",
    "        tc_modified_time_span=None,     # Date range in which times cited counts were modified.\n",
    "        detail=None,                    # Set to returns full data by default, alternative: detail=short\n",
    "        configuration=configuration ):\n",
    "\n",
    "    with clarivate.wos_starter.client.ApiClient(configuration) as api_client:\n",
    "        api_instance = clarivate.wos_starter.client.DocumentsApi(api_client)\n",
    "        try:\n",
    "            api_response = api_instance.documents_get(\n",
    "                q,\n",
    "                db=db,\n",
    "                limit=limit,\n",
    "                page=page,\n",
    "                sort_field=sort_field,\n",
    "                modified_time_span=modified_time_span,\n",
    "                tc_modified_time_span=tc_modified_time_span,\n",
    "                detail=detail\n",
    "            )\n",
    "            return api_response\n",
    "        \n",
    "        except ApiException as e:\n",
    "            print(f\"Exception when calling DocumentsApi->documents_get: {e}\")\n",
    "            return None\n",
    "        \n",
    "# -------------- Function to Fetch --------------\n",
    "# Funciton: Fetch X number of pages\n",
    "def wos_fetch_pages(q: str, limit: int = 50) -> pd.DataFrame:\n",
    "    all_hits = []\n",
    "\n",
    "    for p in range(1, 11):  # pages 1-10\n",
    "        resp = run_wos_api(q, page=p, limit=limit)\n",
    "        if resp is None:\n",
    "            print(f\"[WARN] No response for page {p}\")\n",
    "            continue\n",
    "        hits = getattr(resp, \"hits\", []) or []\n",
    "        all_hits.extend(h.to_dict() for h in hits)\n",
    "\n",
    "    if not all_hits:\n",
    "        return pd.DataFrame()\n",
    "\n",
    "    df = pd.DataFrame(all_hits)\n",
    "    if \"uid\" in df.columns:\n",
    "        df = df.drop_duplicates(subset=[\"uid\"]).reset_index(drop=True)\n",
    "    return df\n",
    "\n",
    "# Funciton: Fetch ALL pages\n",
    "def wos_fetch_all_pages(q: str, limit: int = 50) -> pd.DataFrame:\n",
    "    # Step 1: Fetch the first page to get the total number of records\n",
    "    resp = run_wos_api(q, page=1, limit=limit)\n",
    "    if resp is None:\n",
    "        print(f\"[WARN] No response for the first page of query: {q}\")\n",
    "        return pd.DataFrame()\n",
    "\n",
    "    total_records = getattr(resp.metadata, \"total\", 0)  # Get the total number of records\n",
    "    if total_records == 0:\n",
    "        print(f\"[WARN] No records found for query: {q}\")\n",
    "        return pd.DataFrame()\n",
    "\n",
    "    # Step 2: Calculate the number of pages required\n",
    "    total_pages = (total_records + limit - 1) // limit  # equivalent to math.ceil(total_records / limit)\n",
    "\n",
    "    # Step 3: Loop through all pages and collect the records\n",
    "    all_hits = []\n",
    "    for page in range(1, total_pages + 1):\n",
    "        resp = run_wos_api(q, page=page, limit=limit)\n",
    "        if resp is None:\n",
    "            print(f\"[WARN] No response for page {page} of query: {q}\")\n",
    "            continue\n",
    "\n",
    "        hits = getattr(resp, \"hits\", []) or []\n",
    "        all_hits.extend(h.to_dict() for h in hits)\n",
    "\n",
    "    if not all_hits:\n",
    "        return pd.DataFrame()\n",
    "\n",
    "    # Step 4: Convert the results to a DataFrame\n",
    "    df = pd.DataFrame(all_hits)\n",
    "    \n",
    "    # Deduplicate based on 'uid' (unique identifier)\n",
    "    if \"uid\" in df.columns:\n",
    "        df = df.drop_duplicates(subset=[\"uid\"]).reset_index(drop=True)\n",
    "\n",
    "    return df\n",
    "\n",
    "# Function: Get total record counts for each query\n",
    "def wos_query_totals(wos_queries: dict) -> pd.DataFrame:\n",
    "    results = []\n",
    "    for name, q in wos_queries.items():\n",
    "        resp = run_wos_api(q, page=1, limit=1)\n",
    "        print(f\"Processing query: {name}\")\n",
    "        \n",
    "        if resp is None:\n",
    "            results.append({\"QueryName\": name, \"TotalRecords\": None})\n",
    "            continue\n",
    "\n",
    "        total = getattr(resp.metadata, \"total\", None)\n",
    "        results.append({\"QueryName\": name, \"TotalRecords\": total})\n",
    "\n",
    "    return pd.DataFrame(results).sort_values(\"TotalRecords\", ascending=False).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4bc332c8",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# Define search terms\n",
    "\n",
    "# 1. LLM Block\n",
    "LLM_Block = 'TS=(\"large language model*\" OR \"Large Language Models\" OR \"foundation model*\" OR LLM OR LLMs OR GPT OR LLaMA* OR Mistral OR Mixtral OR Claude* OR Gemini OR PaLM OR Qwen OR DeepSeek OR \"Falcon 180B\" OR \"Phi-3\")'\n",
    "\n",
    "# 2. Survey Block\n",
    "Survey_Block = 'TS=(survey* OR \"survey data\" OR \"survey response*\" OR questionnaire* OR question* OR \"opinion poll*\" OR \"public opinion*\" OR attitude* OR value* OR norm* OR moral* OR \"feeling thermometer*\" OR \"open-ended\" OR \"open ended\" OR nonresponse OR \"non-response\" OR respondent* OR participant* OR interview* OR \"self-report*\" OR \"data collection\")'\n",
    "\n",
    "# 3. Simulation Block (merged A+B)\n",
    "Simulation_BlockA = 'TS=((simulat* OR emulat* OR predict* OR imput* OR \"missing data\" OR nonresponse OR \"non-response\" OR \"item nonresponse\" OR \"unit nonresponse\" OR \"synthetic respondent*\" OR \"synthetic participant*\" OR \"artificial respondent*\" OR \"artificial participant*\" OR \"virtual respondent*\" OR \"virtual participant*\" OR persona* OR \"role play*\") NEAR/5 (survey* OR questionnaire* OR respondent* OR response* OR interview* OR \"self-report*\" OR \"data collection\" OR opinion* OR poll*))'\n",
    "\n",
    "# 3. 2nd version of  Simulation Block (more comprehensive)\n",
    "Simulation_BlockB = 'TS=( ( simulat* OR emulat* OR predict* OR imput* OR \"synthetic data\" OR \"missing data\" OR nonresponse OR \"non-response\" OR \"item nonresponse\" OR \"synthetic respondent*\" OR \"synthetic participant*\" OR \"artificial respondent*\" OR \"artificial participant*\" OR \"virtual respondent*\" OR \"virtual participant*\" OR persona* OR \"role play*\" OR \"as a respondent\" OR \"LLM as respondent\" OR \"model as respondent\" OR proxy OR surrogate OR \"stand-in\" OR \"stand in\" OR replac* OR substitut* OR represent* OR fidelit* OR faithful* OR doppelg* OR (\"Synthetic Voice*\" NEAR/5 (persona* OR respondent* OR survey* OR \"public opinion*\" OR opinion*)) OR (\"representing people\" NEAR/3 (survey* OR respondent* OR persona* OR opinion*)) OR (\"LLM-generated persona*\" OR \"LLM generated persona*\") ) NEAR/5 (survey* OR questionnaire* OR respondent* OR response* OR interview* OR \"self-report*\" OR \"data collection\" OR opinion* OR poll* OR attitude* OR value* OR norm* OR \"public opinion*\") )'\n",
    "\n",
    "# 3. 3rd version of  Simulation Block (fixed phrases)\n",
    "Simulation_BlockC = 'TS=(\"survey simulation\" OR \"simulated participant*\" OR \"simulated respondent*\" OR \"synthetic data\" OR \"synthetic survey data\" OR \"synthetic respondent*\" OR \"synthetic participant*\" OR \"artificial respondent*\" OR \"artificial participant*\" OR \"virtual respondent*\" OR \"virtual participant*\" OR \"LLM as respondent\" OR \"model as respondent\" OR \"as a respondent\" OR \"role play*\" OR persona*)'\n",
    "\n",
    "# 4. Model Training Block (optional)\n",
    "Methods_Block = 'TS=( prompt* OR \"few-shot\" OR \"few-shot learning\" OR \"zero-shot\" OR \"zero-shot learning\" OR \"in-context learning\" OR ICL OR \"chain of thought\" OR \"self-consistency\" OR \"system message\" OR persona OR personas OR \"role prompt*\" OR \"instruction-tun*\" OR \"instruction prompt*\" OR \"fine-tun*\" OR (\"reinforcement learning with human feedback\" OR RLHF) OR (\"reinforcement learning with AI feedback\" OR RLAIF) OR \"temperature parameter\" OR \"temperature setting\" OR \"nucleus sampling\" OR \"top-p sampling\" OR \"active learning\" OR \"transfer learning\" OR \"meta learning\" OR \"meta-learning\" OR \"representation learning\" OR \"continual learning\" OR \"lifelong learning\" )'\n",
    "\n",
    "# Create combinations of search blocks with Exclusion Block\n",
    "LLM_and_Survey = f'{LLM_Block} AND {Survey_Block}'\n",
    "LLM_and_Survey_and_Methods = f'{LLM_Block} AND {Survey_Block} AND {Methods_Block}'\n",
    "LLM_and_SimulationA = f'{LLM_Block} AND {Simulation_BlockA}'\n",
    "LLM_and_SimulationB = f'{LLM_Block} AND {Simulation_BlockB}'\n",
    "LLM_and_SimulationC = f'{LLM_Block} AND {Simulation_BlockC}'\n",
    "LLM_and_Methods = f'{LLM_Block} AND {Methods_Block}'\n",
    "LLM_and_Survey_and_SimulationA = f'{LLM_Block} AND {Survey_Block} AND {Simulation_BlockA}'\n",
    "LLM_and_Survey_and_SimulationB = f'{LLM_Block} AND {Survey_Block} AND {Simulation_BlockB}'\n",
    "LLM_and_Survey_and_SimulationC = f'{LLM_Block} AND {Survey_Block} AND {Simulation_BlockC}'\n",
    "LLM_and_SimulationA_and_Methods = f'{LLM_Block} AND {Simulation_BlockA} AND {Methods_Block}'\n",
    "LLM_and_SimulationB_and_Methods = f'{LLM_Block} AND {Simulation_BlockB} AND {Methods_Block}'\n",
    "LLM_and_SimulationC_and_Methods = f'{LLM_Block} AND {Simulation_BlockC} AND {Methods_Block}'\n",
    "LLMSurvey_or_LLMSimulationA = f'({LLM_and_Survey}) OR ({LLM_and_SimulationA})'\n",
    "LLMSurvey_or_LLMSimulationB = f'({LLM_and_Survey}) OR ({LLM_and_SimulationB})'\n",
    "LLMSurvey_or_LLMSimulationC = f'({LLM_and_Survey}) OR ({LLM_and_SimulationC})'\n",
    "Survey_and_SimulationA = f'{Survey_Block} AND {Simulation_BlockA}'\n",
    "Survey_and_SimulationB = f'{Survey_Block} AND {Simulation_BlockB}'\n",
    "Survey_and_SimulationC = f'{Survey_Block} AND {Simulation_BlockC}'\n",
    "\n",
    "Simulation_BlockD = 'TS=((simulat* OR emulat* OR predict* OR imput* OR \"synthetic data\" OR \"missing data\" OR nonresponse OR \"non-response\" OR \"item nonresponse\" OR \"unit nonresponse\" OR \"synthetic respondent*\" OR \"synthetic participant*\" OR \"artificial respondent*\" OR \"artificial participant*\" OR \"virtual respondent*\" OR \"virtual participant*\" OR persona* OR \"role play*\" OR \"as a respondent\" OR \"LLM as respondent\" OR \"model as respondent\" OR proxy OR surrogate OR \"stand-in\" OR \"stand in\" OR replac* OR substitut* OR represent* OR fidelit* OR faithful* OR doppelg* OR \"Synthetic Voice*\" OR \"representing people\" OR \"LLM-generated persona*\" OR \"LLM generated persona*\") NEAR/5 (survey* OR questionnaire* OR respondent* OR response* OR interview* OR \"self-report*\" OR \"data collection\" OR opinion* OR poll* OR attitude* OR value* OR norm* OR \"public opinion*\"))'\n",
    "\n",
    "Simulation_BlockE = 'TS=(simulat* OR emulat* OR predict* OR imput* OR \"synthetic data\" OR \"missing data\" OR nonresponse OR \"non-response\" OR \"item nonresponse\" OR \"unit nonresponse\" OR \"synthetic respondent*\" OR \"synthetic participant*\" OR \"artificial respondent*\" OR \"artificial participant*\" OR \"virtual respondent*\" OR \"virtual participant*\" OR persona* OR \"role play*\" OR \"as a respondent\" OR \"LLM as respondent\" OR \"model as respondent\" OR proxy OR surrogate OR \"stand-in\" OR \"stand in\" OR replac* OR substitut* OR represent* OR fidelit* OR faithful* OR doppelg* OR \"Synthetic Voice*\" OR \"representing people\" OR \"LLM-generated persona*\" OR \"LLM generated persona*\")'\n",
    "\n",
    "LLM_and_SimulationD = f'{LLM_Block} AND {Simulation_BlockD}'\n",
    "LLM_and_SimulationE = f'{LLM_Block} AND {Simulation_BlockE}'\n",
    "LLM_and_Survey_and_SimulationD = f'{LLM_Block} AND {Survey_Block} AND {Simulation_BlockB}'\n",
    "LLM_and_Survey_and_SimulationE = f'{LLM_Block} AND {Survey_Block} AND {Simulation_BlockE}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44eefa65",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# DEFINE Set of Queries\n",
    "wos_queries = {\n",
    "    \"LLM\": LLM_Block,\n",
    "    \"Survey\": Survey_Block,\n",
    "    \"SimulationB\": Simulation_BlockB,\n",
    "    \"LLM and Survey\": LLM_and_Survey,\n",
    "    \"LLM and Survey and Methods\": LLM_and_Survey_and_Methods,\n",
    "    \"LLM and SimulationA\": LLM_and_SimulationA,\n",
    "    \"LLM and SimulationB\": LLM_and_SimulationB,\n",
    "    \"LLM and SimulationC\": LLM_and_SimulationC,\n",
    "    \"LLM and Methods\": LLM_and_Methods,\n",
    "    \"LLM and Survey and SimulationA\": LLM_and_Survey_and_SimulationA,\n",
    "    \"LLM and Survey and SimulationB\": LLM_and_Survey_and_SimulationB,\n",
    "    \"LLM and Survey and SimulationC\": LLM_and_Survey_and_SimulationC,\n",
    "    \"LLM and SimulationA and Methods\": LLM_and_SimulationA_and_Methods,\n",
    "    \"LLM and SimulationB and Methods\": LLM_and_SimulationB_and_Methods,\n",
    "    \"LLM and SimulationC and Methods\": LLM_and_SimulationC_and_Methods,\n",
    "    \"LLMSurvey or LLMSimulationA\": LLMSurvey_or_LLMSimulationA,\n",
    "    \"LLMSurvey or LLMSimulationB\": LLMSurvey_or_LLMSimulationB,\n",
    "    \"LLMSurvey or LLMSimulationC\": LLMSurvey_or_LLMSimulationC,\n",
    "    \"Survey and SimulationA\": Survey_and_SimulationA,\n",
    "    \"Survey and SimulationB\": Survey_and_SimulationB,\n",
    "    \"Survey and SimulationC\": Survey_and_SimulationC\n",
    "}\n",
    "\n",
    "wos_queries_subset = {\n",
    "    \"LLM_and_SimulationA\": LLM_and_SimulationA,\n",
    "    \"LLM_and_SimulationB\": LLM_and_SimulationB,\n",
    "    \"LLM_and_Survey_and_SimulationA\": LLM_and_Survey_and_SimulationA,\n",
    "    \"LLM_and_Survey_and_SimulationB\": LLM_and_Survey_and_SimulationB,\n",
    "    \"LLM_and_SimulationA_and_Methods\": LLM_and_SimulationA_and_Methods,\n",
    "    \"LLM_and_SimulationB_and_Methods\": LLM_and_SimulationB_and_Methods,\n",
    "    #\"LLMSurvey or LLMSimulationA\": LLMSurvey_or_LLMSimulationA,\n",
    "    #\"LLMSurvey or LLMSimulationB\": LLMSurvey_or_LLMSimulationB,   \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f0bb452",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing query: LLM_and_SimulationD\n",
      "Processing query: LLM_and_SimulationE\n",
      "Processing query: LLM_and_Survey_and_SimulationD\n",
      "Processing query: LLM_and_Survey_and_SimulationE\n"
     ]
    },
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "QueryName",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "TotalRecords",
         "rawType": "int64",
         "type": "integer"
        }
       ],
       "ref": "d67c9ff3-74b6-43ad-9476-e703e251b4bd",
       "rows": [
        [
         "0",
         "LLM_and_SimulationE",
         "38068"
        ],
        [
         "1",
         "LLM_and_Survey_and_SimulationE",
         "11691"
        ],
        [
         "2",
         "LLM_and_SimulationD",
         "2175"
        ],
        [
         "3",
         "LLM_and_Survey_and_SimulationD",
         "1674"
        ]
       ],
       "shape": {
        "columns": 2,
        "rows": 4
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>QueryName</th>\n",
       "      <th>TotalRecords</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LLM_and_SimulationE</td>\n",
       "      <td>38068</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>LLM_and_Survey_and_SimulationE</td>\n",
       "      <td>11691</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>LLM_and_SimulationD</td>\n",
       "      <td>2175</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>LLM_and_Survey_and_SimulationD</td>\n",
       "      <td>1674</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        QueryName  TotalRecords\n",
       "0             LLM_and_SimulationE         38068\n",
       "1  LLM_and_Survey_and_SimulationE         11691\n",
       "2             LLM_and_SimulationD          2175\n",
       "3  LLM_and_Survey_and_SimulationD          1674"
      ]
     },
     "execution_count": 297,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# RUN: Get Max Total records\n",
    "df_WoS_totals = wos_query_totals(wos_queries_subset)\n",
    "df_WoS_totals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91faf724",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# RUN Fetch for ALL queries\n",
    "dfs_WoS = {}\n",
    "for name, query in wos_queries.items():\n",
    "    print(f\"\\nFetching WoS results for: {name}\")\n",
    "    df = wos_fetch_all_pages(query, limit=50)\n",
    "    print(f\"{name}: {len(df)} rows\")\n",
    "    dfs_WoS[name] = df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "706d3180",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching records for query: LLM_and_SimulationA\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching records for query: LLM_and_SimulationB\n",
      "Fetching records for query: LLM_and_Survey_and_SimulationA\n",
      "Fetching records for query: LLM_and_Survey_and_SimulationB\n",
      "Fetching records for query: LLM_and_SimulationA_and_Methods\n",
      "Fetching records for query: LLM_and_SimulationB_and_Methods\n"
     ]
    }
   ],
   "source": [
    "# RUN Fetch for SUBSET of queries\n",
    "dfs_WoS_subset = {}\n",
    "for query_name, query in wos_queries_subset.items():\n",
    "    print(f\"Fetching records for query: {query_name}\")\n",
    "    df_results = wos_fetch_all_pages(query)\n",
    "    dfs_WoS_subset[query_name] = df_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1c28bf0d",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# Define Functions to clean and normalize WoS DataFrames\n",
    "def authors_from_names(names_obj):\n",
    "    if isinstance(names_obj, dict):\n",
    "        people = names_obj.get(\"authors\") or []\n",
    "        out = []\n",
    "        for a in people:\n",
    "            if isinstance(a, dict):\n",
    "                dn = a.get(\"displayName\") or a.get(\"wosStandard\") or a.get(\"full_name\") or \"\"\n",
    "                if dn:\n",
    "                    out.append(dn)\n",
    "        return \"; \".join(out)\n",
    "    return \"\"\n",
    "\n",
    "def keywords_from_obj(keywords_obj):\n",
    "    if isinstance(keywords_obj, dict):\n",
    "        ak = keywords_obj.get(\"authorKeywords\")\n",
    "        if isinstance(ak, list):\n",
    "            return \"; \".join([k for k in ak if isinstance(k, str)])\n",
    "        if isinstance(ak, str):\n",
    "            return ak\n",
    "    return \"\"\n",
    "\n",
    "def doi_from_identifiers(ident_obj):\n",
    "    if isinstance(ident_obj, dict):\n",
    "        doi = ident_obj.get(\"doi\")\n",
    "        if doi:\n",
    "            return doi\n",
    "        dois = ident_obj.get(\"dois\")\n",
    "        if isinstance(dois, list) and len(dois) > 0:\n",
    "            return dois[0]\n",
    "    return None\n",
    "\n",
    "def issn_from_identifiers(ident_obj):\n",
    "    if isinstance(ident_obj, dict):\n",
    "        val = ident_obj.get(\"issn\")\n",
    "        issn = val[0] if isinstance(val, list) and val else val\n",
    "        return issn\n",
    "    return None\n",
    "\n",
    "def isbn_from_identifiers(ident_obj):\n",
    "    if isinstance(ident_obj, dict):\n",
    "        val = ident_obj.get(\"isbn\")\n",
    "        isbn = val[0] if isinstance(val, list) and val else val\n",
    "        return isbn\n",
    "    return None\n",
    "\n",
    "def year_from_source(src_obj):\n",
    "    if isinstance(src_obj, dict):\n",
    "        return src_obj.get(\"publishYear\") or src_obj.get(\"publishedYear\")\n",
    "    return None\n",
    "\n",
    "def first_source_type(st_list):\n",
    "    if isinstance(st_list, list) and st_list:\n",
    "        return st_list[0]\n",
    "    return None\n",
    "\n",
    "def clean_wos_df(df_raw: pd.DataFrame) -> pd.DataFrame:\n",
    "    if df_raw is None or df_raw.empty:\n",
    "        return pd.DataFrame(columns=[\"title\", \"authors\", \"doi\", \"Year\", \"keywords\", \"sourceType\"])\n",
    "\n",
    "    df = df_raw.copy()\n",
    "\n",
    "    # Compute desired fields\n",
    "    df[\"authors\"] = df[\"names\"].apply(authors_from_names) if \"names\" in df.columns else \"\"\n",
    "    df[\"doi\"] = df[\"identifiers\"].apply(doi_from_identifiers) if \"identifiers\" in df.columns else None\n",
    "    df[\"issn\"] = df[\"identifiers\"].apply(issn_from_identifiers) if \"identifiers\" in df.columns else None\n",
    "    df[\"isbn\"] = df[\"identifiers\"].apply(isbn_from_identifiers) if \"identifiers\" in df.columns else None\n",
    "    df[\"Year\"] = df[\"source\"].apply(year_from_source) if \"source\" in df.columns else None\n",
    "    df[\"keywords\"] = df[\"keywords\"].apply(keywords_from_obj) if \"keywords\" in df.columns else \"\"\n",
    "    df[\"sourceType\"] = df[\"sourceTypes\"].apply(first_source_type) if \"sourceTypes\" in df.columns else None\n",
    "\n",
    "    # Drop intermediate/noisy columns\n",
    "    to_drop = [\"uid\", \"types\", \"sourceTypes\", \"source\", \"names\", \"links\", \"citations\", \"identifiers\"]\n",
    "    df = df.drop(columns=[c for c in to_drop if c in df.columns], errors=\"ignore\")\n",
    "\n",
    "    # Reorder columns (keep others after the key fields)\n",
    "    key_cols = [c for c in [\"title\", \"authors\", \"doi\", \"issn\", \"isbn\",\n",
    "                            \"Year\", \"keywords\", \"sourceType\"] if c in df.columns]\n",
    "    other_cols = [c for c in df.columns if c not in key_cols]\n",
    "    df = df[key_cols + other_cols]\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df457fdf",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# RUN Cleaning \n",
    "dfs_WoS_clean = {name: clean_wos_df(df) for name, df in dfs_WoS_clean.items()}\n",
    "\n",
    "df_WoS_LLM_and_Survey_clean = dfs_WoS_clean[\"LLM and Survey\"]\n",
    "df_WoS_LLM_and_Survey_and_Methods_clean = dfs_WoS_clean[\"LLM and Survey and Methods\"]\n",
    "df_WoS_LLM_and_SimulationA_clean = dfs_WoS_clean[\"LLM and SimulationA\"]\n",
    "df_WoS_LLM_and_SimulationB_clean = dfs_WoS_clean[\"LLM and SimulationB\"]\n",
    "df_WoS_LLM_and_SimulationC_clean = dfs_WoS_clean[\"LLM and SimulationC\"]\n",
    "df_WoS_LLM_and_Methods_clean = dfs_WoS_clean[\"LLM and Methods\"]\n",
    "df_WoS_LLM_and_Survey_and_SimulationA_clean = dfs_WoS_clean[\"LLM and Survey and SimulationA\"]\n",
    "df_WoS_LLM_and_Survey_and_SimulationB_clean = dfs_WoS_clean[\"LLM and Survey and SimulationB\"]\n",
    "df_WoS_LLM_and_Survey_and_SimulationC_clean = dfs_WoS_clean[\"LLM and Survey and SimulationC\"]\n",
    "df_WoS_LLM_and_SimulationA_and_Methods_clean = dfs_WoS_clean[\"LLM and SimulationA and Methods\"]\n",
    "df_WoS_LLM_and_SimulationB_and_Methods_clean = dfs_WoS_clean[\"LLM and SimulationB and Methods\"]\n",
    "df_WoS_LLM_and_SimulationC_and_Methods_clean = dfs_WoS_clean[\"LLM and SimulationC and Methods\"]\n",
    "df_WoS_LLMSurvey_or_LLMSimulationA_clean = dfs_WoS_clean[\"LLMSurvey or LLMSimulationA\"]\n",
    "df_WoS_LLMSurvey_or_LLMSimulationB_clean = dfs_WoS_clean[\"LLMSurvey or LLMSimulationB\"]\n",
    "df_WoS_LLMSurvey_or_LLMSimulationC_clean = dfs_WoS_clean[\"LLMSurvey or LLMSimulationC\"]\n",
    "df_WoS_Survey_and_SimulationA_clean = dfs_WoS_clean[\"Survey and SimulationA\"]\n",
    "df_WoS_Survey_and_SimulationB_clean = dfs_WoS_clean[\"Survey and SimulationB\"]\n",
    "df_WoS_Survey_and_SimulationC_clean = dfs_WoS_clean[\"Survey and SimulationC\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1d5c354",
   "metadata": {},
   "outputs": [],
   "source": [
    "# RUN Cleaning for Subset\n",
    "dfs_WoS_subset_clean = {name: clean_wos_df(df) for name, df in dfs_WoS_subset.items()}\n",
    "\n",
    "# Bind cleaned dataframes to variables\n",
    "df_WoS_LLM_and_SimulationA = dfs_WoS_subset_clean[\"LLM_and_SimulationA\"]\n",
    "df_WoS_LLM_and_SimulationB = dfs_WoS_subset_clean[\"LLM_and_SimulationB\"]\n",
    "df_WoS_LLM_and_Survey_and_SimulationA = dfs_WoS_subset_clean[\"LLM_and_Survey_and_SimulationA\"]\n",
    "df_WoS_LLM_and_Survey_and_SimulationB = dfs_WoS_subset_clean[\"LLM_and_Survey_and_SimulationB\"]\n",
    "df_WoS_LLM_and_SimulationA_and_Methods = dfs_WoS_subset_clean[\"LLM_and_SimulationA_and_Methods\"]\n",
    "df_WoS_LLM_and_SimulationB_and_Methods = dfs_WoS_subset_clean[\"LLM_and_SimulationB_and_Methods\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19c6984a",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# Define Query Blocs\n",
    "LLM_TERMS = [\n",
    "    \"large language model\", \"foundation model\", \"LLM\", \"LLMs\", \"GPT\", \"GPT-3\", \n",
    "    \"GPT-3.5\", \"GPT-4\", \"ChatGPT\", \"LLaMA\", \"Llama 2\", \"Llama 3\", \"Mistral\", \n",
    "    \"Mixtral\", \"Claude\", \"Gemini\", \"PaLM\", \"Qwen\", \"Falcon 180B\", \"Phi-3\", \n",
    "    \"DeepSeek\", \"AI language model\", \"AI model\", \"chatbot\", \"chat bot\", \n",
    "    \"transformer-based model\", \"transformer language model\"\n",
    "]\n",
    "\n",
    "SURVEY_TERMS = [\n",
    "    \"survey\", \"questionnaire\", \"opinion poll\", \"survey data\", \"public opinion\", \n",
    "    \"feeling thermometer\", \"open ended\", \"nonresponse\", \"non-response\", \"Likert\", \n",
    "    \"rating scale\", \"ranking question\", \"matrix question\", \"vignette\", \n",
    "    \"anchoring vignette\", \"conjoint\", \"discrete choice\", \"DCE\", \"self-report\", \n",
    "    \"respondent data\", \"human judgment\", \"item nonresponse\", 'nonresponse', \n",
    "    \"unit nonresponse\", \"missing data\"\n",
    "]\n",
    "\n",
    "SIMULATION_CORE = [\n",
    "    \"simulate\", \"simulation\", \"simulating\", \"emulate\", \"emulation\", \"synthetic\", \"imputation\", \"impute\",\n",
    "    \"synthetic data\", \"response generation\", \"as a respondent\", \"model as respondent\", \n",
    "    \"LLM as respondent\", \"synthetic respondent\", \"artificial respondent\", \"virtual participant\", \n",
    "    \"synthetic participant\", \"proxy respondent\", \"surrogate respondent\", \"persona\", \n",
    "    \"role play\", \"role prompt\", \"persona prompt\"\n",
    "]\n",
    "\n",
    "\n",
    "# Function to check if any terms from a list are in the text (used in the query generation)\n",
    "def any_tiabs(terms):\n",
    "    # Placeholder function to demonstrate matching behavior\n",
    "    return \" OR \".join([f\"({term})\" for term in terms])\n",
    "\n",
    "# Blocks that match the different term categories\n",
    "LLM_BLOCK = any_tiabs(LLM_TERMS)\n",
    "SURVEY_BLOCK = any_tiabs(SURVEY_TERMS)\n",
    "SIM_BLOCK = any_tiabs(SIMULATION_CORE)\n",
    "\n",
    "# Query blocks for combining different categories\n",
    "query_blocks = {\n",
    "    \"Simulation Block + Survey Block\": f\"({SIM_BLOCK}) AND ({SURVEY_BLOCK})\",\n",
    "    \"LLM Block + Survey Block\": f\"({LLM_BLOCK}) AND ({SURVEY_BLOCK})\",\n",
    "    \"All Blocks\": f\"({LLM_BLOCK}) AND ({SURVEY_BLOCK}) AND ({SIM_BLOCK})\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c03f929",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "### RUN SEARCHES AND STORE RESULTS\n",
    "\n",
    "dfs = {}\n",
    "for label, query in query_blocks.items():\n",
    "    print(f\"Fetching results for: {label}\")\n",
    "    df = fetch_results(query, max_results=100, page_size=100)\n",
    "    dfs[label] = df\n",
    "    print(f\"Found {len(df)} results for {label}\")\n",
    "\n",
    "df_sim_survey = dfs[\"Simulation Block + Survey Block\"]\n",
    "df_llm_survey = dfs[\"LLM Block + Survey Block\"]\n",
    "df_all_blocks = dfs[\"All Blocks\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3840ea0e",
   "metadata": {},
   "source": [
    "## Semantic Scholar API Call"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17ace23e",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "48f41e66",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "from semanticscholar import SemanticScholar\n",
    "import os\n",
    "from dotenv import load_dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "3cd87858",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# Define Search Parameters\n",
    "FIELDS_SS = [\"paperId\", \"title\", \"year\", \"authors\", \"abstract\", \"url\", \"citationCount\", \"externalIds\"]\n",
    "YEAR_FILTER = \"2020-\"\n",
    "BULK_SORT = \"citationCount:desc\"\n",
    "MAX_PAPERS_PER_GROUP = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "e8c2ddcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define Search Function\n",
    "\n",
    "# -------- Helper Functions --------\n",
    "def author_names(paper_authors):\n",
    "    if not paper_authors:\n",
    "        return \"\"\n",
    "    names = []\n",
    "    for a in paper_authors:\n",
    "        # supports Author objects and dicts\n",
    "        names.append(getattr(a, \"name\", a.get(\"name\") if isinstance(a, dict) else None))\n",
    "    return \", \".join([n for n in names if n])\n",
    "\n",
    "def _safe_get(container, key):\n",
    "    \"\"\"Access dict or object attribute safely.\"\"\"\n",
    "    if container is None:\n",
    "        return None\n",
    "    if isinstance(container, dict):\n",
    "        return container.get(key)\n",
    "    return getattr(container, key, None)\n",
    "\n",
    "def ss_paper_row(p):\n",
    "    ext = getattr(p, \"externalIds\", None)\n",
    "    pv  = getattr(p, \"publicationVenue\", None)\n",
    "    doi  = _safe_get(ext, \"DOI\") or _safe_get(ext, \"doi\")\n",
    "\n",
    "    return {\n",
    "        \"paperId\": getattr(p, \"paperId\", None),\n",
    "        \"title\": getattr(p, \"title\", None),\n",
    "        \"year\": getattr(p, \"year\", None),\n",
    "        \"authors\": author_names(getattr(p, \"authors\", None)),\n",
    "        \"abstract\": getattr(p, \"abstract\", None),\n",
    "        \"url\": getattr(p, \"url\", None),\n",
    "        \"citationCount\": getattr(p, \"citationCount\", None),\n",
    "        \"doi\": doi,\n",
    "    }\n",
    "\n",
    "# -------- Main Fetch Function --------\n",
    "\n",
    "# Funciton: Fetch all pages\n",
    "def ss_fetch_bulk(tag: str,\n",
    "                       max_papers: int = MAX_PAPERS_PER_GROUP,\n",
    "                       sort: str | None = BULK_SORT) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Fetch all pages for a query key via Semantic Scholar bulk search,\n",
    "    returning a DataFrame with:paperId, title, year, authors, abstract, url, citationCount, doi\n",
    "    \"\"\"\n",
    "    if tag not in QUERY_GROUPS:\n",
    "        valid = \", \".join(QUERY_GROUPS.keys())\n",
    "        raise ValueError(f\"Unknown group '{tag}'. Valid keys: {valid}\")\n",
    "\n",
    "    sch = SemanticScholar(api_key=api_key_SS, timeout=45, retry=True)\n",
    "    query = QUERY_GROUPS[tag]\n",
    "\n",
    "    results = sch.search_paper(\n",
    "        query=query,\n",
    "        year=YEAR_FILTER,      \n",
    "        fields=FIELDS_SS,      \n",
    "        bulk=True,             \n",
    "        sort=sort,             \n",
    "    )\n",
    "\n",
    "    est_total = getattr(results, \"total\", None)\n",
    "    print(f\"Estimated total: {est_total if est_total is not None else 'n/a'}\")\n",
    "\n",
    "    rows = []\n",
    "    for i, p in enumerate(results, start=1):\n",
    "        rows.append(ss_paper_row(p))\n",
    "        if i >= max_papers:\n",
    "            break\n",
    "\n",
    "    cols = [\"paperId\", \"title\", \"year\", \"authors\", \"abstract\", \"url\", \"citationCount\", \"doi\"]\n",
    "    return pd.DataFrame(rows, columns=cols)\n",
    "\n",
    "# Function: Get total record counts for each query\n",
    "def ss_query_totals(query_groups: dict) -> pd.DataFrame:\n",
    "    sch = SemanticScholar\n",
    "    sch = SemanticScholar(api_key=api_key_SS, timeout=45, retry=True)\n",
    "    results = []\n",
    "    for name, query in query_groups.items():\n",
    "        res = sch.search_paper(\n",
    "            query=query,\n",
    "            year=YEAR_FILTER,\n",
    "            fields=FIELDS_SS,\n",
    "            bulk=True,\n",
    "            sort=BULK_SORT\n",
    "        )\n",
    "        total = getattr(res, \"total\", None)\n",
    "        results.append({\"QueryName\": name, \"TotalRecords\": total})    \n",
    "    return pd.DataFrame(results).sort_values(\"TotalRecords\", ascending=False).reset_index(drop=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "dc6c4e5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define Search Query Blocks\n",
    "LLM_Block = ('( \"large language model\" | \"large language models\" | \"foundation model\" | \"foundation models\" | LLM | LLMs | GPT | \"GPT-3\" | \"GPT-3.5\" | \"GPT-4\" | ChatGPT | LLaMA* | \"Llama 2\" | \"Llama 3\" | Mistral | Mixtral | Claude* | Gemini | PaLM | Qwen | DeepSeek |  \"Falcon 180B\" | \"Phi-3\" | \"AI language model\" | chatbot | \"chat bot\" | \"transformer language model\" | \"transformer-based model\" )')\n",
    "\n",
    "Survey_Block = ('( survey* | \"survey data\" | \"survey response\" | \"survey responses\" | questionnaire* | question* | \"opinion poll\" | \"public opinion\" | attitude* | value* | norm* | moral* | \"feeling thermometer\" | \"open ended\" | \"open-ended\" | nonresponse | \"non-response\" |  respondent* | participant* | interview* | \"self-report\" | \"self-reported\" | \"data collection\")' )\n",
    "\n",
    "Simulation_BlockA = ('((simulat* | emulat* | predict* | imput* | \"missing data\" | nonresponse | \"non-response\" |  \"item nonresponse\" | \"synthetic respondent*\" | \"synthetic participant*\" | \"artificial respondent*\" |  \"artificial participant*\" | \"virtual respondent*\" | \"virtual participant*\" | persona* | \"role play*\") + (survey* | questionnaire* | respondent* | response* | interview* | \"self-report*\" |  \"data collection\" | opinion* | poll*))')\n",
    "\n",
    "Simulation_BlockB = ('( simulat* | emulat* | predict* | imput* | \"synthetic data\" | \"missing data\" | nonresponse | \"non-response\" |  \"item nonresponse\" | \"synthetic respondent\" | \"synthetic respondents\" | \"synthetic participant\" |  \"synthetic participants\" | \"artificial respondent\" | \"artificial participant\" | \"virtual respondent\" | \"virtual participant\" | persona | personas |  \"role play\" | \"role-playing\" | (role + play*) |  \"as a respondent\" | \"LLM as respondent\" | \"model as respondent\" | proxy | surrogate | \"stand-in\" | \"stand in\" | replac* | substitut* | represent* | fidelit* | faithful* | doppelg* | (\"Synthetic Voice persona\"~5 | \"persona Synthetic Voice\"~5 |   \"representing people survey\"~5 | \"survey representing people\"~5 |  \"representing people respondent\"~5 | \"respondent representing people\"~5) )')\n",
    "\n",
    "Simulation_BlockC = ('( \"survey simulation\" | \"simulated participant\" | \"simulated respondent\" |  \"synthetic data\" | \"synthetic survey data\" | \"synthetic respondent\" | \"synthetic participant\" |  \"artificial respondent\" | \"artificial participant\" | \"virtual respondent\" | \"virtual participant\" |  \"LLM as respondent\" | \"model as respondent\" | \"as a respondent\" | \"role play\" | \"role-playing\" | persona | personas)')\n",
    "\n",
    "Methods_Block = ('(prompt* | \"few-shot\" | \"few-shot learning\" | \"zero-shot\" | \"zero-shot learning\" | \"in-context learning\" | ICL | \"chain of thought\" | \"self-consistency\" | \"system message\" | persona | personas | \"role prompt*\" | \"instruction-tun*\" | \"instruction prompt*\" | \"fine-tun*\" | (\"reinforcement learning with human feedback\" | RLHF) | (\"reinforcement learning with AI feedback\" | RLAIF) | \"temperature parameter\" | \"temperature setting\" | \"nucleus sampling\" | \"top-p sampling\" | \"active learning\" | \"transfer learning\" | \"meta learning\" | \"meta-learning\" | \"representation learning\" | \"continual learning\" | \"lifelong learning\")')\n",
    "\n",
    "# Combinations using + for AND and | for OR\n",
    "QUERY_GROUPS = {\n",
    "    # pairs\n",
    "    \"ss_llm_and_survey\":           f'{LLM_Block} + {Survey_Block}',\n",
    "    \"ss_llm_and_simA\":             f'{LLM_Block} + {Simulation_BlockA}',\n",
    "    \"ss_llm_and_simB\":             f'{LLM_Block} + {Simulation_BlockB}',\n",
    "    \"ss_llm_and_simC\":             f'{LLM_Block} + {Simulation_BlockC}',\n",
    "    #\"ss_llm_and_methods\":          f'{LLM_Block} + {Methods_Block}',\n",
    "    \"ss_survey_and_simA\":          f'{Survey_Block} + {Simulation_BlockA}',\n",
    "    \"ss_survey_and_simB\":          f'{Survey_Block} + {Simulation_BlockB}',\n",
    "    \"ss_survey_and_simC\":          f'{Survey_Block} + {Simulation_BlockC}',\n",
    "\n",
    "    # triples\n",
    "    #\"ss_llm_survey_methods\":       f'{LLM_Block} + {Survey_Block} + {Methods_Block}',\n",
    "    \"ss_llm_survey_simA\":          f'{LLM_Block} + {Survey_Block} + {Simulation_BlockA}',\n",
    "    \"ss_llm_survey_simB\":          f'{LLM_Block} + {Survey_Block} + {Simulation_BlockB}',\n",
    "    \"ss_llm_survey_simC\":          f'{LLM_Block} + {Survey_Block} + {Simulation_BlockC}',\n",
    "    #\"ss_llm_simA_methods\":         f'{LLM_Block} + {Simulation_BlockA} + {Methods_Block}',\n",
    "    #\"ss_llm_simB_methods\":         f'{LLM_Block} + {Simulation_BlockB} + {Methods_Block}',\n",
    "    #\"ss_llm_simC_methods\":         f'{LLM_Block} + {Simulation_BlockC} + {Methods_Block}',\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "73a84e21",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "QueryName",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "TotalRecords",
         "rawType": "int64",
         "type": "integer"
        }
       ],
       "ref": "3a148d56-df9e-4b20-9a67-ad40f4c6dd58",
       "rows": [
        [
         "0",
         "ss_survey_and_simB",
         "2301514"
        ],
        [
         "1",
         "ss_survey_and_simA",
         "521098"
        ],
        [
         "2",
         "ss_survey_and_simC",
         "409921"
        ],
        [
         "3",
         "ss_llm_and_simB",
         "66677"
        ],
        [
         "4",
         "ss_llm_and_survey",
         "65721"
        ],
        [
         "5",
         "ss_llm_survey_simB",
         "21293"
        ],
        [
         "6",
         "ss_llm_and_simA",
         "9408"
        ],
        [
         "7",
         "ss_llm_and_simC",
         "6650"
        ],
        [
         "8",
         "ss_llm_survey_simA",
         "5957"
        ],
        [
         "9",
         "ss_llm_survey_simC",
         "3269"
        ]
       ],
       "shape": {
        "columns": 2,
        "rows": 10
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>QueryName</th>\n",
       "      <th>TotalRecords</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ss_survey_and_simB</td>\n",
       "      <td>2301514</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ss_survey_and_simA</td>\n",
       "      <td>521098</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ss_survey_and_simC</td>\n",
       "      <td>409921</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ss_llm_and_simB</td>\n",
       "      <td>66677</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ss_llm_and_survey</td>\n",
       "      <td>65721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>ss_llm_survey_simB</td>\n",
       "      <td>21293</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>ss_llm_and_simA</td>\n",
       "      <td>9408</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>ss_llm_and_simC</td>\n",
       "      <td>6650</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>ss_llm_survey_simA</td>\n",
       "      <td>5957</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>ss_llm_survey_simC</td>\n",
       "      <td>3269</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            QueryName  TotalRecords\n",
       "0  ss_survey_and_simB       2301514\n",
       "1  ss_survey_and_simA        521098\n",
       "2  ss_survey_and_simC        409921\n",
       "3     ss_llm_and_simB         66677\n",
       "4   ss_llm_and_survey         65721\n",
       "5  ss_llm_survey_simB         21293\n",
       "6     ss_llm_and_simA          9408\n",
       "7     ss_llm_and_simC          6650\n",
       "8  ss_llm_survey_simA          5957\n",
       "9  ss_llm_survey_simC          3269"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Run: Get Max Total records\n",
    "ss_query_totals(QUERY_GROUPS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "78cf5a25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimated total: 65721\n",
      "Estimated total: 9408\n",
      "Estimated total: 66677\n",
      "Estimated total: 6650\n",
      "Estimated total: 521097\n",
      "Estimated total: 2301515\n",
      "Estimated total: 409921\n",
      "Estimated total: 5957\n",
      "Estimated total: 21293\n",
      "Estimated total: 3269\n"
     ]
    }
   ],
   "source": [
    "# Run Fetch for all defined queries\n",
    "df_ss_llm_and_survey = ss_fetch_bulk(\"ss_llm_and_survey\")\n",
    "df_SS_llm_and_simA = ss_fetch_bulk(\"ss_llm_and_simA\")\n",
    "df_SS_llm_and_simB = ss_fetch_bulk(\"ss_llm_and_simB\")\n",
    "df_SS_llm_and_simC = ss_fetch_bulk(\"ss_llm_and_simC\")\n",
    "df_ss_survey_and_simA = ss_fetch_bulk(\"ss_survey_and_simA\")\n",
    "df_ss_survey_and_simB = ss_fetch_bulk(\"ss_survey_and_simB\")\n",
    "df_ss_survey_and_simC = ss_fetch_bulk(\"ss_survey_and_simC\")\n",
    "df_SS_llm_survey_simA = ss_fetch_bulk(\"ss_llm_survey_simA\")\n",
    "df_SS_llm_survey_simB = ss_fetch_bulk(\"ss_llm_survey_simB\")\n",
    "df_SS_llm_survey_simC = ss_fetch_bulk(\"ss_llm_survey_simC\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "49aaf6f7",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'matplotlib'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[60]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# plot citation count for 2000 and 2025 of df_ss_survey_and_simB\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mmatplotlib\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpyplot\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mplt\u001b[39;00m\n\u001b[32m      3\u001b[39m plt.figure(figsize=(\u001b[32m10\u001b[39m, \u001b[32m6\u001b[39m))\n\u001b[32m      4\u001b[39m plt.hist(df_ss_survey_and_simB[\u001b[33m'\u001b[39m\u001b[33mcitationCount\u001b[39m\u001b[33m'\u001b[39m].dropna(), bins=\u001b[32m30\u001b[39m, color=\u001b[33m'\u001b[39m\u001b[33mskyblue\u001b[39m\u001b[33m'\u001b[39m, edgecolor=\u001b[33m'\u001b[39m\u001b[33mblack\u001b[39m\u001b[33m'\u001b[39m)\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'matplotlib'"
     ]
    }
   ],
   "source": [
    "# plot citation count for 2000 and 2025 of df_ss_survey_and_simB\n",
    "import matplotlib.pyplot as plt\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.hist(df_ss_survey_and_simB['citationCount'].dropna(), bins=30, color='skyblue', edgecolor='black')\n",
    "plt.title('Citation Count Distribution for df_ss_survey_and_simB')\n",
    "plt.xlabel('Citation Count')\n",
    "plt.ylabel('Number of Papers')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efae8589",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimated total: 51839\n",
      "Estimated total: 8050\n",
      "Estimated total: 54719\n",
      "Estimated total: 4949\n",
      "Estimated total: 5098\n",
      "Estimated total: 17113\n",
      "Estimated total: 2470\n"
     ]
    }
   ],
   "source": [
    "# Common combos\n",
    "df_SS_llm_svy       = main(\"ss_llm_and_survey\")\n",
    "df_SS_llm_simA      = main(\"ss_llm_and_simA\")\n",
    "df_SS_llm_simB      = main(\"ss_llm_and_simB\")\n",
    "df_SS_llm_simC      = main(\"ss_llm_and_simC\")\n",
    "df_SS_llm_svy_simA  = main(\"ss_llm_survey_simA\")\n",
    "df_SS_llm_svy_simB  = main(\"ss_llm_survey_simB\")\n",
    "df_SS_llm_svy_simC  = main(\"ss_llm_survey_simC\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cb6e9ed",
   "metadata": {},
   "source": [
    "## ArXiv API Call"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5e4d45b9",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "import arxiv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "41288d7f",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# Define Search\n",
    "def fetch_results(query, max_results=200, page_size=100):\n",
    "    client = arxiv.Client(\n",
    "        page_size=page_size,      # results per page from API\n",
    "        delay_seconds=3,          # be nice to arXiv\n",
    "        num_retries=3\n",
    "    )\n",
    "    search = arxiv.Search(\n",
    "        query=query,\n",
    "        max_results=max_results,\n",
    "        sort_by=arxiv.SortCriterion.Relevance,\n",
    "        sort_order=arxiv.SortOrder.Descending,\n",
    "    )\n",
    "    seen = set()\n",
    "    rows = []\n",
    "    for r in client.results(search):\n",
    "        if r.entry_id in seen:\n",
    "            continue\n",
    "        seen.add(r.entry_id)\n",
    "        rows.append({\n",
    "            \"arxiv_id\": r.get_short_id() if hasattr(r, \"get_short_id\") else r.entry_id.split('/')[-1],\n",
    "            \"title\": r.title.strip(),\n",
    "            \"published\": r.published.strftime(\"%Y-%m-%d\") if r.published else \"\",\n",
    "            \"updated\": r.updated.strftime(\"%Y-%m-%d\") if r.updated else \"\",\n",
    "            \"primary_category\": getattr(r, \"primary_category\", \"\"),\n",
    "            \"categories\": \", \".join(getattr(r, \"categories\", []) or []),\n",
    "            \"authors\": \", \".join(a.name for a in r.authors),\n",
    "            \"summary\": r.summary.strip(),\n",
    "            \"pdf_url\": r.pdf_url,\n",
    "            \"abs_url\": r.entry_id,\n",
    "        })\n",
    "    return pd.DataFrame(rows)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a35c725f",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# Define Functions\n",
    "def author_names(paper_authors):\n",
    "    if not paper_authors:\n",
    "        return \"\"\n",
    "    names = []\n",
    "    for a in paper_authors:\n",
    "        # supports Author objects and dicts\n",
    "        names.append(getattr(a, \"name\", a.get(\"name\") if isinstance(a, dict) else None))\n",
    "    return \", \".join([n for n in names if n])\n",
    "\n",
    "def paper_row(p):\n",
    "    return {\n",
    "        \"paperId\": getattr(p, \"paperId\", None),\n",
    "        \"title\": getattr(p, \"title\", None),\n",
    "        \"year\": getattr(p, \"year\", None),\n",
    "        \"authors\": author_names(getattr(p, \"authors\", None)),\n",
    "        \"abstract\": getattr(p, \"abstract\", None),\n",
    "        \"url\": getattr(p, \"url\", None),\n",
    "        \"citationCount\": getattr(p, \"citationCount\", None),\n",
    "    }\n",
    "\n",
    "def fetch_bulk_group(sch: SemanticScholar, query: str,\n",
    "                     year_filter: str, fields: list,\n",
    "                     max_papers: int, sort: str | None = None):\n",
    "    \"\"\"\n",
    "    Runs a bulk search and yields up to max_papers Paper objects.\n",
    "    Prints the API estimated total and progress as it goes.\n",
    "    \"\"\"\n",
    "    results = sch.search_paper(\n",
    "        query=query,\n",
    "        year=year_filter,     # e.g., \"2023-\"\n",
    "        fields=fields,\n",
    "        bulk=True,            # /graph/v1/paper/search/bulk\n",
    "        sort=sort,            # only works with bulk=True\n",
    "    )\n",
    "    est_total = getattr(results, \"total\", None)\n",
    "    print(f\"Estimated total: {est_total if est_total is not None else 'n/a'}\")\n",
    "\n",
    "    count = 0\n",
    "    for p in results:        # iterates across pages automatically\n",
    "        yield p\n",
    "        count += 1\n",
    "        if count >= max_papers:\n",
    "            break\n",
    "\n",
    "def fetch_group_df(sch: SemanticScholar, \n",
    "                   tag: str, \n",
    "                   max_papers_override=None) -> pd.DataFrame:\n",
    "    \"\"\"Fetch a single query group and return a DataFrame.\"\"\"\n",
    "    if tag not in QUERY_GROUPS:\n",
    "        valid = \", \".join(QUERY_GROUPS.keys())\n",
    "        raise ValueError(f\"Unknown group '{tag}'. Valid keys: {valid}\")\n",
    "\n",
    "    query = QUERY_GROUPS[tag]\n",
    "    rows = []\n",
    "    for paper in fetch_bulk_group(\n",
    "        sch,\n",
    "        query=query,\n",
    "        year_filter=YEAR_FILTER,\n",
    "        fields=FIELDS,\n",
    "        max_papers=max_papers_override if max_papers_override is not None else MAX_PAPERS_PER_GROUP,\n",
    "        sort=BULK_SORT,\n",
    "    ):\n",
    "        rows.append(paper_row(paper))\n",
    "\n",
    "    df = pd.DataFrame(rows, columns=FIELDS)\n",
    "    return df\n",
    "\n",
    "\n",
    "# ---------- Main ----------\n",
    "def main(tag: str | None = None, \n",
    "         max_papers_override=None):\n",
    "\n",
    "    sch = SemanticScholar(api_key=api_key_SS, timeout=45, retry=True)\n",
    "\n",
    "    if tag is not None:\n",
    "        return fetch_group_df(sch, tag, max_papers_override=max_papers_override)\n",
    "\n",
    "    out = {}\n",
    "    for k in QUERY_GROUPS:\n",
    "        out[k] = fetch_group_df(sch, k, max_papers_override=max_papers_override)\n",
    "    return out"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c12b760",
   "metadata": {},
   "source": [
    "# Measure Precision & Recall"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ca95283",
   "metadata": {},
   "source": [
    "## Load Refence Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7a901bf6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gold list size: 25\n"
     ]
    }
   ],
   "source": [
    "# Load the CSV of Zotero list of papers\n",
    "gold_df = pd.read_csv(\"data/LLM - Survey Proxies.csv\")\n",
    "\n",
    "gold_df = gold_df[[\"Title\", \"Item Type\", \"Abstract Note\", \n",
    "                   \"Publication Year\", \"Author\", \n",
    "                   \"DOI\", \"ISBN\", \"ISSN\"]].drop_duplicates().reset_index(drop=True)\n",
    "gold_df[\"preprint_flag\"] = gold_df[\"Item Type\"].apply(lambda x: \"preprint\" if x == \"preprint\" else \"non-preprint\")\n",
    "gold_df = gold_df.rename(columns={\"DOI\": \"doi\", \"ISBN\": \"isbn\", \"ISSN\": \"issn\"})\n",
    "\n",
    "print(f\"Gold list size: {len(gold_df)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f1fdbfa2",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# Define normalization function (normalize_title)\n",
    "def normalize_title(s: str) -> str:\n",
    "    # Unicode normalize\n",
    "    s = unicodedata.normalize(\"NFKC\", str(s))\n",
    "    # Lowercase\n",
    "    s = s.lower()\n",
    "    # Remove punctuation-like characters\n",
    "    s = re.sub(r\"[^\\w\\s]\", \" \", s)   # keep letters, numbers, underscore, whitespace\n",
    "    # Collapse whitespace\n",
    "    s = re.sub(r\"\\s+\", \" \", s).strip()\n",
    "    return s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d286990c-0982-4551-ab17-495e42325387",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaned Gold list size: 22 after removing bad entries\n"
     ]
    }
   ],
   "source": [
    "# Remove known papers that doesn't exist in WoS Dataset\n",
    "bad_titles = [\n",
    "    \"Algorithmic Fidelity of Large Language Models in Generating Synthetic German Public Opinions: A Case Study\",\n",
    "    \"Extracting Affect Aggregates from Longitudinal Social Media Data with Temporal Adapters for Large Language Models\",\n",
    "    \"The Potential and Challenges of Evaluating Attitudes, Opinions, and Values in Large Language Models\"\n",
    "]\n",
    "\n",
    "bad_titles_normalized = [normalize_title(t) for t in bad_titles]\n",
    "gold_df[\"norm_title\"] = gold_df[\"Title\"].apply(normalize_title)\n",
    "gold_df = gold_df[~gold_df[\"norm_title\"].isin(bad_titles_normalized)].reset_index(drop=True) # filter out bad titles\n",
    "\n",
    "print(f\"Cleaned Gold list size: {len(gold_df)} after removing bad entries\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "eba22586",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate sets for preprint and non-preprint for 'calc_recall_with_missing' function\n",
    "gold_preprint_set = set(gold_df[gold_df[\"preprint_flag\"] == \"preprint\"][\"norm_title\"])\n",
    "gold_non_preprint_set = set(gold_df[gold_df[\"preprint_flag\"] == \"non-preprint\"][\"norm_title\"])\n",
    "gold_norm_set = set(gold_df[\"norm_title\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce24126d",
   "metadata": {},
   "source": [
    "## Define Recall Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ecb2bdf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define function to calculate recall\n",
    "def calc_recall(df, \n",
    "                gold_norm_set, \n",
    "                gold_preprint_set, \n",
    "                gold_non_preprint_set):\n",
    "    df = df.copy()\n",
    "    df[\"norm_title\"] = df[\"title\"].map(normalize_title)\n",
    "    \n",
    "    found_norms = gold_norm_set.intersection(set(df['norm_title']))\n",
    "    recall = len(found_norms) / len(gold_norm_set) if len(gold_norm_set) > 0 else 0\n",
    "\n",
    "    found_preprints = gold_preprint_set.intersection(set(df['norm_title']))\n",
    "    recall_preprint = len(found_preprints) / len(gold_preprint_set) if len(gold_preprint_set) > 0 else 0\n",
    "\n",
    "    found_non_preprints = gold_non_preprint_set.intersection(set(df['norm_title']))\n",
    "    recall_non_preprint = len(found_non_preprints) / len(gold_non_preprint_set) if len(gold_non_preprint_set) > 0 else 0\n",
    "\n",
    "    return pd.DataFrame({\n",
    "        \"Number of Papers Retrieved\": [int(len(df))],\n",
    "        \"Recall (out of 21)\": [f\"{recall:.2%}\"],\n",
    "        \"Recall (journalArticels & other)\": [f\"{recall_non_preprint:.2%}\"],\n",
    "        \"Recall (preprints)\": [f\"{recall_preprint:.2%}\"],\n",
    "    })\n",
    "\n",
    "# Define function to calculate recall w/ missing titles\n",
    "gold_norm_to_orig = {row[\"norm_title\"]: row[\"Title\"] for _, row in gold_df.iterrows()}\n",
    "\n",
    "def calc_recall_with_missing(df, \n",
    "                             gold_norm_set = gold_norm_set, \n",
    "                             gold_preprint_set = gold_preprint_set, \n",
    "                             gold_non_preprint_set = gold_non_preprint_set, \n",
    "                             norm_to_orig = gold_norm_to_orig):\n",
    "    df = df.copy()\n",
    "    if \"title\" not in df.columns:\n",
    "        df[\"title\"] = \"\"\n",
    "    df[\"norm_title\"] = df[\"title\"].map(normalize_title)\n",
    "\n",
    "    df_norms = set(df[\"norm_title\"])\n",
    "\n",
    "    found_norms = gold_norm_set.intersection(df_norms)\n",
    "    found_preprints = gold_preprint_set.intersection(df_norms)\n",
    "    found_non_preprints = gold_non_preprint_set.intersection(df_norms)\n",
    "\n",
    "    recall = len(found_norms) / len(gold_norm_set) if len(gold_norm_set) > 0 else 0\n",
    "    recall_preprint = len(found_preprints) / len(gold_preprint_set) if len(gold_preprint_set) > 0 else 0\n",
    "    recall_non_preprint = len(found_non_preprints) / len(gold_non_preprint_set) if len(gold_non_preprint_set) > 0 else 0\n",
    "\n",
    "    # Missing normalized titles\n",
    "    missing_preprint_norms = gold_preprint_set - df_norms\n",
    "    missing_non_preprint_norms = gold_non_preprint_set - df_norms\n",
    "\n",
    "    # Map back to original titles\n",
    "    missing_preprint_titles = [norm_to_orig.get(n, n) for n in sorted(missing_preprint_norms)]\n",
    "    missing_non_preprint_titles = [norm_to_orig.get(n, n) for n in sorted(missing_non_preprint_norms)]\n",
    "\n",
    "    # return a dataframe with recall stats and missing titles\n",
    "    return pd.DataFrame([{\n",
    "        \"Number of Papers Retrieved\": len(df),\n",
    "        \"Recall (out of 21)\": f\"{recall:.2%}\",\n",
    "        \"Recall (journalArticels & other)\": f\"{recall_non_preprint:.2%}\",\n",
    "        \"Recall (preprints)\": f\"{recall_preprint:.2%}\",\n",
    "        \"Missing Articles\": \"; \".join(missing_non_preprint_titles),\n",
    "        \"Missing Preprint\": \"; \".join(missing_preprint_titles),\n",
    "    }])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8cc855c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define Recall Function\n",
    "# ---------- Normalizers ----------\n",
    "def _first_token(s: str) -> str:\n",
    "    \"\"\"Return the first nonempty token split on common delimiters.\"\"\"\n",
    "    if not isinstance(s, str): \n",
    "        return \"\"\n",
    "    for tok in re.split(r\"[;,|\\s]+\", s.strip()):\n",
    "        if tok:\n",
    "            return tok\n",
    "    return \"\"\n",
    "\n",
    "def normalize_doi(x: str) -> str:\n",
    "    if not isinstance(x, str): \n",
    "        return \"\"\n",
    "    x = _first_token(x).lower()\n",
    "    x = re.sub(r'^(https?://(dx\\.)?doi\\.org/)', '', x)\n",
    "    x = x.replace('\\u200b', '')  # zero-width\n",
    "    return x\n",
    "\n",
    "def normalize_issn(x: str) -> str:\n",
    "    if not isinstance(x, str): \n",
    "        return \"\"\n",
    "    s = _first_token(x)\n",
    "    s = re.sub(r'[^0-9xX]', '', s).upper()\n",
    "    if len(s) == 8:\n",
    "        return s[:4] + \"-\" + s[4:]\n",
    "    return s\n",
    "\n",
    "def normalize_isbn(x: str) -> str:\n",
    "    if not isinstance(x, str): \n",
    "        return \"\"\n",
    "    s = _first_token(x)\n",
    "    s = re.sub(r'[^0-9xX]', '', s).upper()\n",
    "    return s\n",
    "\n",
    "def canonical_title(s: str) -> str:\n",
    "    if not isinstance(s, str): \n",
    "        return \"\"\n",
    "    # strip diacritics\n",
    "    s = unicodedata.normalize(\"NFKD\", s)\n",
    "    s = \"\".join(c for c in s if not unicodedata.combining(c))\n",
    "    # normalize quotes and dashes/hyphens\n",
    "    s = s.replace(\"\", \"'\").replace(\"\", \"'\").replace(\"\", '\"').replace(\"\", '\"')\n",
    "    s = s.replace(\"\", \"-\").replace(\"\", \"-\")\n",
    "    s = s.lower()\n",
    "    # fix known glued tokens (extend as needed)\n",
    "    s = s.replace(\"financialwellbeing\", \"financial wellbeing\")\n",
    "    # remove punctuation except spaces and alphanumerics\n",
    "    s = re.sub(r\"[^a-z0-9\\s]\", \" \", s)\n",
    "    # collapse whitespace\n",
    "    s = re.sub(r\"\\s+\", \" \", s).strip()\n",
    "    return s\n",
    "\n",
    "# ---------- Main ----------\n",
    "def calc_recall_with_missing(res_df,\n",
    "                             gold_df = gold_df,\n",
    "                             gold_cols=dict(doi=\"doi\", issn=\"issn\", isbn=\"isbn\", title=\"Title\"),\n",
    "                             res_cols=dict(doi=\"doi\", issn=\"issn\", isbn=\"isbn\", title=\"title\"),):\n",
    "    \n",
    "    g = gold_df.copy()\n",
    "    r = res_df.copy()\n",
    "\n",
    "    # Build normalized keys\n",
    "    g[\"_doi\"]  = g[gold_cols[\"doi\"]].map(normalize_doi)\n",
    "    r[\"_doi\"]  = r[res_cols[\"doi\"]].map(normalize_doi)\n",
    "\n",
    "    g[\"_issn\"] = g[gold_cols[\"issn\"]].map(normalize_issn)\n",
    "    r[\"_issn\"] = r[res_cols[\"issn\"]].map(normalize_issn)\n",
    "\n",
    "    g[\"_isbn\"] = g[gold_cols[\"isbn\"]].map(normalize_isbn)\n",
    "    r[\"_isbn\"] = r[res_cols[\"isbn\"]].map(normalize_isbn)\n",
    "\n",
    "    g[\"_tkey\"] = g[gold_cols[\"title\"]].map(canonical_title)\n",
    "    r[\"_tkey\"] = r[res_cols[\"title\"]].map(canonical_title)\n",
    "\n",
    "    # Tracking frame\n",
    "    out = g[[gold_cols[\"title\"]]].rename(columns={gold_cols[\"title\"]: \"gold_title\"}).copy()\n",
    "    out[[\"_doi\", \"_issn\", \"_isbn\", \"_tkey\"]] = g[[\"_doi\", \"_issn\", \"_isbn\", \"_tkey\"]]\n",
    "    if \"preprint_flag\" in g.columns:\n",
    "        out[\"preprint_flag\"] = g[\"preprint_flag\"].values\n",
    "    else:\n",
    "        out[\"preprint_flag\"] = pd.NA\n",
    "    out[\"matched_by\"] = pd.NA\n",
    "    out[\"matched_title\"] = pd.NA\n",
    "\n",
    "    def do_join(key: str, label: str):\n",
    "        nonlocal out, r\n",
    "        # work only on still-unmatched and nonempty keys\n",
    "        pending = out[out[\"matched_by\"].isna()]\n",
    "        pending = pending[pending[key].astype(bool)]\n",
    "        if pending.empty:\n",
    "            return\n",
    "\n",
    "        # keep original row ids for round-trip\n",
    "        pending = pending.assign(_row_id=pending.index)\n",
    "\n",
    "        # right side: one row per key\n",
    "        right = r[[res_cols[\"title\"], key]].drop_duplicates().set_index(key)\n",
    "\n",
    "        # left join via key, preserve _row_id\n",
    "        merged = pending.join(right, on=key, how=\"left\")\n",
    "\n",
    "        # rows that found a match on this key\n",
    "        hits = merged[merged[res_cols[\"title\"]].notna()]\n",
    "        if hits.empty:\n",
    "            return\n",
    "\n",
    "        # write back using the saved row ids\n",
    "        out.loc[hits[\"_row_id\"], \"matched_by\"] = label\n",
    "        out.loc[hits[\"_row_id\"], \"matched_title\"] = hits[res_cols[\"title\"]].values\n",
    "\n",
    "    # Match in priority order\n",
    "    do_join(\"_doi\",  \"doi\")\n",
    "    do_join(\"_issn\", \"issn\")\n",
    "    do_join(\"_isbn\", \"isbn\")\n",
    "    do_join(\"_tkey\", \"title_exact\")\n",
    "\n",
    "    # Metrics\n",
    "    matched_mask = out[\"matched_title\"].notna()\n",
    "    tp = out[\"matched_title\"].notna().sum()\n",
    "    fn = out[\"matched_title\"].isna().sum()\n",
    "    denom = tp + fn\n",
    "    recall = tp / denom if denom else 0.0\n",
    "\n",
    "    # Subgroup recalls by preprint flag\n",
    "    pre_mask = out[\"preprint_flag\"].astype(str).str.lower().eq(\"preprint\")\n",
    "    non_pre_mask = out[\"preprint_flag\"].astype(str).str.lower().eq(\"non-preprint\")\n",
    "\n",
    "    pre_tp = (matched_mask & pre_mask).sum()\n",
    "    pre_den = pre_mask.sum()\n",
    "    recall_preprint = (pre_tp / pre_den) if pre_den else 0.0\n",
    "\n",
    "    non_pre_tp = (matched_mask & non_pre_mask).sum()\n",
    "    non_pre_den = non_pre_mask.sum()\n",
    "    recall_non_preprint = (non_pre_tp / non_pre_den) if non_pre_den else 0.0\n",
    "\n",
    "    # Missing titles (avoid reindexing warnings by filtering on `out`)\n",
    "    missing_mask = ~matched_mask\n",
    "    missing_all_titles = out.loc[missing_mask, \"gold_title\"].tolist()\n",
    "    missing_pre_titles = out.loc[missing_mask & pre_mask, \"gold_title\"].tolist()\n",
    "    missing_non_pre_titles = out.loc[missing_mask & non_pre_mask, \"gold_title\"].tolist()\n",
    "\n",
    "    return pd.DataFrame([{\n",
    "        \"Number of Papers Retrieved\": len(res_df),\n",
    "        \"Recall (All)\": f\"{recall:.2%}\",\n",
    "        \"Recall (Journal & Conf. Papers)\": f\"{recall_non_preprint:.2%}\",\n",
    "        \"Recall (Preprints)\": f\"{recall_preprint:.2%}\",\n",
    "        \"Missing Journal & Conf. Papers\": \"; \".join(sorted(missing_non_pre_titles)),\n",
    "        \"Missing Preprints\": \"; \".join(sorted(missing_pre_titles)),\n",
    "    }])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "344af5d5",
   "metadata": {},
   "source": [
    "## Recall Rate - WoS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a39a929",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# Run recall calculations for Full WoS set\n",
    "wos_recall_results = {\n",
    "    \"LLM and Survey\": calc_recall_with_missing(df_WoS_LLM_and_Survey_clean),\n",
    "    \"LLM and Survey and Methods\": calc_recall_with_missing(df_WoS_LLM_and_Survey_and_Methods_clean),\n",
    "    \"LLM and SimulationA\": calc_recall_with_missing(df_WoS_LLM_and_SimulationA_clean),\n",
    "    \"LLM and SimulationB\": calc_recall_with_missing(df_WoS_LLM_and_SimulationB_clean),\n",
    "    \"LLM and SimulationC\": calc_recall_with_missing(df_WoS_LLM_and_SimulationC_clean),\n",
    "    \"LLM and Methods\": calc_recall_with_missing(df_WoS_LLM_and_Methods_clean),\n",
    "    \"LLM and Survey and SimulationA\": calc_recall_with_missing(df_WoS_LLM_and_Survey_and_SimulationA_clean),\n",
    "    \"LLM and Survey and SimulationB\": calc_recall_with_missing(df_WoS_LLM_and_Survey_and_SimulationB_clean),\n",
    "    \"LLM and Survey and SimulationC\": calc_recall_with_missing(df_WoS_LLM_and_Survey_and_SimulationC_clean),\n",
    "    \"LLM and SimulationA and Methods\": calc_recall_with_missing(df_WoS_LLM_and_SimulationA_and_Methods_clean),\n",
    "    \"LLM and SimulationB and Methods\": calc_recall_with_missing(df_WoS_LLM_and_SimulationB_and_Methods_clean),\n",
    "    \"LLM and SimulationC and Methods\": calc_recall_with_missing(df_WoS_LLM_and_SimulationC_and_Methods_clean),\n",
    "    \"LLMSurvey or LLMSimulationA\": calc_recall_with_missing(df_WoS_LLMSurvey_or_LLMSimulationA_clean),\n",
    "    \"LLMSurvey or LLMSimulationB\": calc_recall_with_missing(df_WoS_LLMSurvey_or_LLMSimulationB_clean),\n",
    "    \"LLMSurvey or LLMSimulationC\": calc_recall_with_missing(df_WoS_LLMSurvey_or_LLMSimulationC_clean),\n",
    "    \"Survey and SimulationA\": calc_recall_with_missing(df_WoS_Survey_and_SimulationA_clean),\n",
    "    \"Survey and SimulationB\": calc_recall_with_missing(df_WoS_Survey_and_SimulationB_clean),\n",
    "    \"Survey and SimulationC\": calc_recall_with_missing(df_WoS_Survey_and_SimulationC_clean),\n",
    "}\n",
    "\n",
    "recall_table_WoS = pd.concat(wos_recall_results.values(), \n",
    "                             keys=wos_recall_results.keys()).reset_index(level=1, \n",
    "                             drop=True).reset_index().rename(columns={\"index\": \"Query\"})\n",
    "\n",
    "recall_table_WoS = recall_table_WoS.merge(df_WoS_totals.rename(columns={\"QueryName\": \"Query\", \"TotalRecords\": \"Total Records in WoS\"}),\n",
    "                                          on=\"Query\", how=\"left\")\n",
    "\n",
    "recall_table_WoS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "id": "0722654e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of records in Preprint Papers gold set: 11\n",
      "Number of records in Journals & Conference Articles gold set: 11\n"
     ]
    },
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Query",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Number of Papers Retrieved",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Recall (All)",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Recall (Journal & Conf. Papers)",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Recall (Preprints)",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Missing Journal & Conf. Papers",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Missing Preprints",
         "rawType": "object",
         "type": "string"
        }
       ],
       "ref": "72508727-aca3-4f7a-b064-39cc1e21a176",
       "rows": [
        [
         "0",
         "LLM and SimulationA",
         "823",
         "45.45%",
         "90.91%",
         "0.00%",
         "Knowledge of cultural moral norms in large language models",
         "AI-Augmented Surveys: Leveraging Large Language Models and Surveys for Opinion Prediction; Addressing Systematic Non-response Bias with Supervised Fine-Tuning of Large Language Models: A Case Study on German Voting Behaviour; Are Large Language Models Chameleons? An Attempt to Simulate Social Surveys; Can Large Language Models Simulate Human Responses? A Case Study of Stated Preference Experiments in the Context of Heating-related Choices; Delving Into the Psychology of Machines: Exploring the Structure of Self-Regulated Learning via LLM-Generated Survey Responses; Donald Trumps in the Virtual Polls: Simulating and Predicting Public Opinions in Surveys Using Large Language Models; Examining the Feasibility of Large Language Models as Survey Respondents; More Parameters Than Populations: A Systematic Literature Review of Large Language Models within Survey Research; Questioning the Survey Responses of Large Language Models; Random Silicon Sampling: Simulating Human Sub-Population Opinion Using a Large Language Model Based on Group-Level Demographic Information; The threat of analytic flexibility in using large language models to simulate human data: A call to attention"
        ],
        [
         "1",
         "LLM and SimulationB",
         "2175",
         "50.00%",
         "100.00%",
         "0.00%",
         "",
         "AI-Augmented Surveys: Leveraging Large Language Models and Surveys for Opinion Prediction; Addressing Systematic Non-response Bias with Supervised Fine-Tuning of Large Language Models: A Case Study on German Voting Behaviour; Are Large Language Models Chameleons? An Attempt to Simulate Social Surveys; Can Large Language Models Simulate Human Responses? A Case Study of Stated Preference Experiments in the Context of Heating-related Choices; Delving Into the Psychology of Machines: Exploring the Structure of Self-Regulated Learning via LLM-Generated Survey Responses; Donald Trumps in the Virtual Polls: Simulating and Predicting Public Opinions in Surveys Using Large Language Models; Examining the Feasibility of Large Language Models as Survey Respondents; More Parameters Than Populations: A Systematic Literature Review of Large Language Models within Survey Research; Questioning the Survey Responses of Large Language Models; Random Silicon Sampling: Simulating Human Sub-Population Opinion Using a Large Language Model Based on Group-Level Demographic Information; The threat of analytic flexibility in using large language models to simulate human data: A call to attention"
        ],
        [
         "2",
         "LLM and Survey and SimulationA",
         "445",
         "45.45%",
         "90.91%",
         "0.00%",
         "Knowledge of cultural moral norms in large language models",
         "AI-Augmented Surveys: Leveraging Large Language Models and Surveys for Opinion Prediction; Addressing Systematic Non-response Bias with Supervised Fine-Tuning of Large Language Models: A Case Study on German Voting Behaviour; Are Large Language Models Chameleons? An Attempt to Simulate Social Surveys; Can Large Language Models Simulate Human Responses? A Case Study of Stated Preference Experiments in the Context of Heating-related Choices; Delving Into the Psychology of Machines: Exploring the Structure of Self-Regulated Learning via LLM-Generated Survey Responses; Donald Trumps in the Virtual Polls: Simulating and Predicting Public Opinions in Surveys Using Large Language Models; Examining the Feasibility of Large Language Models as Survey Respondents; More Parameters Than Populations: A Systematic Literature Review of Large Language Models within Survey Research; Questioning the Survey Responses of Large Language Models; Random Silicon Sampling: Simulating Human Sub-Population Opinion Using a Large Language Model Based on Group-Level Demographic Information; The threat of analytic flexibility in using large language models to simulate human data: A call to attention"
        ],
        [
         "3",
         "LLM and Survey and SimulationB",
         "1674",
         "50.00%",
         "100.00%",
         "0.00%",
         "",
         "AI-Augmented Surveys: Leveraging Large Language Models and Surveys for Opinion Prediction; Addressing Systematic Non-response Bias with Supervised Fine-Tuning of Large Language Models: A Case Study on German Voting Behaviour; Are Large Language Models Chameleons? An Attempt to Simulate Social Surveys; Can Large Language Models Simulate Human Responses? A Case Study of Stated Preference Experiments in the Context of Heating-related Choices; Delving Into the Psychology of Machines: Exploring the Structure of Self-Regulated Learning via LLM-Generated Survey Responses; Donald Trumps in the Virtual Polls: Simulating and Predicting Public Opinions in Surveys Using Large Language Models; Examining the Feasibility of Large Language Models as Survey Respondents; More Parameters Than Populations: A Systematic Literature Review of Large Language Models within Survey Research; Questioning the Survey Responses of Large Language Models; Random Silicon Sampling: Simulating Human Sub-Population Opinion Using a Large Language Model Based on Group-Level Demographic Information; The threat of analytic flexibility in using large language models to simulate human data: A call to attention"
        ],
        [
         "4",
         "LLM and SimulationA and Methods",
         "170",
         "27.27%",
         "54.55%",
         "0.00%",
         "Can large language models estimate public opinion about global warming? An empirical assessment of algorithmic fidelity and bias; Knowledge of cultural moral norms in large language models; Out of One, Many: Using Language Models to Simulate Human Samples; Performance and biases of Large Language Models in public opinion simulation; Synthetic Replacements for Human Survey Data? The Perils of Large Language Models",
         "AI-Augmented Surveys: Leveraging Large Language Models and Surveys for Opinion Prediction; Addressing Systematic Non-response Bias with Supervised Fine-Tuning of Large Language Models: A Case Study on German Voting Behaviour; Are Large Language Models Chameleons? An Attempt to Simulate Social Surveys; Can Large Language Models Simulate Human Responses? A Case Study of Stated Preference Experiments in the Context of Heating-related Choices; Delving Into the Psychology of Machines: Exploring the Structure of Self-Regulated Learning via LLM-Generated Survey Responses; Donald Trumps in the Virtual Polls: Simulating and Predicting Public Opinions in Surveys Using Large Language Models; Examining the Feasibility of Large Language Models as Survey Respondents; More Parameters Than Populations: A Systematic Literature Review of Large Language Models within Survey Research; Questioning the Survey Responses of Large Language Models; Random Silicon Sampling: Simulating Human Sub-Population Opinion Using a Large Language Model Based on Group-Level Demographic Information; The threat of analytic flexibility in using large language models to simulate human data: A call to attention"
        ],
        [
         "5",
         "LLM and SimulationB and Methods",
         "330",
         "40.91%",
         "81.82%",
         "0.00%",
         "Can large language models estimate public opinion about global warming? An empirical assessment of algorithmic fidelity and bias; Performance and biases of Large Language Models in public opinion simulation",
         "AI-Augmented Surveys: Leveraging Large Language Models and Surveys for Opinion Prediction; Addressing Systematic Non-response Bias with Supervised Fine-Tuning of Large Language Models: A Case Study on German Voting Behaviour; Are Large Language Models Chameleons? An Attempt to Simulate Social Surveys; Can Large Language Models Simulate Human Responses? A Case Study of Stated Preference Experiments in the Context of Heating-related Choices; Delving Into the Psychology of Machines: Exploring the Structure of Self-Regulated Learning via LLM-Generated Survey Responses; Donald Trumps in the Virtual Polls: Simulating and Predicting Public Opinions in Surveys Using Large Language Models; Examining the Feasibility of Large Language Models as Survey Respondents; More Parameters Than Populations: A Systematic Literature Review of Large Language Models within Survey Research; Questioning the Survey Responses of Large Language Models; Random Silicon Sampling: Simulating Human Sub-Population Opinion Using a Large Language Model Based on Group-Level Demographic Information; The threat of analytic flexibility in using large language models to simulate human data: A call to attention"
        ]
       ],
       "shape": {
        "columns": 7,
        "rows": 6
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Query</th>\n",
       "      <th>Number of Papers Retrieved</th>\n",
       "      <th>Recall (All)</th>\n",
       "      <th>Recall (Journal &amp; Conf. Papers)</th>\n",
       "      <th>Recall (Preprints)</th>\n",
       "      <th>Missing Journal &amp; Conf. Papers</th>\n",
       "      <th>Missing Preprints</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LLM and SimulationA</td>\n",
       "      <td>823</td>\n",
       "      <td>45.45%</td>\n",
       "      <td>90.91%</td>\n",
       "      <td>0.00%</td>\n",
       "      <td>Knowledge of cultural moral norms in large lan...</td>\n",
       "      <td>AI-Augmented Surveys: Leveraging Large Languag...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>LLM and SimulationB</td>\n",
       "      <td>2175</td>\n",
       "      <td>50.00%</td>\n",
       "      <td>100.00%</td>\n",
       "      <td>0.00%</td>\n",
       "      <td></td>\n",
       "      <td>AI-Augmented Surveys: Leveraging Large Languag...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>LLM and Survey and SimulationA</td>\n",
       "      <td>445</td>\n",
       "      <td>45.45%</td>\n",
       "      <td>90.91%</td>\n",
       "      <td>0.00%</td>\n",
       "      <td>Knowledge of cultural moral norms in large lan...</td>\n",
       "      <td>AI-Augmented Surveys: Leveraging Large Languag...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>LLM and Survey and SimulationB</td>\n",
       "      <td>1674</td>\n",
       "      <td>50.00%</td>\n",
       "      <td>100.00%</td>\n",
       "      <td>0.00%</td>\n",
       "      <td></td>\n",
       "      <td>AI-Augmented Surveys: Leveraging Large Languag...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>LLM and SimulationA and Methods</td>\n",
       "      <td>170</td>\n",
       "      <td>27.27%</td>\n",
       "      <td>54.55%</td>\n",
       "      <td>0.00%</td>\n",
       "      <td>Can large language models estimate public opin...</td>\n",
       "      <td>AI-Augmented Surveys: Leveraging Large Languag...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>LLM and SimulationB and Methods</td>\n",
       "      <td>330</td>\n",
       "      <td>40.91%</td>\n",
       "      <td>81.82%</td>\n",
       "      <td>0.00%</td>\n",
       "      <td>Can large language models estimate public opin...</td>\n",
       "      <td>AI-Augmented Surveys: Leveraging Large Languag...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             Query  Number of Papers Retrieved Recall (All)  \\\n",
       "0              LLM and SimulationA                         823       45.45%   \n",
       "1              LLM and SimulationB                        2175       50.00%   \n",
       "2   LLM and Survey and SimulationA                         445       45.45%   \n",
       "3   LLM and Survey and SimulationB                        1674       50.00%   \n",
       "4  LLM and SimulationA and Methods                         170       27.27%   \n",
       "5  LLM and SimulationB and Methods                         330       40.91%   \n",
       "\n",
       "  Recall (Journal & Conf. Papers) Recall (Preprints)  \\\n",
       "0                          90.91%              0.00%   \n",
       "1                         100.00%              0.00%   \n",
       "2                          90.91%              0.00%   \n",
       "3                         100.00%              0.00%   \n",
       "4                          54.55%              0.00%   \n",
       "5                          81.82%              0.00%   \n",
       "\n",
       "                      Missing Journal & Conf. Papers  \\\n",
       "0  Knowledge of cultural moral norms in large lan...   \n",
       "1                                                      \n",
       "2  Knowledge of cultural moral norms in large lan...   \n",
       "3                                                      \n",
       "4  Can large language models estimate public opin...   \n",
       "5  Can large language models estimate public opin...   \n",
       "\n",
       "                                   Missing Preprints  \n",
       "0  AI-Augmented Surveys: Leveraging Large Languag...  \n",
       "1  AI-Augmented Surveys: Leveraging Large Languag...  \n",
       "2  AI-Augmented Surveys: Leveraging Large Languag...  \n",
       "3  AI-Augmented Surveys: Leveraging Large Languag...  \n",
       "4  AI-Augmented Surveys: Leveraging Large Languag...  \n",
       "5  AI-Augmented Surveys: Leveraging Large Languag...  "
      ]
     },
     "execution_count": 289,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Run recall calculations for Subset WoS set\n",
    "wos_recall_results_subset = {\n",
    "    \"LLM and SimulationA\": calc_recall_with_missing(df_WoS_LLM_and_SimulationA),\n",
    "    \"LLM and SimulationB\": calc_recall_with_missing(df_WoS_LLM_and_SimulationB),\n",
    "    \"LLM and Survey and SimulationA\": calc_recall_with_missing(df_WoS_LLM_and_Survey_and_SimulationA),\n",
    "    \"LLM and Survey and SimulationB\": calc_recall_with_missing(df_WoS_LLM_and_Survey_and_SimulationB),\n",
    "    \"LLM and SimulationA and Methods\": calc_recall_with_missing(df_WoS_LLM_and_SimulationA_and_Methods),\n",
    "    \"LLM and SimulationB and Methods\": calc_recall_with_missing(df_WoS_LLM_and_SimulationB_and_Methods),\n",
    "}\n",
    "\n",
    "recall_table_WoS_subset = pd.concat(wos_recall_results_subset.values(), \n",
    "                                   keys=wos_recall_results_subset.keys()).reset_index(level=1, drop=True).reset_index().rename(columns={\"index\": \"Query\"})\n",
    "\n",
    "print(f\"Number of records in Preprint Papers gold set: {len(gold_preprint_set)}\")\n",
    "print(f\"Number of records in Journals & Conference Articles gold set: {len(gold_non_preprint_set)}\")\n",
    "recall_table_WoS_subset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "id": "5fddbd9d-9f20-40a3-9b6f-f7687c94e02a",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Comparison of Missing Journal Articles between 'LLM and Survey and SimulationA' and 'LLM and SimulationA':\n",
      "\n",
      "ONly Missing in 'LLM and Survey and SimulationA' (0 articles):\n",
      "\n",
      "Only Missing in 'LLM and SimulationA' (0 articles):\n",
      "\n",
      "Missing In both (1 articles):\n",
      " - Knowledge of cultural moral norms in large language models\n"
     ]
    }
   ],
   "source": [
    "# Define function: compare_missing_journal_articles\n",
    "def compare_missing_journal_articles(df_recall, query1, query2):\n",
    "    row1 = df_recall[df_recall[\"Query\"] == query1]\n",
    "    row2 = df_recall[df_recall[\"Query\"] == query2]\n",
    "\n",
    "    # print error for missing queries\n",
    "    if row1.empty:\n",
    "        print(f\"Error: Query '{query1}' not found in the recall table.\")\n",
    "        return None\n",
    "    if row2.empty:\n",
    "        print(f\"Error: Query '{query2}' not found in the recall table.\")\n",
    "        return None\n",
    "    \n",
    "    missing1 = set(row1.iloc[0][\"Missing Journal & Conf. Papers\"].split(\"; \")) if pd.notna(row1.iloc[0][\"Missing Journal & Conf. Papers\"]) else set()\n",
    "    missing2 = set(row2.iloc[0][\"Missing Journal & Conf. Papers\"].split(\"; \")) if pd.notna(row2.iloc[0][\"Missing Journal & Conf. Papers\"]) else set()\n",
    "    \n",
    "    only_in_1 = missing1 - missing2\n",
    "    only_in_2 = missing2 - missing1\n",
    "    in_both = missing1.intersection(missing2)\n",
    "    \n",
    "    # output them in a bullet points like\n",
    "    print(f\"Comparison of Missing Journal Articles between '{query1}' and '{query2}':\\n\")\n",
    "    print(f\"ONly Missing in '{query1}' ({len(only_in_1)} articles):\")\n",
    "    for title in sorted(only_in_1):\n",
    "        print(f\" - {title}\")    \n",
    "    print(f\"\\nOnly Missing in '{query2}' ({len(only_in_2)} articles):\")\n",
    "    for title in sorted(only_in_2):\n",
    "        print(f\" - {title}\")\n",
    "    print(f\"\\nMissing In both ({len(in_both)} articles):\")\n",
    "    for title in sorted(in_both):\n",
    "        print(f\" - {title}\")\n",
    "\n",
    "compare_missing_journal_articles(recall_table_WoS_subset,\n",
    "                                 \"LLM and Survey and SimulationA\", \"LLM and SimulationA\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ce8ae5c",
   "metadata": {},
   "source": [
    "## Recall Rate - Scholar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "098b6770",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_SS_llm_svy       = main(\"ss_llm_and_survey\")\n",
    "\n",
    "df_SS_llm_simA      = main(\"ss_llm_and_simA\")\n",
    "df_SS_llm_simB      = main(\"ss_llm_and_simB\")\n",
    "df_SS_llm_simC      = main(\"ss_llm_and_simC\")\n",
    "\n",
    "df_SS_llm_svy_simA  = main(\"ss_llm_survey_simA\")\n",
    "df_SS_llm_svy_simB  = main(\"ss_llm_survey_simB\")\n",
    "df_SS_llm_svy_simC  = main(\"ss_llm_survey_simC\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e1684f2",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df_SS_g1' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[29]\u001b[39m\u001b[32m, line 6\u001b[39m\n\u001b[32m      1\u001b[39m recall_summary_SS = []\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m label, dframe \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(\n\u001b[32m      3\u001b[39m     [\u001b[33m\"\u001b[39m\u001b[33mLLM Terms\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mSurvey Terms\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mSimulation Terms\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m      4\u001b[39m      \u001b[33m\"\u001b[39m\u001b[33mLLM + Survey Terms\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mSurvey + Simulation Terms\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mLLM + Simulation Terms\u001b[39m\u001b[33m\"\u001b[39m, \n\u001b[32m      5\u001b[39m      \u001b[33m\"\u001b[39m\u001b[33mAll Terms\u001b[39m\u001b[33m\"\u001b[39m],\n\u001b[32m----> \u001b[39m\u001b[32m6\u001b[39m     [\u001b[43mdf_SS_g1\u001b[49m, df_SS_g2, df_SS_g3, df_SS_g4, df_SS_g5, df_SS_g6, df_SS_g7]\n\u001b[32m      7\u001b[39m ):\n\u001b[32m      8\u001b[39m     stats = calc_recall(dframe, \n\u001b[32m      9\u001b[39m                         gold_norm_set, \n\u001b[32m     10\u001b[39m                         gold_preprint_set, \n\u001b[32m     11\u001b[39m                         gold_non_preprint_set)\n\u001b[32m     13\u001b[39m     stats[\u001b[33m\"\u001b[39m\u001b[33mSearch Group\u001b[39m\u001b[33m\"\u001b[39m] = label\n",
      "\u001b[31mNameError\u001b[39m: name 'df_SS_g1' is not defined"
     ]
    }
   ],
   "source": [
    "recall_summary_SS = []\n",
    "for label, dframe in zip(\n",
    "    [\"LLM Terms\", \"Survey Terms\", \"Simulation Terms\",\n",
    "     \"LLM + Survey Terms\", \"Survey + Simulation Terms\", \"LLM + Simulation Terms\", \n",
    "     \"All Terms\"],\n",
    "    [ss_llm_and_survey, df_SS_g2, df_SS_g3, df_SS_g4, df_SS_g5, df_SS_g6, df_SS_g7]\n",
    "):\n",
    "    stats = calc_recall(dframe, \n",
    "                        gold_norm_set, \n",
    "                        gold_preprint_set, \n",
    "                        gold_non_preprint_set)\n",
    "    \n",
    "    stats[\"Search Group\"] = label\n",
    "    recall_summary_SS.append(stats)\n",
    "    \n",
    "recall_table_SS = pd.DataFrame(recall_summary_SS)[[\"Search Group\", \"Number of Papers Retrieved\", \"Recall (out of 21)\", \"Recall (journalArticels & other)\", \"Recall (preprints)\"]]\n",
    "recall_table_SS[\"Number of Papers Retrieved\"] = recall_table_SS[\"Number of Papers Retrieved\"].astype(int)\n",
    "recall_table_SS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17743eaf",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Title",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "preprint_flag",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Abstract",
         "rawType": "object",
         "type": "string"
        }
       ],
       "ref": "ea208f71-2591-4f42-8ff2-514951c908f0",
       "rows": [
        [
         "0",
         "Out of One, Many: Using Language Models to Simulate Human Samples",
         "non-preprint",
         "We propose and explore the possibility that language models can be studied as effective proxies for specific human subpopulations in social science research. Practical and research applications of artificial intelligence tools have sometimes been limited by problematic biases (such as racism or sexism), which are often treated as uniform properties of the models. We show that the algorithmic bias within one such toolthe GPT-3 language modelis instead both fine-grained and demographically correlated, meaning that proper conditioning will cause it to accurately emulate response distributions from a wide variety of human subgroups. We term this property algorithmic fidelity and explore its extent in GPT-3. We create silicon samples by conditioning the model on thousands of sociodemographic backstories from real human participants in multiple large surveys conducted in the United States. We then compare the silicon and human samples to demonstrate that the information contained in GPT-3 goes far beyond surface similarity. It is nuanced, multifaceted, and reflects the complex interplay between ideas, attitudes, and sociocultural context that characterize human attitudes. We suggest that language models with sufficient algorithmic fidelity thus constitute a novel and powerful tool to advance understanding of humans and society across a variety of disciplines."
        ],
        [
         "1",
         "AIHuman Hybrids for Marketing Research: Leveraging Large Language Models (LLMs) as Collaborators",
         "non-preprint",
         "The authors central premise is that a humanLLM (large language model) hybrid approach leads to efficiency and effectiveness gains in the marketing research process. In qualitative research, they show that LLMs can assist in both data generation and analysis; LLMs effectively create sample characteristics, generate synthetic respondents, and conduct and moderate in-depth interviews. The AIhuman hybrid generates information-rich, coherent data that surpasses human-only data in depth and insightfulness and matches human performance in data analysis tasks of generating themes and summaries. Evidence from expert judges shows that humans and LLMs possess complementary skills; the humanLLM hybrid outperforms its human-only or LLM-only counterpart. For quantitative research, the LLM correctly picks the answer direction and valence, with the quality of synthetic data significantly improving through few-shot learning and retrieval-augmented generation. The authors demonstrate the value of the AIhuman hybrid by collaborating with a Fortune 500 food company and replicating a 2019 qualitative and quantitative study using GPT-4. For their empirical investigation, the authors design the system architecture and prompts to create personas, ask questions, and obtain responses from synthetic respondents. They provide road maps for integrating LLMs into qualitative and quantitative marketing research and conclude that LLMs serve as valuable collaborators in the insight generation process."
        ],
        [
         "2",
         "Extracting Affect Aggregates from Longitudinal Social Media Data with Temporal Adapters for Large Language Models",
         "non-preprint",
         "This paper proposes temporally aligned Large Language Models (LLMs) as a tool for longitudinal analysis of social media data. We fine-tune Temporal Adapters for Llama 3 8B on full timelines from a panel of British Twitter users and extract longitudinal aggregates of emotions and attitudes with established questionnaires. We focus our analysis on the beginning of the COVID-19 pandemic that had a strong impact on public opinion and collective emotions. We validate our estimates against representative British survey data and find strong positive and significant correlations for several collective emotions. The estimates obtained are robust across multiple training seeds and prompt formulations, and in line with collective emotions extracted using a traditional classification model trained on labeled data. We demonstrate the flexibility of our method on questions of public opinion for which no pre-trained classifier is available. Our work extends the analysis of affect in LLMs to a longitudinal setting through Temporal Adapters. It enables flexible and new approaches to the longitudinal analysis of social media data."
        ],
        [
         "3",
         "Vox Populi, Vox AI? Using Large Language Models to Estimate German Vote Choice",
         "non-preprint",
         "Synthetic samples generated by large language models (LLMs) have been argued to complement or replace traditional surveys, assuming their training data is grounded in human-generated data that potentially reflects attitudes and behaviors prevalent in the population. Initial US-based studies that have prompted LLMs to mimic survey respondents found that the responses match survey data. However, the relationship between the respective target population and LLM training data might affect the generalizability of such findings. In this paper, we critically evaluate the use of LLMs for public opinion research in a different context, by investigating whether LLMs can estimate vote choice in Germany. We generate a synthetic sample matching the 2017 German Longitudinal Election Study respondents and ask the LLM GPT-3.5 to predict each respondents vote choice. Comparing these predictions to the survey-based estimates on the aggregate and subgroup levels, we find that GPT-3.5 exhibits a bias towards the Green and Left parties. While the LLM predictions capture the tendencies of typical voters, they miss more complex factors of vote choice. By examining the LLM-based prediction of voting behavior in a non-English speaking context, our study contributes to research on the extent to which LLMs can be leveraged for studying public opinion. The findings point to disparities in opinion representation in LLMs and underscore the limitations in applying them for public opinion estimation."
        ],
        [
         "4",
         "The Potential and Challenges of Evaluating Attitudes, Opinions, and Values in Large Language Models",
         "non-preprint",
         "Recent advances in Large Language Models (LLMs) have sparked wide interest in validating and comprehending the human-like cognitive-behavioral traits LLMs may capture and convey. These cognitive-behavioral traits include typically Attitudes, Opinions, Values (AOVs). However, measuring AOVs embedded within LLMs remains opaque, and different evaluation methods may yield different results. This has led to a lack of clarity on how different studies are related to each other and how they can be interpreted. This paper aims to bridge this gap by providing a comprehensive overview of recent works on the evaluation of AOVs in LLMs. Moreover, we survey related approaches in different stages of the evaluation pipeline in these works. By doing so, we address the potential and challenges with respect to understanding the model, human-AI alignment, and downstream application in social sciences. Finally, we provide practical insights into evaluation methods, model enhancement, and interdisciplinary collaboration, thereby contributing to the evolving landscape of evaluating AOVs in LLMs."
        ]
       ],
       "shape": {
        "columns": 3,
        "rows": 5
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>preprint_flag</th>\n",
       "      <th>Abstract</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Out of One, Many: Using Language Models to Sim...</td>\n",
       "      <td>non-preprint</td>\n",
       "      <td>We propose and explore the possibility that la...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AIHuman Hybrids for Marketing Research: Lever...</td>\n",
       "      <td>non-preprint</td>\n",
       "      <td>The authors central premise is that a humanL...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Extracting Affect Aggregates from Longitudinal...</td>\n",
       "      <td>non-preprint</td>\n",
       "      <td>This paper proposes temporally aligned Large L...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Vox Populi, Vox AI? Using Large Language Model...</td>\n",
       "      <td>non-preprint</td>\n",
       "      <td>Synthetic samples generated by large languag...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The Potential and Challenges of Evaluating Att...</td>\n",
       "      <td>non-preprint</td>\n",
       "      <td>Recent advances in Large Language Models (LLMs...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Title preprint_flag  \\\n",
       "0  Out of One, Many: Using Language Models to Sim...  non-preprint   \n",
       "1  AIHuman Hybrids for Marketing Research: Lever...  non-preprint   \n",
       "2  Extracting Affect Aggregates from Longitudinal...  non-preprint   \n",
       "3  Vox Populi, Vox AI? Using Large Language Model...  non-preprint   \n",
       "4  The Potential and Challenges of Evaluating Att...  non-preprint   \n",
       "\n",
       "                                            Abstract  \n",
       "0  We propose and explore the possibility that la...  \n",
       "1  The authors central premise is that a humanL...  \n",
       "2  This paper proposes temporally aligned Large L...  \n",
       "3  Synthetic samples generated by large languag...  \n",
       "4  Recent advances in Large Language Models (LLMs...  "
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# I want to see the list of papers from the gold list that were not found in df_SS_g7\n",
    "df_SS_g7_norms = set(df_SS_g7[\"title\"].map(normalize_title))\n",
    "missing_norms = gold_norm_set - df_SS_g7_norms \n",
    "missing_titles = [gold_norm_to_orig[n] for n in missing_norms]\n",
    "missing_preprint_flags = [gold_norm_to_preprint_flag[n] for n in missing_norms]\n",
    "missing_df = pd.DataFrame({\n",
    "    \"Title\": missing_titles,\n",
    "    \"preprint_flag\": missing_preprint_flags\n",
    "})\n",
    "\n",
    "# filter for non-preprints only\n",
    "missing_df = missing_df[missing_df[\"preprint_flag\"] == \"non-preprint\"].reset_index(drop=True)\n",
    "\n",
    "# add in the abstracts from the gold list into the respective rows of missing_df\n",
    "missing_df = missing_df.merge(gold_df[[\"Title\", \"Abstract Note\"]], on=\"Title\", how=\"left\")\n",
    "missing_df = missing_df.rename(columns={\"Abstract Note\": \"Abstract\"})\n",
    "missing_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce0e0197",
   "metadata": {},
   "source": [
    "## Recall Rate - ArXiV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a64af17a",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "recall_summary = []\n",
    "for label, dframe in zip(\n",
    "    [\"Simulation Block + Survey Block\", \"LLM Block + Survey Block\", \"All Blocks\"],\n",
    "    [df_sim_survey, df_llm_survey, df_all_blocks]\n",
    "):\n",
    "    stats = calc_recall(dframe, \n",
    "                        gold_norm_set, \n",
    "                        gold_preprint_set, \n",
    "                        gold_non_preprint_set)\n",
    "    \n",
    "    stats[\"Search Block\"] = label\n",
    "    recall_summary.append(stats)\n",
    "\n",
    "recall_table = pd.DataFrame(recall_summary)[[\"Search Block\", \"Number of Papers Retrieved\", \"Recall (out of 21)\", \"Recall (journalArticels & other)\", \"Recall (preprints)\"]]\n",
    "recall_table[\"Number of Papers Retrieved\"] = recall_table[\"Number of Papers Retrieved\"].astype(int)\n",
    "recall_table"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e785080a",
   "metadata": {},
   "source": [
    "## Recall Rate - Elicit A.I."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "81be8852",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# Load Elicit A.I. Search Results (Elicit prompt 1.csv to Elicit prompt 4.csv) each into their respective dataframe\n",
    "df_Elicit1 = pd.read_csv(\"data/Elicit prompt 1.csv\")\n",
    "df_Elicit2 = pd.read_csv(\"data/Elicit prompt 2.csv\")\n",
    "df_Elicit3 = pd.read_csv(\"data/Elicit prompt 3.csv\")\n",
    "df_Elicit4 = pd.read_csv(\"data/Elicit prompt 4.csv\")\n",
    "\n",
    "# rename all Title to title\n",
    "df_Elicit1 = df_Elicit1.rename(columns={\"Title\": \"title\"})\n",
    "df_Elicit2 = df_Elicit2.rename(columns={\"Title\": \"title\"})\n",
    "df_Elicit3 = df_Elicit3.rename(columns={\"Title\": \"title\"})\n",
    "df_Elicit4 = df_Elicit4.rename(columns={\"Title\": \"title\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "3ee5098c",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Are Large Language Models Chameleons? An Attempt to Simulate Social Surveys',\n",
       " 'Can Large Language Models Capture Public Opinion about Global Warming? An Empirical Assessment of Algorithmic Fidelity and Bias',\n",
       " 'Do LLMs Exhibit Human-like Response Biases? A Case Study in Survey Design',\n",
       " 'Donald Trumps in the Virtual Polls: Simulating and Predicting Public Opinions in Surveys Using Large Language Models',\n",
       " 'Evaluating the Moral Beliefs Encoded in LLMs',\n",
       " 'Examining the Feasibility of Large Language Models as Survey Respondents',\n",
       " 'Frontiers: Can Large Language Models Capture Human Preferences?',\n",
       " 'Human Preferences in Large Language Model Latent Space: A Technical Analysis on the Reliability of Synthetic Data in Voting Outcome Prediction',\n",
       " 'Large Language Models Show Human-like Social Desirability Biases in Survey Responses',\n",
       " 'Large Language Models as Subpopulation Representative Models: A Review',\n",
       " 'Large language models display human-like social desirability biases in Big Five personality surveys',\n",
       " 'Llms, Virtual Users, and Bias: Predicting Any Survey Question Without Human Data',\n",
       " 'Out of One, Many: Using Language Models to Simulate Human Samples',\n",
       " 'Prompt Perturbations Reveal Human-Like Biases in LLM Survey Responses',\n",
       " 'Questioning the Survey Responses of Large Language Models',\n",
       " 'Synthetic Replacements for Human Survey Data? The Perils of Large Language Models',\n",
       " 'Towards Measuring the Representation of Subjective Global Opinions in Language Models',\n",
       " 'Using GPT for Market Research',\n",
       " 'Whose Opinions Do Language Models Reflect?'}"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The list of papers that exist in all four Elicit dataframe df1 to df4\n",
    "common_titles = set(df_Elicit1[\"title\"]).intersection(set(df_Elicit2[\"title\"])).intersection(set(df_Elicit3[\"title\"])).intersection(set(df_Elicit4[\"title\"]))\n",
    "common_titles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ceac95fd",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Query",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Number of Papers Retrieved",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Recall (out of 21)",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Recall (journalArticels & other)",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Recall (preprints)",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Missing Articles",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Missing Preprint",
         "rawType": "object",
         "type": "string"
        }
       ],
       "ref": "82bfd0c4-e064-4680-84e2-a670646690f3",
       "rows": [
        [
         "0",
         "Elicit Prompt 1",
         "104",
         "42.86%",
         "27.27%",
         "60.00%",
         "AIHuman Hybrids for Marketing Research: Leveraging Large Language Models (LLMs) as Collaborators; Algorithmic Fidelity of Large Language Models in Generating Synthetic German Public Opinions: A Case Study; Extracting Affect Aggregates from Longitudinal Social Media Data with Temporal Adapters for Large Language Models; Knowledge of cultural moral norms in large language models; Predicting Missing Values in Survey Data Using Prompt Engineering for Addressing Item Non-Response; Synthetic Voices: Evaluating the Fidelity of LLM-Generated Personas in Representing Peoples Financial Wellbeing; The Potential and Challenges of Evaluating Attitudes, Opinions, and Values in Large Language Models; Vox Populi, Vox AI? Using Large Language Models to Estimate German Vote Choice",
         "Addressing Systematic Non-response Bias with Supervised Fine-Tuning of Large Language Models: A Case Study on German Voting Behaviour; Can Large Language Models Simulate Human Responses? A Case Study of Stated Preference Experiments in the Context of Heating-related Choices; Delving Into the Psychology of Machines: Exploring the Structure of Self-Regulated Learning via LLM-Generated Survey Responses; More Parameters Than Populations: A Systematic Literature Review of Large Language Models within Survey Research"
        ],
        [
         "1",
         "Elicit Prompt 2",
         "104",
         "42.86%",
         "27.27%",
         "60.00%",
         "AIHuman Hybrids for Marketing Research: Leveraging Large Language Models (LLMs) as Collaborators; Algorithmic Fidelity of Large Language Models in Generating Synthetic German Public Opinions: A Case Study; Extracting Affect Aggregates from Longitudinal Social Media Data with Temporal Adapters for Large Language Models; Knowledge of cultural moral norms in large language models; Predicting Missing Values in Survey Data Using Prompt Engineering for Addressing Item Non-Response; Synthetic Voices: Evaluating the Fidelity of LLM-Generated Personas in Representing Peoples Financial Wellbeing; The Potential and Challenges of Evaluating Attitudes, Opinions, and Values in Large Language Models; Vox Populi, Vox AI? Using Large Language Models to Estimate German Vote Choice",
         "Addressing Systematic Non-response Bias with Supervised Fine-Tuning of Large Language Models: A Case Study on German Voting Behaviour; Can Large Language Models Simulate Human Responses? A Case Study of Stated Preference Experiments in the Context of Heating-related Choices; Delving Into the Psychology of Machines: Exploring the Structure of Self-Regulated Learning via LLM-Generated Survey Responses; More Parameters Than Populations: A Systematic Literature Review of Large Language Models within Survey Research"
        ],
        [
         "2",
         "Elicit Prompt 3",
         "104",
         "42.86%",
         "36.36%",
         "50.00%",
         "AIHuman Hybrids for Marketing Research: Leveraging Large Language Models (LLMs) as Collaborators; Algorithmic Fidelity of Large Language Models in Generating Synthetic German Public Opinions: A Case Study; Extracting Affect Aggregates from Longitudinal Social Media Data with Temporal Adapters for Large Language Models; Knowledge of cultural moral norms in large language models; Predicting Missing Values in Survey Data Using Prompt Engineering for Addressing Item Non-Response; The Potential and Challenges of Evaluating Attitudes, Opinions, and Values in Large Language Models; Vox Populi, Vox AI? Using Large Language Models to Estimate German Vote Choice",
         "Addressing Systematic Non-response Bias with Supervised Fine-Tuning of Large Language Models: A Case Study on German Voting Behaviour; Can Large Language Models Simulate Human Responses? A Case Study of Stated Preference Experiments in the Context of Heating-related Choices; Delving Into the Psychology of Machines: Exploring the Structure of Self-Regulated Learning via LLM-Generated Survey Responses; More Parameters Than Populations: A Systematic Literature Review of Large Language Models within Survey Research; Random Silicon Sampling: Simulating Human Sub-Population Opinion Using a Large Language Model Based on Group-Level Demographic Information"
        ],
        [
         "3",
         "Elicit Prompt 4",
         "104",
         "33.33%",
         "18.18%",
         "50.00%",
         "AIHuman Hybrids for Marketing Research: Leveraging Large Language Models (LLMs) as Collaborators; Algorithmic Fidelity of Large Language Models in Generating Synthetic German Public Opinions: A Case Study; Extracting Affect Aggregates from Longitudinal Social Media Data with Temporal Adapters for Large Language Models; Knowledge of cultural moral norms in large language models; LLM-Based Doppelgnger Models: Leveraging Synthetic Data for Human-Like Responses in Survey Simulations; Predicting Missing Values in Survey Data Using Prompt Engineering for Addressing Item Non-Response; Synthetic Voices: Evaluating the Fidelity of LLM-Generated Personas in Representing Peoples Financial Wellbeing; The Potential and Challenges of Evaluating Attitudes, Opinions, and Values in Large Language Models; Vox Populi, Vox AI? Using Large Language Models to Estimate German Vote Choice",
         "Addressing Systematic Non-response Bias with Supervised Fine-Tuning of Large Language Models: A Case Study on German Voting Behaviour; AI-Augmented Surveys: Leveraging Large Language Models and Surveys for Opinion Prediction; Can Large Language Models Simulate Human Responses? A Case Study of Stated Preference Experiments in the Context of Heating-related Choices; Delving Into the Psychology of Machines: Exploring the Structure of Self-Regulated Learning via LLM-Generated Survey Responses; More Parameters Than Populations: A Systematic Literature Review of Large Language Models within Survey Research"
        ]
       ],
       "shape": {
        "columns": 7,
        "rows": 4
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Query</th>\n",
       "      <th>Number of Papers Retrieved</th>\n",
       "      <th>Recall (out of 21)</th>\n",
       "      <th>Recall (journalArticels &amp; other)</th>\n",
       "      <th>Recall (preprints)</th>\n",
       "      <th>Missing Articles</th>\n",
       "      <th>Missing Preprint</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Elicit Prompt 1</td>\n",
       "      <td>104</td>\n",
       "      <td>42.86%</td>\n",
       "      <td>27.27%</td>\n",
       "      <td>60.00%</td>\n",
       "      <td>AIHuman Hybrids for Marketing Research: Lever...</td>\n",
       "      <td>Addressing Systematic Non-response Bias with S...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Elicit Prompt 2</td>\n",
       "      <td>104</td>\n",
       "      <td>42.86%</td>\n",
       "      <td>27.27%</td>\n",
       "      <td>60.00%</td>\n",
       "      <td>AIHuman Hybrids for Marketing Research: Lever...</td>\n",
       "      <td>Addressing Systematic Non-response Bias with S...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Elicit Prompt 3</td>\n",
       "      <td>104</td>\n",
       "      <td>42.86%</td>\n",
       "      <td>36.36%</td>\n",
       "      <td>50.00%</td>\n",
       "      <td>AIHuman Hybrids for Marketing Research: Lever...</td>\n",
       "      <td>Addressing Systematic Non-response Bias with S...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Elicit Prompt 4</td>\n",
       "      <td>104</td>\n",
       "      <td>33.33%</td>\n",
       "      <td>18.18%</td>\n",
       "      <td>50.00%</td>\n",
       "      <td>AIHuman Hybrids for Marketing Research: Lever...</td>\n",
       "      <td>Addressing Systematic Non-response Bias with S...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Query  Number of Papers Retrieved Recall (out of 21)  \\\n",
       "0  Elicit Prompt 1                         104             42.86%   \n",
       "1  Elicit Prompt 2                         104             42.86%   \n",
       "2  Elicit Prompt 3                         104             42.86%   \n",
       "3  Elicit Prompt 4                         104             33.33%   \n",
       "\n",
       "  Recall (journalArticels & other) Recall (preprints)  \\\n",
       "0                           27.27%             60.00%   \n",
       "1                           27.27%             60.00%   \n",
       "2                           36.36%             50.00%   \n",
       "3                           18.18%             50.00%   \n",
       "\n",
       "                                    Missing Articles  \\\n",
       "0  AIHuman Hybrids for Marketing Research: Lever...   \n",
       "1  AIHuman Hybrids for Marketing Research: Lever...   \n",
       "2  AIHuman Hybrids for Marketing Research: Lever...   \n",
       "3  AIHuman Hybrids for Marketing Research: Lever...   \n",
       "\n",
       "                                    Missing Preprint  \n",
       "0  Addressing Systematic Non-response Bias with S...  \n",
       "1  Addressing Systematic Non-response Bias with S...  \n",
       "2  Addressing Systematic Non-response Bias with S...  \n",
       "3  Addressing Systematic Non-response Bias with S...  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# calculate recall for df_Elicit1, df_Elicit2, df_Elicit3, df_Elicit4 dataframes with missing titles\n",
    "elicit_recall_results = {\n",
    "    \"Elicit Prompt 1\": calc_recall_with_missing(df_Elicit1, gold_norm_set, gold_preprint_set, gold_non_preprint_set, gold_norm_to_orig),\n",
    "    \"Elicit Prompt 2\": calc_recall_with_missing(df_Elicit2, gold_norm_set, gold_preprint_set, gold_non_preprint_set, gold_norm_to_orig),\n",
    "    \"Elicit Prompt 3\": calc_recall_with_missing(df_Elicit3, gold_norm_set, gold_preprint_set, gold_non_preprint_set, gold_norm_to_orig),\n",
    "    \"Elicit Prompt 4\": calc_recall_with_missing(df_Elicit4, gold_norm_set, gold_preprint_set, gold_non_preprint_set, gold_norm_to_orig),\n",
    "} \n",
    "\n",
    "recall_table_Elicit = pd.concat(elicit_recall_results.values(), keys=elicit_recall_results.keys()).reset_index(level=1, drop=True).reset_index().rename(columns={\"index\": \"Query\"})\n",
    "recall_table_Elicit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86c4337d",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Must pass 2-d input. shape=(4, 1, 7)",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[26]\u001b[39m\u001b[32m, line 18\u001b[39m\n\u001b[32m     14\u001b[39m     stats[\u001b[33m\"\u001b[39m\u001b[33mSearch Prompt\u001b[39m\u001b[33m\"\u001b[39m] = label\n\u001b[32m     15\u001b[39m     recall_summary_Elicit.append(stats)\n\u001b[32m---> \u001b[39m\u001b[32m18\u001b[39m recall_table_Elicit = \u001b[43mpd\u001b[49m\u001b[43m.\u001b[49m\u001b[43mDataFrame\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrecall_summary_Elicit\u001b[49m\u001b[43m)\u001b[49m[[\u001b[33m\"\u001b[39m\u001b[33mSearch Prompt\u001b[39m\u001b[33m\"\u001b[39m, \n\u001b[32m     19\u001b[39m                                                            \u001b[33m\"\u001b[39m\u001b[33mNumber of Papers Retrieved\u001b[39m\u001b[33m\"\u001b[39m, \n\u001b[32m     20\u001b[39m                                                            \u001b[33m\"\u001b[39m\u001b[33mRecall (out of 21)\u001b[39m\u001b[33m\"\u001b[39m, \n\u001b[32m     21\u001b[39m                                                            \u001b[33m\"\u001b[39m\u001b[33mRecall (journalArticels & other)\u001b[39m\u001b[33m\"\u001b[39m, \n\u001b[32m     22\u001b[39m                                                            \u001b[33m\"\u001b[39m\u001b[33mRecall (preprints)\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mMissing Articles\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mMissing Preprint\u001b[39m\u001b[33m\"\u001b[39m]]\n\u001b[32m     24\u001b[39m recall_table_Elicit[\u001b[33m\"\u001b[39m\u001b[33mNumber of Papers Retrieved\u001b[39m\u001b[33m\"\u001b[39m] = recall_table_Elicit[\u001b[33m\"\u001b[39m\u001b[33mNumber of Papers Retrieved\u001b[39m\u001b[33m\"\u001b[39m].astype(\u001b[38;5;28mint\u001b[39m)\n\u001b[32m     25\u001b[39m recall_table_Elicit\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\chanho\\Documents\\AIRESIL\\.venv\\Lib\\site-packages\\pandas\\core\\frame.py:867\u001b[39m, in \u001b[36mDataFrame.__init__\u001b[39m\u001b[34m(self, data, index, columns, dtype, copy)\u001b[39m\n\u001b[32m    859\u001b[39m         mgr = arrays_to_mgr(\n\u001b[32m    860\u001b[39m             arrays,\n\u001b[32m    861\u001b[39m             columns,\n\u001b[32m   (...)\u001b[39m\u001b[32m    864\u001b[39m             typ=manager,\n\u001b[32m    865\u001b[39m         )\n\u001b[32m    866\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m867\u001b[39m         mgr = \u001b[43mndarray_to_mgr\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    868\u001b[39m \u001b[43m            \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    869\u001b[39m \u001b[43m            \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    870\u001b[39m \u001b[43m            \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    871\u001b[39m \u001b[43m            \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    872\u001b[39m \u001b[43m            \u001b[49m\u001b[43mcopy\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    873\u001b[39m \u001b[43m            \u001b[49m\u001b[43mtyp\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmanager\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    874\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    875\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    876\u001b[39m     mgr = dict_to_mgr(\n\u001b[32m    877\u001b[39m         {},\n\u001b[32m    878\u001b[39m         index,\n\u001b[32m   (...)\u001b[39m\u001b[32m    881\u001b[39m         typ=manager,\n\u001b[32m    882\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\chanho\\Documents\\AIRESIL\\.venv\\Lib\\site-packages\\pandas\\core\\internals\\construction.py:319\u001b[39m, in \u001b[36mndarray_to_mgr\u001b[39m\u001b[34m(values, index, columns, dtype, copy, typ)\u001b[39m\n\u001b[32m    314\u001b[39m     values = _ensure_2d(values)\n\u001b[32m    316\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    317\u001b[39m     \u001b[38;5;66;03m# by definition an array here\u001b[39;00m\n\u001b[32m    318\u001b[39m     \u001b[38;5;66;03m# the dtypes will be coerced to a single dtype\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m319\u001b[39m     values = \u001b[43m_prep_ndarraylike\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcopy_on_sanitize\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    321\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m dtype \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m values.dtype != dtype:\n\u001b[32m    322\u001b[39m     \u001b[38;5;66;03m# GH#40110 see similar check inside sanitize_array\u001b[39;00m\n\u001b[32m    323\u001b[39m     values = sanitize_array(\n\u001b[32m    324\u001b[39m         values,\n\u001b[32m    325\u001b[39m         \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m   (...)\u001b[39m\u001b[32m    328\u001b[39m         allow_2d=\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[32m    329\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\chanho\\Documents\\AIRESIL\\.venv\\Lib\\site-packages\\pandas\\core\\internals\\construction.py:582\u001b[39m, in \u001b[36m_prep_ndarraylike\u001b[39m\u001b[34m(values, copy)\u001b[39m\n\u001b[32m    579\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    580\u001b[39m     values = convert(values)\n\u001b[32m--> \u001b[39m\u001b[32m582\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_ensure_2d\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\chanho\\Documents\\AIRESIL\\.venv\\Lib\\site-packages\\pandas\\core\\internals\\construction.py:592\u001b[39m, in \u001b[36m_ensure_2d\u001b[39m\u001b[34m(values)\u001b[39m\n\u001b[32m    590\u001b[39m     values = values.reshape((values.shape[\u001b[32m0\u001b[39m], \u001b[32m1\u001b[39m))\n\u001b[32m    591\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m values.ndim != \u001b[32m2\u001b[39m:\n\u001b[32m--> \u001b[39m\u001b[32m592\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mMust pass 2-d input. shape=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mvalues.shape\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m    593\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m values\n",
      "\u001b[31mValueError\u001b[39m: Must pass 2-d input. shape=(4, 1, 7)"
     ]
    }
   ],
   "source": [
    "# calculate recall rates for each dataframe and summarize in a table\n",
    "recall_summary_Elicit = []\n",
    "for label, dframe in zip( [\"Elicit Prompt 1\", \"Elicit Prompt 2\", \"Elicit Prompt 3\", \"Elicit Prompt 4\"],\n",
    "                          [df_Elicit1, df_Elicit2, df_Elicit3, df_Elicit4]):\n",
    "    \n",
    "    # calculate recall with missing titles\n",
    "\n",
    "    stats = calc_recall(dframe, \n",
    "                        gold_norm_set, \n",
    "                        gold_preprint_set, \n",
    "                        gold_non_preprint_set)\n",
    "    \n",
    "    stats[\"Search Prompt\"] = label\n",
    "    recall_summary_Elicit.append(stats)\n",
    "\n",
    "\n",
    "recall_table_Elicit = pd.DataFrame(recall_summary_Elicit)[[\"Search Prompt\", \"Number of Papers Retrieved\", \n",
    "                                                           \"Recall (out of 21)\", \"Recall (journalArticels & other)\", \"Recall (preprints)\"]]\n",
    "recall_table_Elicit[\"Number of Papers Retrieved\"] = recall_table_Elicit[\"Number of Papers Retrieved\"].astype(int)\n",
    "recall_table_Elicit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae276d18-246f-4814-a02f-a387ddf8fd98",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "id": "5cddbda8",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Publication Type",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Authors",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Book Authors",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Book Editors",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "Book Group Authors",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "Author Full Names",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Book Author Full Names",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Group Authors",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "title",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Source Title",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Book Series Title",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Book Series Subtitle",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Language",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Document Type",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Conference Title",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Conference Date",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Conference Location",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Conference Sponsor",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Conference Host",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Author Keywords",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Keywords Plus",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Abstract",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Addresses",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Affiliations",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Reprint Addresses",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Email Addresses",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Researcher Ids",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "ORCIDs",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Funding Orgs",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Funding Name Preferred",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Funding Text",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Cited References",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Cited Reference Count",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Times Cited, WoS Core",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Times Cited, All Databases",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "180 Day Usage Count",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Since 2013 Usage Count",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Publisher",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Publisher City",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Publisher Address",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "ISSN",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "eISSN",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "ISBN",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Journal Abbreviation",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Journal ISO Abbreviation",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Publication Date",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Publication Year",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Volume",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Issue",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Part Number",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Supplement",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Special Issue",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Meeting Abstract",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Start Page",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "End Page",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Article Number",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "DOI",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "DOI Link",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Book DOI",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Early Access Date",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Number of Pages",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "WoS Categories",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Web of Science Index",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Research Areas",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "IDS Number",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Pubmed Id",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Open Access Designations",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Highly Cited Status",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Hot Paper Status",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Date of Export",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "UT (Unique WOS ID)",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Web of Science Record",
         "rawType": "int64",
         "type": "integer"
        }
       ],
       "ref": "10b1f1a9-279f-43b9-a481-a821d441f468",
       "rows": [
        [
         "0",
         "C",
         "Kaiser, C; Kaiser, J; Manewitsch, V; Rau, L; Schallner, R",
         null,
         null,
         "ACM",
         "Kaiser, Carolin; Kaiser, Jakob; Manewitsch, Vladimir; Rau, Lea; Schallner, Rene",
         null,
         null,
         "Simulating Human Opinions with Large Language Models",
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         "0"
        ],
        [
         "1",
         "J",
         "Ferreira, G; Amidei, J; Nieto, R; Kaltenbrunner, A",
         null,
         null,
         null,
         "Ferreira, Gregorio; Amidei, Jacopo; Nieto, Ruben; Kaltenbrunner, Andreas",
         null,
         null,
         "How Well Do Simulated Population Samples with GPT-4 Align with Real Ones? The Case of the Eysenck Personality Questionnaire Revised-Abbreviated Personality Test",
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         "0"
        ],
        [
         "2",
         "C",
         "Kane, D; Parke, J; Jo, Y; Bak, J",
         null,
         "Bouamor, H; Pino, J; Bali, K",
         null,
         "Kane, Dongjun; Parke, JoonSuk; Jo, Yohan; Bak, JinYeong",
         null,
         null,
         "From Values to Opinions: Predicting Human Behaviors and Stances Using Value-Injected Large Language Models",
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         "0"
        ],
        [
         "3",
         "J",
         "Arora, N; Chakraborty, I; Nishimura, Y",
         null,
         null,
         null,
         "Arora, Neeraj; Chakraborty, Ishita; Nishimura, Yohei",
         null,
         null,
         "AI-Human Hybrids for Marketing Research: Leveraging Large Language Models (LLMs) as Collaborators",
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         "0"
        ],
        [
         "4",
         "J",
         "Antal, M; Beder, N",
         null,
         null,
         null,
         "Antal, Margit; Beder, Norbert",
         null,
         null,
         "Eysenck Personality Questionnaire: A Comparative Study of Humans and Large Language Models Through Repeated Administrations",
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         "0"
        ],
        [
         "5",
         "J",
         "Bisbee, J; Clinton, JD; Dorff, C; Kenkel, B; Larson, JM",
         null,
         null,
         null,
         "Bisbee, James; Clinton, Joshua D.; Dorff, Cassy; Kenkel, Brenton; Larson, Jennifer M.",
         null,
         null,
         "Synthetic Replacements for Human Survey Data? The Perils of Large Language Models",
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         "0"
        ],
        [
         "6",
         "J",
         "Liu, HJ; Cao, Y; Wu, X; Qiu, C; Gu, JG; Liu, MF; Hershcovich, D",
         null,
         null,
         null,
         "Liu, Haijiang; Cao, Yong; Wu, Xun; Qiu, Chen; Gu, Jinguang; Liu, Maofu; Hershcovich, Daniel",
         null,
         null,
         "Towards realistic evaluation of cultural value alignment in large language models: Diversity enhancement for survey response simulation",
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         "0"
        ],
        [
         "7",
         "J",
         "Lee, SG; Peng, TQ; Goldberg, MH; Rosenthal, SA; Kotcher, JE; Maibach, EW; Leiserowitz, A",
         null,
         null,
         null,
         "Lee, Sanguk; Peng, Tai-Quan; Goldberg, Matthew H.; Rosenthal, Seth A.; Kotcher, John E.; Maibach, Edward W.; Leiserowitz, Anthony",
         null,
         null,
         "Can large language models estimate public opinion about global warming? An empirical assessment of algorithmic fidelity and bias",
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         "0"
        ],
        [
         "8",
         "J",
         "Boelaert, J; Coavoux, S; Ollion, E; Petev, I; Prg, P",
         null,
         null,
         null,
         "Boelaert, Julien; Coavoux, Samuel; Ollion, Etienne; Petev, Ivaylo; Prag, Patrick",
         null,
         null,
         "Machine Bias. How Do Generative Language Models Answer Opinion Polls?",
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         "0"
        ],
        [
         "9",
         "J",
         "Qu, Y; Wang, J",
         null,
         null,
         null,
         "Qu, Yao; Wang, Jue",
         null,
         null,
         "Performance and biases of Large Language Models in public opinion simulation",
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         "0"
        ],
        [
         "10",
         "C",
         "Gao, S; Gao, BL; Wei, P; Guo, JP; Yuan, M; Han, C; Xu, YY",
         null,
         "Xiao, X; Yao, J",
         null,
         "Gao, Song; Gao, Bolin; Wei, Peng; Guo, Jianpeng; Yuan, Meng; Han, Cheng; Xu, Yueyun",
         null,
         null,
         "Application of foundation models for autonomous driving: a survey of data synthesis",
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         "0"
        ],
        [
         "11",
         "C",
         "Nguyen, H; Nguyen, V; Lpez-Fierro, S; Ludovise, S; Santagata, R",
         null,
         null,
         "ASSOC COMPUTING MACHINERY",
         "Ha Nguyen; Nguyen, Victoria; Lopez-Fierro, Sariah; Ludovise, Sara; Santagata, Rossella",
         null,
         null,
         "Simulating Climate Change Discussion with Large Language Models: Considerations for Science Communication at Scale",
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         "0"
        ],
        [
         "12",
         "J",
         "Alonso, SLN; Ozili, PK; Hernndez, BMS; Pacheco, LM",
         null,
         null,
         null,
         "Alonso, Sergio Luis Nanez; Ozili, Peterson K.; Hernandez, Beatriz Maria Sastre; Pacheco, Luis Miguel",
         null,
         null,
         "Evaluating the acceptance of CBDCs: experimental research with artificial intelligence (AI) generated synthetic response",
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         "0"
        ],
        [
         "13",
         "J",
         "Salecha, A; Ireland, ME; Subrahmanya, S; Sedoc, J; Ungar, LH; Eichstaedt, JC",
         null,
         null,
         null,
         "Salecha, Aadesh; Ireland, Molly E.; Subrahmanya, Shashanka; Sedoc, Joao; Ungar, Lyle H.; Eichstaedt, Johannes C.",
         null,
         null,
         "Large language models display human-like social desirability biases in Big Five personality surveys",
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         "0"
        ],
        [
         "14",
         "J",
         "Lehtonen, E; Buder-Grndahl, T; Nordhoff, S",
         null,
         null,
         null,
         "Lehtonen, Esko; Buder-Grondahl, Tommi; Nordhoff, Sina",
         null,
         null,
         "Revealing the Influence of Semantic Similarity on Survey Responses: A Synthetic Data Generation Approach",
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         "0"
        ],
        [
         "15",
         "J",
         "Yao, JC; Zhang, HJ; Ou, J; Zuo, DY; Yang, Z; Dong, ZC",
         null,
         null,
         null,
         "Yao, Junchi; Zhang, Hongjie; Ou, Jie; Zuo, Dingyi; Yang, Zheng; Dong, Zhicheng",
         null,
         null,
         "Social opinions prediction utilizes fusing dynamics equation with LLM-based agents",
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         "0"
        ],
        [
         "16",
         "C",
         "Hmlinen, P; Tavast, M; Kunnari, A",
         null,
         null,
         "ACM",
         "Hamalainen, Perttu; Tavast, Mikke; Kunnari, Anton",
         null,
         null,
         "Evaluating Large Language Models in Generating Synthetic HCI Research Data: a Case Study",
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         "0"
        ],
        [
         "17",
         "J",
         "Zhang, S; Xu, J; Alvero, AJ",
         null,
         null,
         null,
         "Zhang, Simone; Xu, Janet; Alvero, A. J.",
         null,
         null,
         "Generative AI Meets Open-Ended Survey Responses: Research Participant Use of AI and Homogenization",
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         "0"
        ],
        [
         "18",
         "J",
         "Zhang, BY; Chen, T; Wang, X; Li, Q; Zhang, WS; Wang, FY",
         null,
         null,
         null,
         "Zhang, Baoyu; Chen, Tao; Wang, Xiao; Li, Qiang; Zhang, Weishan; Wang, Fei-Yue",
         null,
         null,
         "Decoding Activist Public Opinion in Decentralized Self-Organized Protests Using LLM",
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         "0"
        ],
        [
         "19",
         "J",
         "von der Heyde, L; Haensch, AC; Wenz, A",
         null,
         null,
         null,
         "von der Heyde, Leah; Haensch, Anna-Carolina; Wenz, Alexander",
         null,
         null,
         "Vox Populi, Vox AI? Using Large Language Models to Estimate German Vote Choice",
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         "0"
        ],
        [
         "20",
         "J",
         "Gao, C; Lan, XC; Li, N; Yuan, Y; Ding, JT; Zhou, ZL; Xu, FL; Li, Y",
         null,
         null,
         null,
         "Gao, Chen; Lan, Xiaochong; Li, Nian; Yuan, Yuan; Ding, Jingtao; Zhou, Zhilun; Xu, Fengli; Li, Yong",
         null,
         null,
         "Large language models empowered agent-based modeling and simulation: a survey and perspectives",
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         "0"
        ],
        [
         "21",
         "C",
         "Tan, Z; Li, DW; Wang, S; Beigi, A; Jiang, BH; Bhattacharjee, A; Karami, M; Li, JD; Cheng, L; Liu, H",
         null,
         "Al-Onaizan, Y; Bansal, M; Chen, YN",
         null,
         "Tan, Zhen; Li, Dawei; Wang, Song; Beigi, Alimohammad; Jiang, Bohan; Bhattacharjee, Amrita; Karami, Mansooreh; Li, Jundong; Cheng, Lu; Liu, Huan",
         null,
         null,
         "Large Language Models for Data Annotation and Synthesis: A Survey",
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         "0"
        ],
        [
         "22",
         "J",
         "Jung, SG; Salminen, J; Aldous, KK; Jansen, BJ",
         null,
         null,
         null,
         "Jung, Soon-Gyo; Salminen, Joni; Aldous, Kholoud Khalil; Jansen, Bernard J.",
         null,
         null,
         "PersonaCraft: Leveraging language models for data-driven persona development",
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         "0"
        ],
        [
         "23",
         "J",
         "Cho, S; Kim, J; Kim, JH",
         null,
         null,
         null,
         "Cho, Suhyun; Kim, Jaeyun; Kim, Jang Hyun",
         null,
         null,
         "LLM-Based Doppelganger Models: Leveraging Synthetic Data for Human-Like Responses in Survey Simulations",
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         "0"
        ],
        [
         "24",
         "C",
         "Kaur, A; Aird, A; Borman, H; Nicastro, A; Leontjeva, A; Pizzato, L; Jermyn, D",
         null,
         null,
         "ACM",
         "Kaur, Arshnoor; Aird, Amanda; Borman, Harris; Nicastro, Andrea; Leontjeva, Anna; Pizzato, Luiz; Jermyn, Dan",
         null,
         null,
         "Synthetic Voices: Evaluating the Fidelity of LLM-Generated Personas in Representing People's FinancialWellbeing",
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         "0"
        ],
        [
         "25",
         "J",
         "Ding, GZ; Liu, ZR; Li, S; Cao, J; Ye, ZH",
         null,
         null,
         null,
         "Ding, Guozhu; Liu, Zuer; Li, Shan; Cao, Jie; Ye, Zhuohai",
         null,
         null,
         "Impact of mindset types and social community compositions on opinion dynamics: A large language model-based multi-agent simulation study",
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         "0"
        ],
        [
         "26",
         "C",
         "AlKhamissi, B; ElNokrashy, M; AlKhamissi, M; Diab, M",
         null,
         "Ku, LW; Martins, A; Srikumar, V",
         null,
         "AlKhamissi, Badr; ElNokrashy, Muhammad; AlKhamissi, Mai; Diab, Mona",
         null,
         null,
         "Investigating Cultural Alignment of Large Language Models",
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         "0"
        ],
        [
         "27",
         "J",
         "Zhao, XJ; Wang, H; Dai, CX; Tang, JC; Deng, KX; Zhong, ZH; Kong, FY; Wang, SY; Morikawa, S",
         null,
         null,
         null,
         "Zhao, Xinjie; Wang, Hao; Dai, Chengxiao; Tang, Jiacheng; Deng, Kaixin; Zhong, Zhihua; Kong, Fanying; Wang, Shiyun; Morikawa, So",
         null,
         null,
         "Multi-Stage Simulation of Residents' Disaster Risk Perception and Decision-Making Behavior: An Exploratory Study on Large Language Model-Driven Social-Cognitive Agent Framework",
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         "0"
        ],
        [
         "28",
         "J",
         "de Winter, JCF; Driessen, T; Dodou, D",
         null,
         null,
         null,
         "de Winter, Joost C. F.; Driessen, Tom; Dodou, Dimitra",
         null,
         null,
         "The use of ChatGPT for personality research: Administering questionnaires using generated personas",
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         "0"
        ],
        [
         "29",
         "C",
         "Brasoveanu, AMP; Scharl, A; Nixon, LJB; Andonie, R",
         null,
         "Banissi, E; Datia, N; Pires, JM; Ursyn, A; Nazemi, K; Kovalerchuk, B; Andonie, R; Gavrilova, M; Nakayama, M; Nguyen, QV; Mabakane, MS; Rusu, A; Sciarrone, F; Temperini, M; Bouali, F; Venturini, G; Huang, T",
         null,
         "Brasoveanu, Adrian M. P.; Scharl, Arno; Nixon, Lyndon J. B.; Andonie, Razvan",
         null,
         null,
         "Visualizing Large Language Models: A Brief Survey",
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         "0"
        ],
        [
         "30",
         "J",
         "Rakovics, Z; Rakovics, M",
         null,
         null,
         null,
         "Rakovics, Zsofia; Rakovics, Marton",
         null,
         null,
         "Exploring the potential and limitations of large language models as virtual respondents for social science research",
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         "0"
        ],
        [
         "31",
         "C",
         "Omata, M; Shimizu, A",
         null,
         "Ardito, C; Lanzilotti, R; Malizia, A; Petrie, H; Piccinno, A; Desolda, G; Inkpen, K",
         null,
         "Omata, Masaki; Shimizu, Atsuki",
         null,
         null,
         "A Proposal for Discreet Auxiliary Figures for Reducing VR Sickness and for Not Obstructing FOV",
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         "0"
        ],
        [
         "32",
         "J",
         "Leung, HW; Bovy, J",
         null,
         null,
         null,
         "Leung, Henry W.; Bovy, Jo",
         null,
         null,
         "Towards an astronomical foundation model for stars with a transformer-based model",
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         "0"
        ],
        [
         "33",
         "J",
         "Mburu, TK; Rong, KX; McColley, CJ; Werth, A",
         null,
         null,
         null,
         "Mburu, Ted K.; Rong, Kangxuan; McColley, Campbell J.; Werth, Alexandra",
         null,
         null,
         "Methodological foundations for artificial intelligence-driven survey question generation",
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         "0"
        ],
        [
         "34",
         "C",
         "Li, YH; Wang, SF; Ding, H; Chen, H",
         null,
         null,
         "ACM",
         "Li, Yinheng; Wang, Shaofei; Ding, Han; Chen, Hang",
         null,
         null,
         "Large Language Models in Finance: A Survey",
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         "0"
        ],
        [
         "35",
         "J",
         "Timothy, TR",
         null,
         null,
         null,
         "Timothy, Tyrese Raku",
         null,
         null,
         "AI-driven fabrication of healthcare survey data: methods, motivations, and ethical implications",
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         "0"
        ],
        [
         "36",
         "J",
         "Zhang, KH; Dong, CQ; Guo, YF; Zhou, W; Yu, G; Mi, JN",
         null,
         null,
         null,
         "Zhang, Kaihang; Dong, Changqi; Guo, Yifeng; Zhou, Wuai; Yu, Guang; Mi, Jianing",
         null,
         null,
         "Lagged Stance Interactions and Counter-Spiral of Silence: A Data-Driven Analysis and Agent-Based Modeling of Technical Public Opinion Events",
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         "0"
        ],
        [
         "37",
         "C",
         "Zhao, XX; Qiu, Y",
         null,
         "Rau, PLP",
         null,
         "Zhao, Xiaoxuan; Qiu, Yue",
         null,
         null,
         "Insight Through Dialogue: A Practical Exploration of AIGC in Cross-cultural Design Research",
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         "0"
        ],
        [
         "38",
         "J",
         "Zhang, ZC; Wu, HN; Zhang, EL; Zhai, GT; Lin, WS",
         null,
         null,
         null,
         "Zhang, Zicheng; Wu, Haoning; Zhang, Erli; Zhai, Guangtao; Lin, Weisi",
         null,
         null,
         "Q-BENCH+: A Benchmark for Multi-Modal Foundation Models on Low-Level Vision From Single Images to Pairs",
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         "0"
        ],
        [
         "39",
         "J",
         "Campos, M; Farinhas, A; Zerva, C; Figueiredo, MAT; Martins, AFT",
         null,
         null,
         null,
         "Campos, Margarida; Farinhas, Antonio; Zerva, Chrysoula; Figueiredo, Mario A. T.; Martins, Andre F. T.",
         null,
         null,
         "Conformal Prediction for Natural Language Processing: A Survey",
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         "0"
        ],
        [
         "40",
         "J",
         "Wilden, J; Riley, RH",
         null,
         null,
         null,
         "Wilden, J; Riley, RH",
         null,
         null,
         "Personal digital assistant (PDA) use amongst anaesthetists: An Australian survey",
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         "0"
        ],
        [
         "41",
         "J",
         "Zheng, JY; Wang, X; Hosio, S; Xu, XX; Lee, LH",
         null,
         null,
         null,
         "Zheng, Jingyao; Wang, Xian; Hosio, Simo; Xu, Xiaoxian; Lee, Lik-Hang",
         null,
         null,
         "LMLPA: Language Model Linguistic Personality Assessment",
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         "0"
        ],
        [
         "42",
         "C",
         "Cheng, M; Piccardi, T; Yang, DY",
         null,
         "Bouamor, H; Pino, J; Bali, K",
         null,
         "Cheng, Myra; Piccardi, Tiziano; Yang, Diyi",
         null,
         null,
         "CoMPosT: Characterizing and Evaluating Caricature in LLM Simulations",
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         "0"
        ],
        [
         "43",
         "C",
         "Dobre, SC; Popescu, E",
         null,
         null,
         "IEEE",
         "Dobre, Stefania-Carmen; Popescu, Elvira",
         null,
         null,
         "Exploring Students' Perception and Experience with ChatGPT and Critical Thinking in a Higher Education Context",
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         "0"
        ],
        [
         "44",
         "J",
         "Kaur, A; Budko, A; Liu, K; Eaton, E; Steitz, BD; Johnson, KB",
         null,
         null,
         null,
         "Kaur, Amarpreet; Budko, Alexander; Liu, Katrina; Eaton, Eric; Steitz, Bryan D.; Johnson, Kevin B.",
         null,
         null,
         "Automating Responses to Patient Portal Messages Using Generative AI",
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         "0"
        ],
        [
         "45",
         "J",
         "Ji, J; Kim, J; Kim, Y",
         null,
         null,
         null,
         "Ji, Junyung; Kim, Jiwoo; Kim, Younghoon",
         null,
         null,
         "Predicting Missing Values in Survey Data Using Prompt Engineering for Addressing Item Non-Response",
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         "0"
        ],
        [
         "46",
         "J",
         "Cisar, P",
         null,
         null,
         null,
         "Cisar, Peter",
         null,
         null,
         "The Place and Role of Honeypot Solutions in Network Intrusion Detection Systems",
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         "0"
        ],
        [
         "47",
         "J",
         "Goli, A; Singh, A",
         null,
         null,
         null,
         "Goli, Ali; Singh, Amandeep",
         null,
         null,
         "Frontiers: Can Large Language Models Capture Human Preferences?",
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         "0"
        ],
        [
         "48",
         "C",
         "Zhao, RB; Xie, ZW; Zhuang, YP; Li, HX; Yu, PLH",
         null,
         "Kashihara, A; Jiang, B; Rodrigo, MM; Sugay, JO",
         null,
         "Zhao, Ruibin; Xie, Zhiwei; Zhuang, Yipeng; Li, Huixian; Yu, Philip L. H.",
         null,
         null,
         "Enhancing Language Learning Through Multimodal AI-Driven Feedback on Picture Descriptions: An Eye-Tracking Study",
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         "0"
        ],
        [
         "49",
         "J",
         "Hur, JK; Heffner, J; Feng, GW; Joormann, J; Rutledge, RB",
         null,
         null,
         null,
         "Hur, Jihyun K.; Heffner, Joseph; Feng, Gloria W.; Joormann, Jutta; Rutledge, Robb B.",
         null,
         null,
         "Language sentiment predicts changes in depressive symptoms",
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         "0"
        ]
       ],
       "shape": {
        "columns": 72,
        "rows": 124
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Publication Type</th>\n",
       "      <th>Authors</th>\n",
       "      <th>Book Authors</th>\n",
       "      <th>Book Editors</th>\n",
       "      <th>Book Group Authors</th>\n",
       "      <th>Author Full Names</th>\n",
       "      <th>Book Author Full Names</th>\n",
       "      <th>Group Authors</th>\n",
       "      <th>title</th>\n",
       "      <th>Source Title</th>\n",
       "      <th>...</th>\n",
       "      <th>Web of Science Index</th>\n",
       "      <th>Research Areas</th>\n",
       "      <th>IDS Number</th>\n",
       "      <th>Pubmed Id</th>\n",
       "      <th>Open Access Designations</th>\n",
       "      <th>Highly Cited Status</th>\n",
       "      <th>Hot Paper Status</th>\n",
       "      <th>Date of Export</th>\n",
       "      <th>UT (Unique WOS ID)</th>\n",
       "      <th>Web of Science Record</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>C</td>\n",
       "      <td>Kaiser, C; Kaiser, J; Manewitsch, V; Rau, L; S...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ACM</td>\n",
       "      <td>Kaiser, Carolin; Kaiser, Jakob; Manewitsch, Vl...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Simulating Human Opinions with Large Language ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>J</td>\n",
       "      <td>Ferreira, G; Amidei, J; Nieto, R; Kaltenbrunne...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Ferreira, Gregorio; Amidei, Jacopo; Nieto, Rub...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>How Well Do Simulated Population Samples with ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>C</td>\n",
       "      <td>Kane, D; Parke, J; Jo, Y; Bak, J</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Bouamor, H; Pino, J; Bali, K</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Kane, Dongjun; Parke, JoonSuk; Jo, Yohan; Bak,...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>From Values to Opinions: Predicting Human Beha...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>J</td>\n",
       "      <td>Arora, N; Chakraborty, I; Nishimura, Y</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Arora, Neeraj; Chakraborty, Ishita; Nishimura,...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>AI-Human Hybrids for Marketing Research: Lever...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>J</td>\n",
       "      <td>Antal, M; Beder, N</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Antal, Margit; Beder, Norbert</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Eysenck Personality Questionnaire: A Comparati...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119</th>\n",
       "      <td>J</td>\n",
       "      <td>Moscoso, V; Albernaz, AL; Salomao, RDP</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Moscoso, Valdenice; Albernaz, Ana Luisa; Salom...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Niche modelling for twelve plant species (six ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>120</th>\n",
       "      <td>J</td>\n",
       "      <td>Domenach, P; Krause, KR; Malmartel, A; Ravaud,...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Domenach, Paul; Krause, Karolin R.; Malmartel,...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Identifying psychosocial and contextual marker...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>121</th>\n",
       "      <td>J</td>\n",
       "      <td>Lim, MC; Lukman, KA; Giloi, N; Lim, JF; Salleh...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Lim, Mei Ching; Lukman, Khamisah Awang; Giloi,...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Landscaping Work: Work-related Musculoskeletal...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122</th>\n",
       "      <td>J</td>\n",
       "      <td>King, RJ; Cordon-Rosales, C; Cox, J; Davies, C...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>King, Raymond J.; Cordon-Rosales, Celia; Cox, ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Triatoma dimidiata Infestation in Chagas Disea...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>123</th>\n",
       "      <td>J</td>\n",
       "      <td>BOROSON, TA; SALZER, JJ; TROTTER, A</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>BOROSON, TA; SALZER, JJ; TROTTER, A</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>A NEW SURVEY FOR LOW-LUMINOSITY EMISSION-LINE ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>124 rows  72 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Publication Type                                            Authors  \\\n",
       "0                  C  Kaiser, C; Kaiser, J; Manewitsch, V; Rau, L; S...   \n",
       "1                  J  Ferreira, G; Amidei, J; Nieto, R; Kaltenbrunne...   \n",
       "2                  C                   Kane, D; Parke, J; Jo, Y; Bak, J   \n",
       "3                  J             Arora, N; Chakraborty, I; Nishimura, Y   \n",
       "4                  J                                 Antal, M; Beder, N   \n",
       "..               ...                                                ...   \n",
       "119                J             Moscoso, V; Albernaz, AL; Salomao, RDP   \n",
       "120                J  Domenach, P; Krause, KR; Malmartel, A; Ravaud,...   \n",
       "121                J  Lim, MC; Lukman, KA; Giloi, N; Lim, JF; Salleh...   \n",
       "122                J  King, RJ; Cordon-Rosales, C; Cox, J; Davies, C...   \n",
       "123                J                BOROSON, TA; SALZER, JJ; TROTTER, A   \n",
       "\n",
       "     Book Authors                  Book Editors Book Group Authors  \\\n",
       "0             NaN                           NaN                ACM   \n",
       "1             NaN                           NaN                NaN   \n",
       "2             NaN  Bouamor, H; Pino, J; Bali, K                NaN   \n",
       "3             NaN                           NaN                NaN   \n",
       "4             NaN                           NaN                NaN   \n",
       "..            ...                           ...                ...   \n",
       "119           NaN                           NaN                NaN   \n",
       "120           NaN                           NaN                NaN   \n",
       "121           NaN                           NaN                NaN   \n",
       "122           NaN                           NaN                NaN   \n",
       "123           NaN                           NaN                NaN   \n",
       "\n",
       "                                     Author Full Names  \\\n",
       "0    Kaiser, Carolin; Kaiser, Jakob; Manewitsch, Vl...   \n",
       "1    Ferreira, Gregorio; Amidei, Jacopo; Nieto, Rub...   \n",
       "2    Kane, Dongjun; Parke, JoonSuk; Jo, Yohan; Bak,...   \n",
       "3    Arora, Neeraj; Chakraborty, Ishita; Nishimura,...   \n",
       "4                        Antal, Margit; Beder, Norbert   \n",
       "..                                                 ...   \n",
       "119  Moscoso, Valdenice; Albernaz, Ana Luisa; Salom...   \n",
       "120  Domenach, Paul; Krause, Karolin R.; Malmartel,...   \n",
       "121  Lim, Mei Ching; Lukman, Khamisah Awang; Giloi,...   \n",
       "122  King, Raymond J.; Cordon-Rosales, Celia; Cox, ...   \n",
       "123                BOROSON, TA; SALZER, JJ; TROTTER, A   \n",
       "\n",
       "     Book Author Full Names  Group Authors  \\\n",
       "0                       NaN            NaN   \n",
       "1                       NaN            NaN   \n",
       "2                       NaN            NaN   \n",
       "3                       NaN            NaN   \n",
       "4                       NaN            NaN   \n",
       "..                      ...            ...   \n",
       "119                     NaN            NaN   \n",
       "120                     NaN            NaN   \n",
       "121                     NaN            NaN   \n",
       "122                     NaN            NaN   \n",
       "123                     NaN            NaN   \n",
       "\n",
       "                                                 title  Source Title  ...  \\\n",
       "0    Simulating Human Opinions with Large Language ...           NaN  ...   \n",
       "1    How Well Do Simulated Population Samples with ...           NaN  ...   \n",
       "2    From Values to Opinions: Predicting Human Beha...           NaN  ...   \n",
       "3    AI-Human Hybrids for Marketing Research: Lever...           NaN  ...   \n",
       "4    Eysenck Personality Questionnaire: A Comparati...           NaN  ...   \n",
       "..                                                 ...           ...  ...   \n",
       "119  Niche modelling for twelve plant species (six ...           NaN  ...   \n",
       "120  Identifying psychosocial and contextual marker...           NaN  ...   \n",
       "121  Landscaping Work: Work-related Musculoskeletal...           NaN  ...   \n",
       "122  Triatoma dimidiata Infestation in Chagas Disea...           NaN  ...   \n",
       "123  A NEW SURVEY FOR LOW-LUMINOSITY EMISSION-LINE ...           NaN  ...   \n",
       "\n",
       "     Web of Science Index  Research Areas  IDS Number  Pubmed Id  \\\n",
       "0                     NaN             NaN         NaN        NaN   \n",
       "1                     NaN             NaN         NaN        NaN   \n",
       "2                     NaN             NaN         NaN        NaN   \n",
       "3                     NaN             NaN         NaN        NaN   \n",
       "4                     NaN             NaN         NaN        NaN   \n",
       "..                    ...             ...         ...        ...   \n",
       "119                   NaN             NaN         NaN        NaN   \n",
       "120                   NaN             NaN         NaN        NaN   \n",
       "121                   NaN             NaN         NaN        NaN   \n",
       "122                   NaN             NaN         NaN        NaN   \n",
       "123                   NaN             NaN         NaN        NaN   \n",
       "\n",
       "     Open Access Designations  Highly Cited Status  Hot Paper Status  \\\n",
       "0                         NaN                  NaN               NaN   \n",
       "1                         NaN                  NaN               NaN   \n",
       "2                         NaN                  NaN               NaN   \n",
       "3                         NaN                  NaN               NaN   \n",
       "4                         NaN                  NaN               NaN   \n",
       "..                        ...                  ...               ...   \n",
       "119                       NaN                  NaN               NaN   \n",
       "120                       NaN                  NaN               NaN   \n",
       "121                       NaN                  NaN               NaN   \n",
       "122                       NaN                  NaN               NaN   \n",
       "123                       NaN                  NaN               NaN   \n",
       "\n",
       "     Date of Export  UT (Unique WOS ID)  Web of Science Record  \n",
       "0               NaN                 NaN                      0  \n",
       "1               NaN                 NaN                      0  \n",
       "2               NaN                 NaN                      0  \n",
       "3               NaN                 NaN                      0  \n",
       "4               NaN                 NaN                      0  \n",
       "..              ...                 ...                    ...  \n",
       "119             NaN                 NaN                      0  \n",
       "120             NaN                 NaN                      0  \n",
       "121             NaN                 NaN                      0  \n",
       "122             NaN                 NaN                      0  \n",
       "123             NaN                 NaN                      0  \n",
       "\n",
       "[124 rows x 72 columns]"
      ]
     },
     "execution_count": 183,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Web of Science Search Results\n",
    "df_results_wos = pd.read_excel(\"data/savedrecs (2).xls\")\n",
    "df_results_wos = df_results_wos.rename(columns={\"Article Title\": \"title\"})\n",
    "\n",
    "# Semantic Scholar Search Results\n",
    "df_SS_g7\n",
    "\n",
    "df_results_wos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4317cbea",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Publication Type",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Authors",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Book Authors",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Book Editors",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "Book Group Authors",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "Author Full Names",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Book Author Full Names",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Group Authors",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "title_WoS",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Source Title",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Book Series Title",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Book Series Subtitle",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Language",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Document Type",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Conference Title",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Conference Date",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Conference Location",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Conference Sponsor",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Conference Host",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Author Keywords",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Keywords Plus",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Abstract",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Addresses",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Affiliations",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Reprint Addresses",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Email Addresses",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Researcher Ids",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "ORCIDs",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Funding Orgs",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Funding Name Preferred",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Funding Text",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Cited References",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Cited Reference Count",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Times Cited, WoS Core",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Times Cited, All Databases",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "180 Day Usage Count",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Since 2013 Usage Count",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Publisher",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Publisher City",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Publisher Address",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "ISSN",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "eISSN",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "ISBN",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Journal Abbreviation",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Journal ISO Abbreviation",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Publication Date",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Publication Year",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Volume",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Issue",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Part Number",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Supplement",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Special Issue",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Meeting Abstract",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Start Page",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "End Page",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Article Number",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "DOI",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "DOI Link",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Book DOI",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Early Access Date",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Number of Pages",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "WoS Categories",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Web of Science Index",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Research Areas",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "IDS Number",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Pubmed Id",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Open Access Designations",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Highly Cited Status",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Hot Paper Status",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Date of Export",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "UT (Unique WOS ID)",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Web of Science Record",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "norm_title",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "paperId",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "title_SS",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "year",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "authors",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "abstract",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "url",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "citationCount",
         "rawType": "int64",
         "type": "integer"
        }
       ],
       "ref": "6eaad3e7-3f5d-45d9-96c5-285484d05a60",
       "rows": [
        [
         "0",
         "J",
         "Ferreira, G; Amidei, J; Nieto, R; Kaltenbrunner, A",
         null,
         null,
         null,
         "Ferreira, Gregorio; Amidei, Jacopo; Nieto, Ruben; Kaltenbrunner, Andreas",
         null,
         null,
         "How Well Do Simulated Population Samples with GPT-4 Align with Real Ones? The Case of the Eysenck Personality Questionnaire Revised-Abbreviated Personality Test",
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         "0",
         "how well do simulated population samples with gpt 4 align with real ones the case of the eysenck personality questionnaire revised abbreviated personality test",
         "25f383b7a807392696073801959dcc1c1aadd2bb",
         "How Well Do Simulated Population Samples with GPT-4 Align with Real Ones? The Case of the Eysenck Personality Questionnaire Revised-Abbreviated Personality Test",
         "2025",
         "Gregorio Ferreira, Jacopo Amidei, Rubn Nieto, Andreas Kaltenbrunner",
         "Background: Advances in artificial intelligence have enabled the simulation of human-like behaviors, raising the possibility of using large language models (LLMs) to generate synthetic population samples for research purposes, which may be particularly useful in health and social sciences. Methods: This paper explores the potential of LLMs to simulate population samples mirroring real ones, as well as the feasibility of using personality questionnaires to assess the personality of LLMs. To advance in that direction, 2 experiments were conducted with GPT-4o using the Eysenck Personality Questionnaire Revised-Abbreviated (EPQR-A) in 6 languages: Spanish, English, Slovak, Hebrew, Portuguese, and Turkish. Results: We find that GPT-4o exhibits distinct personality traits, which vary based on parameter settings and the language of the questionnaire. While the model shows promising trends in reflecting certain personality traits and differences across gender and academic fields, discrepancies between the synthetic populations responses and those from real populations remain. Conclusions: These inconsistencies suggest that creating fully reliable synthetic population samples for questionnaire testing is still an open challenge. Further research is required to better align synthetic and real population behaviors.",
         "https://www.semanticscholar.org/paper/25f383b7a807392696073801959dcc1c1aadd2bb",
         "0"
        ],
        [
         "1",
         "C",
         "Kane, D; Parke, J; Jo, Y; Bak, J",
         null,
         "Bouamor, H; Pino, J; Bali, K",
         null,
         "Kane, Dongjun; Parke, JoonSuk; Jo, Yohan; Bak, JinYeong",
         null,
         null,
         "From Values to Opinions: Predicting Human Behaviors and Stances Using Value-Injected Large Language Models",
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         "0",
         "from values to opinions predicting human behaviors and stances using value injected large language models",
         "52e963c40a5083d5403cebf4d4782271aaa06994",
         "From Values to Opinions: Predicting Human Behaviors and Stances Using Value-Injected Large Language Models",
         "2023",
         "Dongjun Kang, Joonsuk Park, Yohan Jo, Jinyeong Bak",
         "Being able to predict people's opinions on issues and behaviors in realistic scenarios can be helpful in various domains, such as politics and marketing. However, conducting large-scale surveys like the European Social Survey to solicit people's opinions on individual issues can incur prohibitive costs. Leveraging prior research showing influence of core human values on individual decisions and actions, we propose to use value-injected large language models (LLM) to predict opinions and behaviors. To this end, we present Value Injection Method (VIM), a collection of two methods -- argument generation and question answering -- designed to inject targeted value distributions into LLMs via fine-tuning. We then conduct a series of experiments on four tasks to test the effectiveness of VIM and the possibility of using value-injected LLMs to predict opinions and behaviors of people. We find that LLMs value-injected with variations of VIM substantially outperform the baselines. Also, the results suggest that opinions and behaviors can be better predicted using value-injected LLMs than the baseline approaches.",
         "https://www.semanticscholar.org/paper/52e963c40a5083d5403cebf4d4782271aaa06994",
         "4"
        ],
        [
         "2",
         "J",
         "Bisbee, J; Clinton, JD; Dorff, C; Kenkel, B; Larson, JM",
         null,
         null,
         null,
         "Bisbee, James; Clinton, Joshua D.; Dorff, Cassy; Kenkel, Brenton; Larson, Jennifer M.",
         null,
         null,
         "Synthetic Replacements for Human Survey Data? The Perils of Large Language Models",
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         "0",
         "synthetic replacements for human survey data the perils of large language models",
         "58d735a54d3aba79ad3bffbfa2433d8e5ee27313",
         "Synthetic Replacements for Human Survey Data? The Perils of Large Language Models",
         "2024",
         "James Bisbee, Joshua D. Clinton, C. Dorff, Brenton Kenkel, Jennifer M. Larson",
         "\n Large language models (LLMs) offer new research possibilities for social scientists, but their potential as synthetic data is still largely unknown. In this paper, we investigate how accurately the popular LLM ChatGPT can recover public opinion, prompting the LLM to adopt different personas and then provide feeling thermometer scores for 11 sociopolitical groups. The average scores generated by ChatGPT correspond closely to the averages in our baseline survey, the 20162020 American National Election Study (ANES). Nevertheless, sampling by ChatGPT is not reliable for statistical inference: there is less variation in responses than in the real surveys, and regression coefficients often differ significantly from equivalent estimates obtained using ANES data. We also document how the distribution of synthetic responses varies with minor changes in prompt wording, and we show how the same prompt yields significantly different results over a 3-month period. Altogether, our findings raise serious concerns about the quality, reliability, and reproducibility of synthetic survey data generated by LLMs.",
         "https://www.semanticscholar.org/paper/58d735a54d3aba79ad3bffbfa2433d8e5ee27313",
         "74"
        ],
        [
         "3",
         "J",
         "Liu, HJ; Cao, Y; Wu, X; Qiu, C; Gu, JG; Liu, MF; Hershcovich, D",
         null,
         null,
         null,
         "Liu, Haijiang; Cao, Yong; Wu, Xun; Qiu, Chen; Gu, Jinguang; Liu, Maofu; Hershcovich, Daniel",
         null,
         null,
         "Towards realistic evaluation of cultural value alignment in large language models: Diversity enhancement for survey response simulation",
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         "0",
         "towards realistic evaluation of cultural value alignment in large language models diversity enhancement for survey response simulation",
         "3ab59b3d4a4b2e89f7eda93a950eeaa77b37332e",
         "Towards realistic evaluation of cultural value alignment in large language models: Diversity enhancement for survey response simulation",
         "2025",
         "Haijiang Liu, Yong Cao, Xun Wu, Chen Qiu, Jinguang Gu, Maofu Liu, Daniel Hershcovich",
         null,
         "https://www.semanticscholar.org/paper/3ab59b3d4a4b2e89f7eda93a950eeaa77b37332e",
         "2"
        ],
        [
         "4",
         "J",
         "Boelaert, J; Coavoux, S; Ollion, E; Petev, I; Prg, P",
         null,
         null,
         null,
         "Boelaert, Julien; Coavoux, Samuel; Ollion, Etienne; Petev, Ivaylo; Prag, Patrick",
         null,
         null,
         "Machine Bias. How Do Generative Language Models Answer Opinion Polls?",
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         "0",
         "machine bias how do generative language models answer opinion polls",
         "45f9ea8d0dc1a7e6c56ff6e1f23c8e632687d2a7",
         "Machine Bias. How Do Generative Language Models Answer Opinion Polls?",
         "2025",
         "J. Boelaert, Samuel Coavoux, tienne Ollion, Ivaylo Petev, P. Prg",
         "Generative artificial intelligence (AI) is increasingly presented as a potential substitute for humans, including as research subjects. However, there is no scientific consensus on how closely these in silico clones can emulate survey respondents. While some defend the use of these synthetic users, others point toward social biases in the responses provided by large language models (LLMs). In this article, we demonstrate that these critics are right to be wary of using generative AI to emulate respondents, but probably not for the right reasons. Our results show (i) that to date, models cannot replace research subjects for opinion or attitudinal research; (ii) that they display a strong bias and a low variance on each topic; and (iii) that this bias randomly varies from one topic to the next. We label this pattern machine bias, a concept we define, and whose consequences for LLM-based research we further explore.",
         "https://www.semanticscholar.org/paper/45f9ea8d0dc1a7e6c56ff6e1f23c8e632687d2a7",
         "9"
        ],
        [
         "5",
         "J",
         "Qu, Y; Wang, J",
         null,
         null,
         null,
         "Qu, Yao; Wang, Jue",
         null,
         null,
         "Performance and biases of Large Language Models in public opinion simulation",
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         "0",
         "performance and biases of large language models in public opinion simulation",
         "e6d14d140c4faaf8f3d9f47e61cc5c6091bccf1e",
         "Performance and Biases of Large Language Models in Public Opinion Simulation",
         "2024",
         "Yao Qu, Jue Wang",
         null,
         "https://www.semanticscholar.org/paper/e6d14d140c4faaf8f3d9f47e61cc5c6091bccf1e",
         "46"
        ],
        [
         "6",
         "C",
         "Nguyen, H; Nguyen, V; Lpez-Fierro, S; Ludovise, S; Santagata, R",
         null,
         null,
         "ASSOC COMPUTING MACHINERY",
         "Ha Nguyen; Nguyen, Victoria; Lopez-Fierro, Sariah; Ludovise, Sara; Santagata, Rossella",
         null,
         null,
         "Simulating Climate Change Discussion with Large Language Models: Considerations for Science Communication at Scale",
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         "0",
         "simulating climate change discussion with large language models considerations for science communication at scale",
         "dd95064d28ee5d123a6a284422bbba3d443f0416",
         "Simulating Climate Change Discussion with Large Language Models: Considerations for Science Communication at Scale",
         "2024",
         "Ha Nguyen, Victoria Nguyen, Sarah Lpez-Fierro, Sara Ludovise, R. Santagata",
         "Large language models (LLMs) have shown promise in simulating public opinions on social issues. These models can be leveraged in educational simulations that allow students to acquire information and feedback from multiple perspectives. In this research, we investigate the potential of using LLMs (specifically GPT-4) to generate open-ended responses about climate change within a science communication simulation. We prompt GPT-4 to role-play as different personas with various demographics (race/ethnicity, gender, age, income, political affiliations, and ability status) and levels of concern about climate change. We find that GPT-4 is capable of representing multifaceted perspectives around climate change's impact and solutions. However, the model may exaggerate narratives for certain personas based on political affiliations, gender, and concern levels. Such exaggeration may lead to homogeneous narratives that do not fully represent the simulated personas. Our findings highlight the affordances and challenges of applying LLMs to simulating public opinions and enriching educational experiences.",
         "https://www.semanticscholar.org/paper/dd95064d28ee5d123a6a284422bbba3d443f0416",
         "16"
        ],
        [
         "7",
         "J",
         "Salecha, A; Ireland, ME; Subrahmanya, S; Sedoc, J; Ungar, LH; Eichstaedt, JC",
         null,
         null,
         null,
         "Salecha, Aadesh; Ireland, Molly E.; Subrahmanya, Shashanka; Sedoc, Joao; Ungar, Lyle H.; Eichstaedt, Johannes C.",
         null,
         null,
         "Large language models display human-like social desirability biases in Big Five personality surveys",
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         "0",
         "large language models display human like social desirability biases in big five personality surveys",
         "8253104f5b1481d8557380d2dc5dab03ff9a7716",
         "Large language models display human-like social desirability biases in Big Five personality surveys",
         "2024",
         "Aadesh Salecha, Molly E. Ireland, Shashanka Subrahmanya, Joo Sedoc, Pallavi V. Kulkarni, J. Eichstaedt",
         "Abstract Large language models (LLMs) are becoming more widely used to simulate human participants and so understanding their biases is important. We developed an experimental framework using Big Five personality surveys and uncovered a previously undetected social desirability bias in a wide range of LLMs. By systematically varying the number of questions LLMs were exposed to, we demonstrate their ability to infer when they are being evaluated. When personality evaluation is inferred, LLMs skew their scores towards the desirable ends of trait dimensions (i.e. increased extraversion, decreased neuroticism, etc.). This bias exists in all tested models, including GPT-4/3.5, Claude 3, Llama 3, and PaLM-2. Bias levels appear to increase in more recent models, with GPT-4s survey responses changing by 1.20 (human) SD and Llama 3s by 0.98 SD, which are very large effects. This bias remains after question order randomization and paraphrasing. Reverse coding the questions decreases bias levels but does not eliminate them, suggesting that this effect cannot be attributed to acquiescence bias. Our findings reveal an emergent social desirability bias and suggest constraints on profiling LLMs with psychometric tests and on this use of LLMs as proxies for human participants.",
         "https://www.semanticscholar.org/paper/8253104f5b1481d8557380d2dc5dab03ff9a7716",
         "25"
        ],
        [
         "8",
         "J",
         "Yao, JC; Zhang, HJ; Ou, J; Zuo, DY; Yang, Z; Dong, ZC",
         null,
         null,
         null,
         "Yao, Junchi; Zhang, Hongjie; Ou, Jie; Zuo, Dingyi; Yang, Zheng; Dong, Zhicheng",
         null,
         null,
         "Social opinions prediction utilizes fusing dynamics equation with LLM-based agents",
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         "0",
         "social opinions prediction utilizes fusing dynamics equation with llm based agents",
         "392de716c8f6610f080ba655e885935c20ac6c73",
         "Social opinions prediction utilizes fusing dynamics equation with LLM-based agents",
         "2024",
         "Junchi Yao, Hongjie Zhang, Jie Ou, Dingyi Zuo, Zheng Yang, Zhicheng Dong",
         "In the context where social media emerges as a pivotal platform for social movements and shaping public opinion, accurately simulating and predicting the dynamics of user opinions is of significant importance. Such insights are vital for understanding social phenomena, informing policy decisions, and guiding public opinion. Unfortunately, traditional algorithms based on idealized models and disregarding social data often fail to capture the complexity and nuance of real-world social interactions. This study proposes the Fusing Dynamics Equation-Large Language Model (FDE-LLM) algorithm. This innovative approach aligns the actions and evolution of opinions in Large Language Models (LLMs) with the real-world data on social networks. The FDE-LLM divides users into two roles: opinion leaders and followers. Opinion leaders use LLM for role-playing and employ Cellular Automata(CA) to constrain opinion changes. In contrast, opinion followers are integrated into a dynamic system that combines the CA model with the Susceptible-Infectious-Recovered (SIR) model. This innovative design significantly improves the accuracy of the simulation. Our experiments utilized four real-world datasets from Weibo. The result demonstrates that the FDE-LLM significantly outperforms traditional Agent-Based Modeling (ABM) algorithms and LLM-based algorithms. Additionally, our algorithm accurately simulates the decay and recovery of opinions over time, underscoring LLMs potential to revolutionize the understanding of social media dynamics.",
         "https://www.semanticscholar.org/paper/392de716c8f6610f080ba655e885935c20ac6c73",
         "5"
        ],
        [
         "9",
         "C",
         "Hmlinen, P; Tavast, M; Kunnari, A",
         null,
         null,
         "ACM",
         "Hamalainen, Perttu; Tavast, Mikke; Kunnari, Anton",
         null,
         null,
         "Evaluating Large Language Models in Generating Synthetic HCI Research Data: a Case Study",
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         "0",
         "evaluating large language models in generating synthetic hci research data a case study",
         "0ffd57884d7957f6b5634b9fa24843dc3759668f",
         "Evaluating Large Language Models in Generating Synthetic HCI Research Data: a Case Study",
         "2023",
         "Perttu Hmlinen, Mikke Tavast, Anton Kunnari",
         "Collecting data is one of the bottlenecks of Human-Computer Interaction (HCI) research. Motivated by this, we explore the potential of large language models (LLMs) in generating synthetic user research data. We use OpenAIs GPT-3 model to generate open-ended questionnaire responses about experiencing video games as art, a topic not tractable with traditional computational user models. We test whether synthetic responses can be distinguished from real responses, analyze errors of synthetic data, and investigate content similarities between synthetic and real data. We conclude that GPT-3 can, in this context, yield believable accounts of HCI experiences. Given the low cost and high speed of LLM data generation, synthetic data should be useful in ideating and piloting new experiments, although any findings must obviously always be validated with real data. The results also raise concerns: if employed by malicious users of crowdsourcing services, LLMs may make crowdsourcing of self-report data fundamentally unreliable.",
         "https://www.semanticscholar.org/paper/0ffd57884d7957f6b5634b9fa24843dc3759668f",
         "218"
        ],
        [
         "10",
         "J",
         "Zhang, S; Xu, J; Alvero, AJ",
         null,
         null,
         null,
         "Zhang, Simone; Xu, Janet; Alvero, A. J.",
         null,
         null,
         "Generative AI Meets Open-Ended Survey Responses: Research Participant Use of AI and Homogenization",
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         "0",
         "generative ai meets open ended survey responses research participant use of ai and homogenization",
         "8398dfa4d015b3784654a77b3913b62a1f68eed8",
         "Generative AI Meets Open-Ended Survey Responses: Research Participant Use of AI and Homogenization",
         "2025",
         "Simone Zhang, Janet Xu, AJ Alvero",
         "The growing popularity of generative artificial intelligence (AI) tools presents new challenges for data quality in online surveys and experiments. This study examines participants use of large language models to answer open-ended survey questions and describes empirical tendencies in human versus large language model (LLM)-generated text responses. In an original survey of research participants recruited from a popular online platform for sourcing social science research subjects, 34 percent reported using LLMs to help them answer open-ended survey questions. Simulations comparing human-written responses from three pre-ChatGPT studies with LLM-generated text reveal that LLM responses are more homogeneous and positive, particularly when they describe social groups in sensitive questions. These homogenization patterns may mask important underlying social variation in attitudes and beliefs among human subjects, raising concerns about data validity. Our findings shed light on the scope and potential consequences of participants LLM use in online research.",
         "https://www.semanticscholar.org/paper/8398dfa4d015b3784654a77b3913b62a1f68eed8",
         "10"
        ],
        [
         "11",
         "J",
         "Zhang, BY; Chen, T; Wang, X; Li, Q; Zhang, WS; Wang, FY",
         null,
         null,
         null,
         "Zhang, Baoyu; Chen, Tao; Wang, Xiao; Li, Qiang; Zhang, Weishan; Wang, Fei-Yue",
         null,
         null,
         "Decoding Activist Public Opinion in Decentralized Self-Organized Protests Using LLM",
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         "0",
         "decoding activist public opinion in decentralized self organized protests using llm",
         "4949ff97cf5e7c31ed9a057cbbde4b95d3ddd1f8",
         "Decoding Activist Public Opinion in Decentralized Self-Organized Protests Using LLM",
         "2024",
         "Baoyu Zhang, Tao Chen, Xiao Wang, Qiang Li, Weishan Zhang, FeiYue Wang",
         "Based on an investigation of online public opinion on the Nahel Merzouk protests in France, an approach for analyzing and predicting public opinion on protests based on large language model (LLM) is proposed, revealing the impact of emerging social media on the protests. We demonstrate that protests generate public opinion on social media with some lag, but that comment sentiment and expression are consistent with protest trends. As the protests unfolded, we analyzed the evolution of public sentiment. We constructed the prompt based on historical data to predict the protests using the p-tuning and Lora approach to fine-tune LLM. In addition, we discuss how to use blockchain technology to optimize distributed, self-organizing protests and reduce the potential for disinformation and violent conflict.",
         "https://www.semanticscholar.org/paper/4949ff97cf5e7c31ed9a057cbbde4b95d3ddd1f8",
         "2"
        ],
        [
         "12",
         "J",
         "Gao, C; Lan, XC; Li, N; Yuan, Y; Ding, JT; Zhou, ZL; Xu, FL; Li, Y",
         null,
         null,
         null,
         "Gao, Chen; Lan, Xiaochong; Li, Nian; Yuan, Yuan; Ding, Jingtao; Zhou, Zhilun; Xu, Fengli; Li, Yong",
         null,
         null,
         "Large language models empowered agent-based modeling and simulation: a survey and perspectives",
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         "0",
         "large language models empowered agent based modeling and simulation a survey and perspectives",
         "592ac35991e583fc37c26ee6659d2deb85142ad9",
         "Large Language Models Empowered Agent-based Modeling and Simulation: A Survey and Perspectives",
         "2023",
         "Chen Gao, Xiaochong Lan, Nian Li, Yuan Yuan, Jingtao Ding, Zhilun Zhou, Fengli Xu, Yong Li",
         "Agent-based modeling and simulation have evolved as a powerful tool for modeling complex systems, offering insights into emergent behaviors and interactions among diverse agents. Recently, integrating large language models into agent-based modeling and simulation presents a promising avenue for enhancing simulation capabilities. This paper surveys the landscape of utilizing large language models in agent-based modeling and simulation, discussing their challenges and promising future directions. In this survey, since this is an interdisciplinary field, we first introduce the background of agent-based modeling and simulation and large language model-empowered agents. We then discuss the motivation for applying large language models to agent-based simulation and systematically analyze the challenges in environment perception, human alignment, action generation, and evaluation. Most importantly, we provide a comprehensive overview of the recent works of large language model-empowered agent-based modeling and simulation in multiple scenarios, which can be divided into four domains: cyber, physical, social, and hybrid, covering simulation of both real-world and virtual environments, and how these works address the above challenges. Finally, since this area is new and quickly evolving, we discuss the open problems and promising future directions. We summarize the representative papers along with their code repositories in https://github.com/tsinghua-fib-lab/LLM-Agent-Based-Modeling-and-Simulation.",
         "https://www.semanticscholar.org/paper/592ac35991e583fc37c26ee6659d2deb85142ad9",
         "182"
        ],
        [
         "13",
         "C",
         "AlKhamissi, B; ElNokrashy, M; AlKhamissi, M; Diab, M",
         null,
         "Ku, LW; Martins, A; Srikumar, V",
         null,
         "AlKhamissi, Badr; ElNokrashy, Muhammad; AlKhamissi, Mai; Diab, Mona",
         null,
         null,
         "Investigating Cultural Alignment of Large Language Models",
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         "0",
         "investigating cultural alignment of large language models",
         "b1890367317f0657c08ed96be4c474035b34b485",
         "Investigating Cultural Alignment of Large Language Models",
         "2024",
         "Badr AlKhamissi, Muhammad N. ElNokrashy, Mai AlKhamissi, Mona Diab",
         "The intricate relationship between language and culture has long been a subject of exploration within the realm of linguistic anthropology. Large Language Models (LLMs), promoted as repositories of collective human knowledge, raise a pivotal question: do these models genuinely encapsulate the diverse knowledge adopted by different cultures? Our study reveals that these models demonstrate greater cultural alignment along two dimensions -- firstly, when prompted with the dominant language of a specific culture, and secondly, when pretrained with a refined mixture of languages employed by that culture. We quantify cultural alignment by simulating sociological surveys, comparing model responses to those of actual survey participants as references. Specifically, we replicate a survey conducted in various regions of Egypt and the United States through prompting LLMs with different pretraining data mixtures in both Arabic and English with the personas of the real respondents and the survey questions. Further analysis reveals that misalignment becomes more pronounced for underrepresented personas and for culturally sensitive topics, such as those probing social values. Finally, we introduce Anthropological Prompting, a novel method leveraging anthropological reasoning to enhance cultural alignment. Our study emphasizes the necessity for a more balanced multilingual pretraining dataset to better represent the diversity of human experience and the plurality of different cultures with many implications on the topic of cross-lingual transfer.",
         "https://www.semanticscholar.org/paper/b1890367317f0657c08ed96be4c474035b34b485",
         "78"
        ],
        [
         "14",
         "J",
         "Zhao, XJ; Wang, H; Dai, CX; Tang, JC; Deng, KX; Zhong, ZH; Kong, FY; Wang, SY; Morikawa, S",
         null,
         null,
         null,
         "Zhao, Xinjie; Wang, Hao; Dai, Chengxiao; Tang, Jiacheng; Deng, Kaixin; Zhong, Zhihua; Kong, Fanying; Wang, Shiyun; Morikawa, So",
         null,
         null,
         "Multi-Stage Simulation of Residents' Disaster Risk Perception and Decision-Making Behavior: An Exploratory Study on Large Language Model-Driven Social-Cognitive Agent Framework",
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         "0",
         "multi stage simulation of residents disaster risk perception and decision making behavior an exploratory study on large language model driven social cognitive agent framework",
         "6d2077c8f4864103780b160501cd207005d045c8",
         "Multi-Stage Simulation of Residents Disaster Risk Perception and Decision-Making Behavior: An Exploratory Study on Large Language Model-Driven SocialCognitive Agent Framework",
         "2025",
         "Xinjie Zhao, Hao Wang, Chengxiao Dai, Jiacheng Tang, Kaixin Deng, Zhihua Zhong, Fanying Kong, Shiyun Wang, So Morikawa",
         "The escalating frequency and complexity of natural disasters highlight the urgent need for deeper insights into how individuals and communities perceive and respond to risk information. Yet, conventional research methodssuch as surveys, laboratory experiments, and field observationsoften struggle with limited sample sizes, external validity concerns, and difficulties in controlling for confounding variables. These constraints hinder our ability to develop comprehensive models that capture the dynamic, context-sensitive nature of disaster decision-making. To address these challenges, we present a novel multi-stage simulation framework that integrates Large Language Model (LLM)-driven socialcognitive agents with well-established theoretical perspectives from psychology, sociology, and decision science. This framework enables the simulation of three critical phasesinformation perception, cognitive processing, and decision-makingproviding a granular analysis of how demographic attributes, situational factors, and social influences interact to shape behavior under uncertain and evolving disaster conditions. A case study focusing on pre-disaster preventive measures demonstrates its effectiveness. By aligning agent demographics with real-world survey data across 5864 simulated scenarios, we reveal nuanced behavioral patterns closely mirroring human responses, underscoring the potential to overcome longstanding methodological limitations and offer improved ecological validity and flexibility to explore diverse disaster environments and policy interventions. While acknowledging the current constraints, such as the need for enhanced emotional modeling and multimodal inputs, our framework lays a foundation for more nuanced, empirically grounded analyses of risk perception and response patterns. By seamlessly blending theory, advanced LLM capabilities, and empirical alignment strategies, this research not only advances the state of computational social simulation but also provides valuable guidance for developing more context-sensitive and targeted disaster management strategies.",
         "https://www.semanticscholar.org/paper/6d2077c8f4864103780b160501cd207005d045c8",
         "1"
        ],
        [
         "15",
         "J",
         "de Winter, JCF; Driessen, T; Dodou, D",
         null,
         null,
         null,
         "de Winter, Joost C. F.; Driessen, Tom; Dodou, Dimitra",
         null,
         null,
         "The use of ChatGPT for personality research: Administering questionnaires using generated personas",
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         "0",
         "the use of chatgpt for personality research administering questionnaires using generated personas",
         "781703bc7e4fb90766824ee808097171afa223b3",
         "The use of ChatGPT for personality research: Administering questionnaires using generated personas",
         "2024",
         "J. D. de Winter, Tom Driessen, Dimitra Dodou",
         null,
         "https://www.semanticscholar.org/paper/781703bc7e4fb90766824ee808097171afa223b3",
         "19"
        ],
        [
         "16",
         "J",
         "Rakovics, Z; Rakovics, M",
         null,
         null,
         null,
         "Rakovics, Zsofia; Rakovics, Marton",
         null,
         null,
         "Exploring the potential and limitations of large language models as virtual respondents for social science research",
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         "0",
         "exploring the potential and limitations of large language models as virtual respondents for social science research",
         "6cd94c4fdfd1ddf59b5385919851de2662e412fe",
         "Exploring the potential and limitations of large language models as virtual respondents for social science research",
         "2024",
         "Zsfia Rakovics, Mrton Rakovics",
         "Social and linguistic differences encoded in various textual content available on the internet represent certain features of modern societies. For any scientific research which is interested in social differences mediated by language, the advent of large language models (LLMs) has brought new opportunities. LLMs could be used to extract information about different groups of society and utilized as data providers by acting as virtual respondents generating answers as such. \nUsing LLMs (GPT-variants, Llama2, and Mixtral), we generated virtual answers for politics and democracy related attitude questions of the European Social Survey (10th wave) and statistically compared the results of the simulated responses to the real ones. We explored different prompting techniques and the effect of different types and richness of contextual information provided to the models. Our results suggest that the tested LLMs generate highly realistic answers and are good at invoking the needed patterns from limited contextual information given to them if a couple of relevant examples are provided, but struggle in a zero-shot setting. \nA critical methodological analysis is inevitable when considering the potential use of data generated by LLMs for scientific research, the exploration of known biases and reflection on social reality not represented on the internet are essential.",
         "https://www.semanticscholar.org/paper/6cd94c4fdfd1ddf59b5385919851de2662e412fe",
         "1"
        ],
        [
         "17",
         "J",
         "Leung, HW; Bovy, J",
         null,
         null,
         null,
         "Leung, Henry W.; Bovy, Jo",
         null,
         null,
         "Towards an astronomical foundation model for stars with a transformer-based model",
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         "0",
         "towards an astronomical foundation model for stars with a transformer based model",
         "264cb7a7dbee1303ff9e0ebe2dac78646271a2fb",
         "Towards an astronomical foundation model for stars with a Transformer-based model",
         "2023",
         "Henry W. Leung, J. Bovy",
         "Rapid strides are currently being made in the field of artificial intelligence using Transformer-based models like Large Language Models (LLMs). The potential of these methods for creating a single, large, versatile model in astronomy has not yet been explored. In this work, we propose a framework for data-driven astronomy that uses the same core techniques and architecture as used by LLMs. Using a variety of observations and labels of stars as an example, we build a Transformer-based model and train it in a self-supervised manner with cross-survey data sets to perform a variety of inference tasks. In particular, we demonstrate that a $\\textit{single}$ model can perform both discriminative and generative tasks even if the model was not trained or fine-tuned to do any specific task. For example, on the discriminative task of deriving stellar parameters from Gaia XP spectra, we achieve an accuracy of 47 K in $T_\\mathrm{eff}$, 0.11 dex in $\\log{g}$, and 0.07 dex in $[\\mathrm{M/H}]$, outperforming an expert $\\texttt{XGBoost}$ model in the same setting. But the same model can also generate XP spectra from stellar parameters, inpaint unobserved spectral regions, extract empirical stellar loci, and even determine the interstellar extinction curve. Our framework demonstrates that building and training a $\\textit{single}$ foundation model without fine-tuning using data and parameters from multiple surveys to predict unmeasured observations and parameters is well within reach. Such\"Large Astronomy Models\"trained on large quantities of observational data will play a large role in the analysis of current and future large surveys.",
         "https://www.semanticscholar.org/paper/264cb7a7dbee1303ff9e0ebe2dac78646271a2fb",
         "24"
        ],
        [
         "18",
         "J",
         "Mburu, TK; Rong, KX; McColley, CJ; Werth, A",
         null,
         null,
         null,
         "Mburu, Ted K.; Rong, Kangxuan; McColley, Campbell J.; Werth, Alexandra",
         null,
         null,
         "Methodological foundations for artificial intelligence-driven survey question generation",
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         "0",
         "methodological foundations for artificial intelligence driven survey question generation",
         "54b63afefc315b5f051f4a19fe413ef6c544c9fd",
         "Methodological foundations for artificial intelligencedriven survey question generation",
         "2025",
         "Ted K. Mburu, Kangxuan Rong, Campbell J. McColley, Alexandra Werth",
         "This study investigates the use of large language models to create adaptive, contextually relevant survey questions, aiming to enhance data quality in educational research without limiting scalability.We provide stepbystep methods to develop a dynamic survey instrument, driven by artificial intelligence (AI),and introduce the Synthetic QuestionResponse Analysis (SQRA) framework, a methodology designed to help evaluate AIgenerated questions before deployment with human participants.We examine the questions generated by our survey instrument, as well as compare AItoAI, generated through our SQRA framework, with AItohuman interactions. Activity theory provides a theoretical lens to examine the dynamic interactions between AI and participants, highlighting the mutual influence within the survey tool.We found that AIgenerated questions were contextually relevant and adaptable, successfully incorporating coursespecific references. However, issues such as redundant phrasing, doublebarreled questions, and jargon affected the clarity of the questions. Although the SQRA framework exhibited limitations in replicating human response variability, its iterative refinement process proved effective in improving question quality, reinforcing the utility of this approach for enhancing AIdriven surveys.While AIdriven question generation can enhance the scalability and personalization of openended survey prompts, more research is needed to establish best practices for highquality educational research. The SQRA framework demonstrated practical utility for prompt refinement and initial validation of AIgenerated survey content, but it is not capable of replicating human responses. We highlight the importance of iterative prompt engineering, ethical considerations, and the need for methodological advancements in the development of trustworthy AIdriven survey instruments for educational research.",
         "https://www.semanticscholar.org/paper/54b63afefc315b5f051f4a19fe413ef6c544c9fd",
         "1"
        ],
        [
         "19",
         "J",
         "Zhang, KH; Dong, CQ; Guo, YF; Zhou, W; Yu, G; Mi, JN",
         null,
         null,
         null,
         "Zhang, Kaihang; Dong, Changqi; Guo, Yifeng; Zhou, Wuai; Yu, Guang; Mi, Jianing",
         null,
         null,
         "Lagged Stance Interactions and Counter-Spiral of Silence: A Data-Driven Analysis and Agent-Based Modeling of Technical Public Opinion Events",
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         "0",
         "lagged stance interactions and counter spiral of silence a data driven analysis and agent based modeling of technical public opinion events",
         "bc270ab2e00f78691c8fd16548809e3609dedee2",
         "Lagged Stance Interactions and Counter-Spiral of Silence: A Data-Driven Analysis and Agent-Based Modeling of Technical Public Opinion Events",
         "2025",
         "Kaihang Zhang, Changqi Dong, Yifeng Guo, Wuai Zhou, Guang Yu, Jianing Mi",
         "Understanding the dynamics of public opinion formation in digital environments is crucial for managing technological communications effectively. This study investigates stance interactions and opinion reversal phenomena in technical discourse through analysis of the Manus AI controversy that generated approximately 36,932 social media interactions during March 2025. Employing an integrated methodology combining Large Language Model (LLM)-enhanced stance detection with agent-based modeling (ABM), we reveal distinctive patterns challenging traditional public opinion theories. Our cross-correlation analysis identifies significant lagged interaction effects between skeptical and supportive stances, demonstrating how critical expressions trigger amplified counter-responses rather than inducing silence. Unlike prior conceptualizations of counter-silencing that emphasize ideological resistance or echo chambers, our notion of the counter-spiral of silence specifically highlights lagged emotional responses and reactive amplification triggered by minority expressions in digital technical discourse. We delineate its boundary conditions as arising under high emotional salience, asymmetrical expertise, and platform structures that enable real-time feedback. The agent-based simulation reproduces empirical patterns, revealing how emotional contagion and network clustering mechanisms generate counter-spiral of silence phenomena where challenges to dominant positions ultimately strengthen rather than weaken those positions. These findings illuminate how cognitive asymmetries between public expectations and industry realities create distinctive discourse patterns in technical contexts, offering insights for managing technology communication and predicting public response trajectories in rapidly evolving digital environments.",
         "https://www.semanticscholar.org/paper/bc270ab2e00f78691c8fd16548809e3609dedee2",
         "0"
        ],
        [
         "20",
         "J",
         "Campos, M; Farinhas, A; Zerva, C; Figueiredo, MAT; Martins, AFT",
         null,
         null,
         null,
         "Campos, Margarida; Farinhas, Antonio; Zerva, Chrysoula; Figueiredo, Mario A. T.; Martins, Andre F. T.",
         null,
         null,
         "Conformal Prediction for Natural Language Processing: A Survey",
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         "0",
         "conformal prediction for natural language processing a survey",
         "346fdbda3ecf4775819fced0cfed78357bee8128",
         "Conformal Prediction for Natural Language Processing: A Survey",
         "2024",
         "Margarida M. Campos, Antnio Farinhas, Chrysoula Zerva, M'ario A.T. Figueiredo, Andr'e F. T. Martins",
         "Abstract The rapid proliferation of large language models and natural language processing (NLP) applications creates a crucial need for uncertainty quantification to mitigate risks such as Hallucinations and to enhance decision-making reliability in critical applications. Conformal prediction is emerging as a theoretically sound and practically useful framework, combining flexibility with strong statistical guarantees. Its model-agnostic and distribution-free nature makes it particularly promising to address the current shortcomings of NLP systems that stem from the absence of uncertainty quantification. This paper provides a comprehensive survey of conformal prediction techniques, their guarantees, and existing applications in NLP, pointing to directions for future research and open challenges.",
         "https://www.semanticscholar.org/paper/346fdbda3ecf4775819fced0cfed78357bee8128",
         "22"
        ],
        [
         "21",
         "C",
         "Cheng, M; Piccardi, T; Yang, DY",
         null,
         "Bouamor, H; Pino, J; Bali, K",
         null,
         "Cheng, Myra; Piccardi, Tiziano; Yang, Diyi",
         null,
         null,
         "CoMPosT: Characterizing and Evaluating Caricature in LLM Simulations",
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         "0",
         "compost characterizing and evaluating caricature in llm simulations",
         "7a4fe2f003241ad97bf1778e527cb0306fa90da2",
         "CoMPosT: Characterizing and Evaluating Caricature in LLM Simulations",
         "2023",
         "Myra Cheng, Tiziano Piccardi, Diyi Yang",
         "Recent work has aimed to capture nuances of human behavior by using LLMs to simulate responses from particular demographics in settings like social science experiments and public opinion surveys. However, there are currently no established ways to discuss or evaluate the quality of such LLM simulations. Moreover, there is growing concern that these LLM simulations are flattened caricatures of the personas that they aim to simulate, failing to capture the multidimensionality of people and perpetuating stereotypes. To bridge these gaps, we present CoMPosT, a framework to characterize LLM simulations using four dimensions: Context, Model, Persona, and Topic. We use this framework to measure open-ended LLM simulations' susceptibility to caricature, defined via two criteria: individuation and exaggeration. We evaluate the level of caricature in scenarios from existing work on LLM simulations. We find that for GPT-4, simulations of certain demographics (political and marginalized groups) and topics (general, uncontroversial) are highly susceptible to caricature.",
         "https://www.semanticscholar.org/paper/7a4fe2f003241ad97bf1778e527cb0306fa90da2",
         "89"
        ],
        [
         "22",
         "J",
         "Kaur, A; Budko, A; Liu, K; Eaton, E; Steitz, BD; Johnson, KB",
         null,
         null,
         null,
         "Kaur, Amarpreet; Budko, Alexander; Liu, Katrina; Eaton, Eric; Steitz, Bryan D.; Johnson, Kevin B.",
         null,
         null,
         "Automating Responses to Patient Portal Messages Using Generative AI",
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         "0",
         "automating responses to patient portal messages using generative ai",
         "caa3c4eb1ede700f03eef5b4f25a18b08c88d832",
         "Automating Responses to Patient Portal Messages Using Generative AI",
         "2024",
         "Amarpreet Kaur, Alexander Budko, Katrina Liu, Eric Eaton, Bryan D. Steitz, Kevin B. Johnson",
         "Background: Patient portals serve as vital bridges between patients and providers, playing an increasing role in healthcare communication. The rising volume and complexity of these messages is exacerbating physician and nursing burnout. Recent studies have demonstrated that AI chatbots can generate message responses that are viewed favorably by healthcare professionals; however, these studies have not included the diverse range of messages typically found in patient portals. Our goal is to investigate the quality of GPT-generated message responses across the spectrum of message types within a patient portal. Methods: We used novel prompt engineering techniques to craft synthetic responses tailored to adult primary care patients. We enrolled a sample of primary care providers in a cross-sectional study to compare authentic with synthetic patient portal message responses, generated by GPT-4. The survey assessed each messages empathy, relevance, medical accuracy, and readability on a scale from 0 to 5. Respondents were asked to identify messages that were GPT-generated vs. provider-generated. Mean scores for all metrics were computed for subsequent analysis. Results: A total of 49 health care providers participated in the survey (59% completion rate), comprising 16 physicians and 32 advanced practice providers (APPs). When presented with GPT vs. authentic message response pairs, participants correctly identified GPT-generated responses 73% of the time and correctly identified authentic responses 50% of the time. In comparison to messages generated by physicians, GPT-4 generated messages exhibited higher mean scores for empathy (3.57 vs. 3.07, p < 0.001), relevance (3.94 vs. 3.81, p = 0.08) accuracy (4.05 vs. 3.95, p= 0.12) and readability (4.5 vs. 4.13, p < 0.001). Limitations: The study is a single-site, single-specialty study, limited due to the use of synthetic data. Conclusion: Our findings affirm the potential of GPT-generated patient portal message responses to achieve comparable levels of empathy, relevance, and readability to those found in typical responses according to the health care providers and indicates promising prospects for their integration in the healthcare sector. Additional studies should be done within provider workflows and with careful evaluation of patient attitudes and concerns related to the ethics as well as the quality of generated patient portal message responses in all settings.",
         "https://www.semanticscholar.org/paper/caa3c4eb1ede700f03eef5b4f25a18b08c88d832",
         "7"
        ],
        [
         "23",
         "J",
         "Ji, J; Kim, J; Kim, Y",
         null,
         null,
         null,
         "Ji, Junyung; Kim, Jiwoo; Kim, Younghoon",
         null,
         null,
         "Predicting Missing Values in Survey Data Using Prompt Engineering for Addressing Item Non-Response",
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         "0",
         "predicting missing values in survey data using prompt engineering for addressing item non response",
         "bdeeaf207e2563f39ad27a9d9511d8573b5bff95",
         "Predicting Missing Values in Survey Data Using Prompt Engineering for Addressing Item Non-Response",
         "2024",
         "Junyung Ji, Jiwoo Kim, Younghoon Kim",
         "Survey data play a crucial role in various research fields, including economics, education, and healthcare, by providing insights into human behavior and opinions. However, item non-response, where respondents fail to answer specific questions, presents a significant challenge by creating incomplete datasets that undermine data integrity and can hinder or even prevent accurate analysis. Traditional methods for addressing missing data, such as statistical imputation techniques and deep learning models, often fall short when dealing with the rich linguistic content of survey data. These approaches are also hampered by high time complexity for training and the need for extensive preprocessing or feature selection. In this paper, we introduce an approach that leverages Large Language Models (LLMs) through prompt engineering for predicting item non-responses in survey data. Our method combines the strengths of both traditional imputation techniques and deep learning methods with the advanced linguistic understanding of LLMs. By integrating respondent similarities, question relevance, and linguistic semantics, our approach enhances the accuracy and comprehensiveness of survey data analysis. The proposed method bypasses the need for complex preprocessing and additional training, making it adaptable, scalable, and capable of generating explainable predictions in natural language. We evaluated the effectiveness of our LLM-based approach through a series of experiments, demonstrating its competitive performance against established methods such as Multivariate Imputation by Chained Equations (MICE), MissForest, and deep learning models like TabTransformer. The results show that our approach not only matches but, in some cases, exceeds the performance of these methods while significantly reducing the time required for data processing.",
         "https://www.semanticscholar.org/paper/bdeeaf207e2563f39ad27a9d9511d8573b5bff95",
         "2"
        ],
        [
         "24",
         "J",
         "Goli, A; Singh, A",
         null,
         null,
         null,
         "Goli, Ali; Singh, Amandeep",
         null,
         null,
         "Frontiers: Can Large Language Models Capture Human Preferences?",
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         "0",
         "frontiers can large language models capture human preferences",
         "0377c4c20d86e3a23cb5c22d89b3cb488c31a564",
         "Frontiers: Can Large Language Models Capture Human Preferences?",
         "2024",
         "Ali Goli, Amandeep Singh",
         "This paper examines the potential of large language models to mimic human survey respondents and to derive their preferences.",
         "https://www.semanticscholar.org/paper/0377c4c20d86e3a23cb5c22d89b3cb488c31a564",
         "31"
        ],
        [
         "25",
         "C",
         "Liu, YH; Chen, XY; Zhang, XQ; Gao, X; Zhang, J; Yan, R",
         null,
         "Larson, K",
         null,
         "Liu, Yuhan; Chen, Xiuying; Zhang, Xiaoqing; Gao, Xing; Zhang, Ji; Yan, Rui",
         null,
         null,
         "From Skepticism to Acceptance: Simulating the Attitude Dynamics Toward Fake News",
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         "0",
         "from skepticism to acceptance simulating the attitude dynamics toward fake news",
         "1bd4b8be136072c8f56114f2f8479aaed2ad6d9b",
         "From Skepticism to Acceptance: Simulating the Attitude Dynamics Toward Fake News",
         "2024",
         "Yuhan Liu, Xiuying Chen, Xiaoqing Zhang, Xing Gao, Ji Zhang, Rui Yan",
         "In the digital era, the rapid propagation of fake news and rumors via social networks brings notable societal challenges and impacts public opinion regulation. Traditional fake news modeling typically forecasts the general popularity trends of different groups or numerically represents opinions shift. However, these methods often oversimplify real-world complexities and overlook the rich semantic information of news text. The advent of large language models (LLMs) provides the possibility of modeling subtle dynamics of opinion. Consequently, in this work, we introduce a Fake news Propagation Simulation framework (FPS) based on LLM, which studies the trends and control of fake news propagation in detail. Specifically, each agent in the simulation represents an individual with a distinct personality. They are equipped with both short-term and long-term memory, as well as a reflective mechanism to mimic human-like thinking. Every day, they engage in random opinion exchanges, reflect on their thinking, and update their opinions. Our simulation results uncover patterns in fake news propagation related to topic relevance, and individual traits, aligning with real-world observations. Additionally, we evaluate various intervention strategies and demonstrate that early and appropriately frequent interventions strike a balance between governance cost and effectiveness, offering valuable insights for practical applications. Our study underscores the significant utility and potential of LLMs in combating fake news.",
         "https://www.semanticscholar.org/paper/1bd4b8be136072c8f56114f2f8479aaed2ad6d9b",
         "44"
        ],
        [
         "26",
         "J",
         "Ferreira, G; Amidei, J; Nieto, R; Kaltenbrunner, A",
         null,
         null,
         null,
         "Ferreira, Gregorio; Amidei, Jacopo; Nieto, Ruben; Kaltenbrunner, Andreas",
         null,
         null,
         "Matching GPT-simulated Populations with Real Ones in Psychological Studies-The Case of the EPQR-A Personality Test",
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         "0",
         "matching gpt simulated populations with real ones in psychological studies the case of the epqr a personality test",
         "e186d394a49ab2866a8b1248a99e6f1637a238fe",
         "Matching GPT-simulated Populations with Real Ones in Psychological StudiesThe Case of the EPQR-A Personality Test",
         "2025",
         "Gregorio Ferreira, Jacopo Amidei, Rubn Nieto, Andreas Kaltenbrunner",
         "This article analyzes how well OpenAIs LLM GPT-4 can emulate different personalities and simulate populations to answer psychological questionnaires similarly to real population samples. For this purpose, we performed different experiments with the Eysenck Personality Questionnaire-Revised Abbreviated (EPQR-A) in three different languages (Spanish, English, and Slovak). The EPQR-A measures personality on four scales: extraversion (E: sociability), neuroticism (N: emotional stability), psychoticism (P: tendency to break social rules, and not having empathy), and lying (L: social desirability). We perform a comparative analysis of the answers of synthetic populations with those of two real population samples of Spanish students as well as the unconditioned baseline personality of GPT. Furthermore, the impact of time (what year the questionnaire is answered), questionnaire language, and student age and gender are analyzed. To our knowledge, this is the first time the EPQR-A test has been used to assess the GPTs personality and the impact of different language versions and time are measured. Our analysis reveals that GPT-4 exhibits an extroverted, emotionally stable personality with low psychoticism levels and high social desirability. GPT-4 replicates some differences observed in real populations in terms of gender but only partially replicates the results for real populations.",
         "https://www.semanticscholar.org/paper/e186d394a49ab2866a8b1248a99e6f1637a238fe",
         "2"
        ],
        [
         "27",
         "C",
         "Scarlatos, A; Baker, RS; Lan, A",
         null,
         null,
         "ACM",
         "Scarlatos, Alexander; Baker, Ryan S.; Lan, Andrew",
         null,
         null,
         "Exploring Knowledge Tracing in Tutor-Student Dialogues using LLMs",
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         "0",
         "exploring knowledge tracing in tutor student dialogues using llms",
         "06e9ec37cc25980544d0a78b5aa4893dafc65fd3",
         "Exploring Knowledge Tracing in Tutor-Student Dialogues using LLMs",
         "2024",
         "Alexander Scarlatos, Ryan S. Baker, Andrew Lan",
         "Recent advances in large language models (LLMs) have led to the development of artificial intelligence (AI)-powered tutoring chatbots, showing promise in providing broad access to high-quality personalized education. Existing works have studied how to make LLMs follow tutoring principles, but have not studied broader uses of LLMs for supporting tutoring. Up until now, tracing student knowledge and analyzing misconceptions has been difficult and time-consuming to implement for open-ended dialogue tutoring. In this work, we investigate whether LLMs can be supportive of this task: we first use LLM prompting methods to identify the knowledge components/skills involved in each dialogue turn, i.e., a tutor utterance posing a task or a student utterance that responds to it. We also evaluate whether the student responds correctly to the tutor and verify the LLMs accuracy using human expert annotations. We then apply a range of knowledge tracing (KT) methods on the resulting labeled data to track student knowledge levels over an entire dialogue. We conduct experiments on two tutoring dialogue datasets, and show that a novel yet simple LLM-based method, LLMKT, significantly outperforms existing KT methods in predicting student response correctness in dialogues. We perform extensive qualitative analyses to highlight the challenges in dialogueKT and outline multiple avenues for future work.",
         "https://www.semanticscholar.org/paper/06e9ec37cc25980544d0a78b5aa4893dafc65fd3",
         "14"
        ],
        [
         "28",
         "C",
         "Steinmacher, I; Penney, JM; Felizardo, KR; Garcia, AF; Gerosa, MA",
         null,
         null,
         "ACM",
         "Steinmacher, Igor; Penney, Jacob Mcauley; Felizardo, Katia Romero; Garcia, Alessandro F.; Gerosa, Marco A.",
         null,
         null,
         "Can ChatGPT emulate humans in software engineering surveys?",
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         "0",
         "can chatgpt emulate humans in software engineering surveys",
         "2a77ac8d1c36ccf9f222cf0ae16e251ac6b13e86",
         "Can ChatGPT emulate humans in software engineering surveys?",
         "2024",
         "Igor Steinmacher, Jacob Penney, K. Felizardo, Alessandro F. Garcia, M. Gerosa",
         "Context: There is a growing belief in the literature that large language models (LLMs), such as ChatGPT, can mimic human behavior in surveys. Gap: While the literature has shown promising results in social sciences and market research, there is scant evidence of its effectiveness in technical fields like software engineering. Objective: Inspired by previous work, this paper explores ChatGPTs ability to replicate findings from prior software engineering research. Given the frequent use of surveys in this field, if LLMs can accurately emulate human responses, this technique could address common methodological challenges like recruitment difficulties, representational shortcomings, and respondent fatigue. Method: We prompted ChatGPT to reflect the behavior of a mega-persona representing the demographic distribution of interest. We replicated surveys from 2019 to 2023 from leading SE conferences, examining ChatGPTs proficiency in mimicking responses from diverse demographics. Results: Our findings reveal that ChatGPT can successfully replicate the outcomes of some studies, but in others, the results were not significantly better than a random baseline. Conclusions: This paper reports our results so far and discusses the challenges and potential research opportunities in leveraging LLMs for representing humans in software engineering surveys.",
         "https://www.semanticscholar.org/paper/2a77ac8d1c36ccf9f222cf0ae16e251ac6b13e86",
         "7"
        ],
        [
         "29",
         "J",
         "Wahidur, RSM; Tashdeed, I; Kaur, M; Lee, HN",
         null,
         null,
         null,
         "Wahidur, Rahman S. M.; Tashdeed, Ishmam; Kaur, Manjit; Lee, Heung-No",
         null,
         null,
         "Enhancing Zero-Shot Crypto Sentiment With Fine-Tuned Language Model and Prompt Engineering",
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         "0",
         "enhancing zero shot crypto sentiment with fine tuned language model and prompt engineering",
         "bcdc44ef48ffadbdaa3bd5cacfe9ddb9b9f48750",
         "Enhancing Zero-Shot Crypto Sentiment With Fine-Tuned Language Model and Prompt Engineering",
         "2023",
         "Rahman S M Wahidur, Ishmam Tashdeed, Manjit Kaur, Heung-No Lee",
         "Blockchain technology has revolutionized the financial landscape, witnessing widespread adoption of cryptocurrencies due to their decentralized and transparent nature. As sentiments expressed on social media platforms wield substantial influence over cryptocurrency market dynamics, sentiment analysis has emerged as a crucial tool for gauging public opinion and predicting market trends. This paper explores fine-tuning techniques for large language models to enhance sentiment analysis performance. Experimental results demonstrate a significant average zero-shot performance gain of 40% on unseen tasks after fine-tuning, highlighting its potential. Additionally, the impact of instruction-based fine-tuning on models of varying scales is examined, revealing that larger models benefit from instruction tuning, achieving the highest average accuracy score of 75.16%. In contrast, smaller-scale models may experience reduced generalization due to complete model capacity utilization. To gain deeper insight into instruction effectiveness, the paper presents experimental investigations under different instruction tuning setups. Results show the model achieves an average accuracy score of 72.38% for short and simple instructions, outperforming long and complex instructions by over 12%. Finally, the paper explores the relationship between fine-tuning corpus size and model performance, identifying an optimal corpus size of 6,000 data points for the highest performance across different models. Microsofts MiniLM, a distilled version of BERT, excels in efficient data use and performance optimization, while Googles FLAN-T5 demonstrates consistent and reliable performance across diverse datasets.",
         "https://www.semanticscholar.org/paper/bcdc44ef48ffadbdaa3bd5cacfe9ddb9b9f48750",
         "17"
        ],
        [
         "30",
         "C",
         "Hwang, E; Majumder, BP; Tandon, N",
         null,
         "Bouamor, H; Pino, J; Bali K",
         null,
         "Hwang, EunJeong; Majumder, Bodhisattwa Prasad; Tandon, Niket",
         null,
         null,
         "Aligning Language Models to User Opinions",
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         "0",
         "aligning language models to user opinions",
         "5db0f55332839c408e3049cea1a6ad48fefba70c",
         "Aligning Language Models to User Opinions",
         "2023",
         "EunJeong Hwang, Bodhisattwa Prasad Majumder, Niket Tandon",
         "An important aspect of developing LLMs that interact with humans is to align models' behavior to their users. It is possible to prompt an LLM into behaving as a certain persona, especially a user group or ideological persona the model captured during its pertaining stage. But, how to best align an LLM with a specific user and not a demographic or ideological group remains an open question. Mining public opinion surveys (by Pew Research), we find that the opinions of a user and their demographics and ideologies are not mutual predictors. We use this insight to align LLMs by modeling both user opinions as well as user demographics and ideology, achieving up to 7 points accuracy gains in predicting public opinions from survey questions across a broad set of topics. In addition to the typical approach of prompting LLMs with demographics and ideology, we discover that utilizing the most relevant past opinions from individual users enables the model to predict user opinions more accurately.",
         "https://www.semanticscholar.org/paper/5db0f55332839c408e3049cea1a6ad48fefba70c",
         "82"
        ],
        [
         "31",
         "C",
         "Min, Y; Jeong, JW",
         null,
         "Eck, U; Sra, M; Stefanucci, J; Sugimoto, M; Tatzgern, M; Williams, I",
         null,
         "Min, Yewon; Jeong, Jin-Woo",
         null,
         null,
         "Public Speaking Q&A Practice with LLM-Generated Personas in Virtual Reality",
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         "0",
         "public speaking q a practice with llm generated personas in virtual reality",
         "3b36ec5f47076620dc7735f8aba55d9c3c3e6b32",
         "Public Speaking Q&A Practice with LLM-Generated Personas in Virtual Reality",
         "2024",
         "Yewon Min, Jin-Woo Jeong",
         "This paper introduces a novel VR-based Q&A practice system that harnesses the power of Large Language Models (LLMs). We support Q&A practice for upcoming public speaking by providing an immersive VR training environment populated with LLM-generated audiences, each capable of posing diverse and realistic questions based on different personas. We conducted a pilot user study involving 20 participants who engaged in VR-based Q&A practice sessions. The sessions featured a variety of questions regarding presentation material provided by the participants, all of which were generated by LLM-based personas. Through post-surveys and interviews, we evaluated the effectiveness of the proposed method. The participants valued the system for engagement and focus while also identifying several areas for improvement. Our study demonstrated the potential of integrating VR and LLMs to create a powerful, immersive tool for Q&A practice.",
         "https://www.semanticscholar.org/paper/3b36ec5f47076620dc7735f8aba55d9c3c3e6b32",
         "5"
        ],
        [
         "32",
         "C",
         "Liu, A; Diab, M; Fried, D",
         null,
         "Martins, A; Srikumar, V; Ku, LW",
         null,
         "Liu, Andy; Diab, Mona; Fried, Daniel",
         null,
         null,
         "Evaluating Large Language Model Biases in Persona-Steered Generation",
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         "0",
         "evaluating large language model biases in persona steered generation",
         "ae03f10729959435ecefc0e90cba4cbe8438a10b",
         "Evaluating Large Language Model Biases in Persona-Steered Generation",
         "2024",
         "Andy Liu, Mona T. Diab, Daniel Fried",
         "The task of persona-steered text generation requires large language models (LLMs) to generate text that reflects the distribution of views that an individual fitting a persona could have. People have multifaceted personas, but prior work on bias in LLM-generated opinions has only explored multiple-choice settings or one-dimensional personas. We define an incongruous persona as a persona with multiple traits where one trait makes its other traits less likely in human survey data, e.g. political liberals who support increased military spending. We find that LLMs are 9.7% less steerable towards incongruous personas than congruous ones, sometimes generating the stereotypical stance associated with its demographic rather than the target stance. Models that we evaluate that are fine-tuned with Reinforcement Learning from Human Feedback (RLHF) are more steerable, especially towards stances associated with political liberals and women, but present significantly less diverse views of personas. We also find variance in LLM steerability that cannot be predicted from multiple-choice opinion evaluation. Our results show the importance of evaluating models in open-ended text generation, as it can surface new LLM opinion biases. Moreover, such a setup can shed light on our ability to steer models toward a richer and more diverse range of viewpoints.",
         "https://www.semanticscholar.org/paper/ae03f10729959435ecefc0e90cba4cbe8438a10b",
         "49"
        ],
        [
         "33",
         "J",
         "Mishra, T; Sutanto, E; Rossanti, R; Pant, N; Ashraf, A; Raut, A; Uwabareze, G; Oluwatomiwa, A; Zeeshan, B",
         null,
         null,
         null,
         "Mishra, Tanisha; Sutanto, Edward; Rossanti, Rini; Pant, Nayana; Ashraf, Anum; Raut, Akshay; Uwabareze, Germaine; Oluwatomiwa, Ajayi; Zeeshan, Bushra",
         null,
         null,
         "Use of large language models as artificial intelligence tools in academic research and publishing among global clinical researchers",
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         "0",
         "use of large language models as artificial intelligence tools in academic research and publishing among global clinical researchers",
         "0c1e396f7f23d34ebad01dac29de6898f18ae63e",
         "Use of large language models as artificial intelligence tools in academic research and publishing among global clinical researchers",
         "2024",
         "Tanisha Mishra, Edward Sutanto, Rini Rossanti, Nayana Pant, Anum Ashraf, Akshay Raut, Germaine Uwabareze, Ajayi Oluwatomiwa, Bushra Zeeshan",
         "With breakthroughs in Natural Language Processing and Artificial Intelligence (AI), the usage of Large Language Models (LLMs) in academic research has increased tremendously. Models such as Generative Pre-trained Transformer (GPT) are used by researchers in literature review, abstract screening, and manuscript drafting. However, these models also present the attendant challenge of providing ethically questionable scientific information. Our study provides a snapshot of global researchers perception of current trends and future impacts of LLMs in research. Using a cross-sectional design, we surveyed 226 medical and paramedical researchers from 59 countries across 65 specialties, trained in the Global Clinical Scholars Research Training certificate program of Harvard Medical School between 2020 and 2024. Majority (57.5%) of these participants practiced in an academic setting with a median of 7 (2,18) PubMed Indexed published articles. 198 respondents (87.6%) were aware of LLMs and those who were aware had higher number of publications (p<0.001). 18.7% of the respondents who were aware (n=37) had previously used LLMs in publications especially for grammatical errors and formatting (64.9%); however, most (40.5%) did not acknowledge its use in their papers. 50.8% of aware respondents (n=95) predicted an overall positive future impact of LLMs while 32.6% were unsure of its scope. 52% of aware respondents (n=102) believed that LLMs would have a major impact in areas such as grammatical errors and formatting (66.3%), revision and editing (57.2%), writing (57.2%) and literature review (54.2%). 58.1% of aware respondents were opined that journals should allow for use of AI in research and 78.3% believed that regulations should be put in place to avoid its abuse. Seeing the perception of researchers towards LLMs and the significant association between awareness of LLMs and number of published works, we emphasize the importance of developing comprehensive guidelines and ethical framework to govern the use of AI in academic research and address the current challenges. Supplementary Information The online version contains supplementary material available at 10.1038/s41598-024-81370-6.",
         "https://www.semanticscholar.org/paper/0c1e396f7f23d34ebad01dac29de6898f18ae63e",
         "14"
        ],
        [
         "34",
         "J",
         "Teferra, BG; Perivolaris, A; Hsiang, WN; Sidharta, CK; Rueda, A; Parkington, K; Wu, YQ; Soni, A; Samavi, R; Jetly, R; Zhang, YB; Cao, B; Rambhatla, S; Krishnan, S; Bhat, V",
         null,
         null,
         null,
         "Teferra, Bazen Gashaw; Perivolaris, Argyrios; Hsiang, Wei-Ni; Sidharta, Christian Kevin; Rueda, Alice; Parkington, Karisa; Wu, Yuqi; Soni, Achint; Samavi, Reza; Jetly, Rakesh; Zhang, Yanbo; Cao, Bo; Rambhatla, Sirisha; Krishnan, Sri; Bhat, Venkat",
         null,
         null,
         "Leveraging large language models for automated depression screening",
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         "0",
         "leveraging large language models for automated depression screening",
         "d0deb3ffd586a886b435d67c1b3aad89eeeaf358",
         "Leveraging large language models for automated depression screening",
         "2025",
         "Bazen Gashaw Teferra, Argyrios Perivolaris, Wei-Ni Hsiang, Christian Kevin Sidharta, Alice Rueda, Karisa B. Parkington, Yuqi Wu, Achint Soni, Reza Samavi, Rakesh Jetly, Yanbo Zhang, Bo Cao, Sirisha Rambhatla, Sri Krishnan, Venkat Bhat",
         "Mental health diagnoses possess unique challenges that often lead to nuanced difficulties in managing an individuals well-being and daily functioning. Self-report questionnaires are a common practice in clinical settings to help mitigate the challenges involved in mental health disorder screening. However, these questionnaires rely on an individuals subjective response which can be influenced by various factors. Despite the advancements of Large Language Models (LLMs), quantifying self-reported experiences with natural language processing has resulted in imperfect accuracy. This project aims to demonstrate the effectiveness of zero-shot learning LLMs for screening and assessing item scales for depression using LLMs. The DAIC-WOZ is a publicly available mental health dataset that contains textual data from clinical interviews and self-report questionnaires with relevant mental health disorder labels. The RISEN prompt engineering framework was utilized to evaluate LLMs effectiveness in predicting depression symptoms based on individual PHQ-8 items. Various LLMs, including GPT models, Llama3_8B, Cohere, and Gemini were assessed based on performance. The GPT models, especially GPT-4o, were consistently better than other LLMs (Llama3_8B, Cohere, Gemini) across all eight items of the PHQ-8 scale in accuracy (M=75.9%), and F1 score (0.74). GPT models were able to predict PHQ-8 items related to emotional and cognitive states. Llama 3_8B demonstrated superior detection of anhedonia-related symptoms and the Cohere LLMs strength was identifying and predicting psychomotor activity symptoms. This study provides a novel outlook on the potential of LLMs for predicting self-reported questionnaire scores from textual interview data. The promising preliminary performance of the various models indicates there is potential that these models could effectively assist in the screening of depression. Further research is needed to establish a framework for which LLM can be used for specific mental health symptoms and other disorders. As well, analysis of additional datasets while fine-tuning models should be explored.",
         "https://www.semanticscholar.org/paper/d0deb3ffd586a886b435d67c1b3aad89eeeaf358",
         "0"
        ],
        [
         "35",
         "J",
         "Bachmann, F; van der Weijden, D; Heitz, L; Sarasua, C; Bernstein, A",
         null,
         null,
         null,
         "Bachmann, Fynn; van der Weijden, Daan; Heitz, Lucien; Sarasua, Cristina; Bernstein, Abraham",
         null,
         null,
         "Adaptive political surveys and GPT-4: Tackling the cold start problem with simulated user interactions",
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         "0",
         "adaptive political surveys and gpt 4 tackling the cold start problem with simulated user interactions",
         "1d1097d378555393b73b492995121ab880fff142",
         "Adaptive political surveys and GPT-4: Tackling the cold start problem with simulated user interactions",
         "2025",
         "Fynn Bachmann, Daan van der Weijden, Lucien Heitz, Cristina Sarasua, Abraham Bernstein",
         "Adaptive questionnaires dynamically select the next question for a survey participant based on their previous answers. Due to digitalisation, they have become a viable alternative to traditional surveys in application areas such as political science. One limitation, however, is their dependency on data to train the model for question selection. Often, such training data (i.e., user interactions) are unavailable a priori. To address this problem, we (i) test whether Large Language Models (LLM) can accurately generate such interaction data and (ii) explore if these synthetic data can be used to pre-train the statistical model of an adaptive political survey. To evaluate this approach, we utilise existing data from the Swiss Voting Advice Application (VAA) Smartvote in two ways: First, we compare the distribution of LLM-generated synthetic data to the real distribution to assess its similarity. Second, we compare the performance of an adaptive questionnaire that is randomly initialised with one pre-trained on synthetic data to assess their suitability for training. We benchmark these results against an oracle questionnaire with perfect prior knowledge. We find that an off-the-shelf LLM (GPT-4) accurately generates answers to the Smartvote questionnaire from the perspective of different Swiss parties. Furthermore, we demonstrate that initialising the statistical model with synthetic data can (i) significantly reduce the error in predicting user responses and (ii) increase the candidate recommendation accuracy of the VAA. Our work emphasises the considerable potential of LLMs to create training data to improve the data collection process in adaptive questionnaires in LLM-affine areas such as political surveys.",
         "https://www.semanticscholar.org/paper/1d1097d378555393b73b492995121ab880fff142",
         "1"
        ],
        [
         "36",
         "C",
         "Mancera, J; Tern, L",
         null,
         "Liao, HC; Cid, DD; Macadar, MA; Bernardini, F",
         null,
         "Mancera, Jose; Teran, Luis",
         null,
         null,
         "From GenAI to Political Profiling Avatars: A Data-Driven Approach to Crafting Virtual Experts for Voting Advice Applications",
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         "0",
         "from genai to political profiling avatars a data driven approach to crafting virtual experts for voting advice applications",
         "3084188f92330fa837a87b6ca422b28ae1ca713c",
         "From GenAI to Political Profiling Avatars: A Data-Driven Approach to Crafting Virtual Experts for Voting Advice Applications",
         "2024",
         "Jos Alberto Mancera Andrade, Luis Tern",
         "Voting advice applications (VAAs) are pivotal web-based tools that guide citizens to align with political parties and candidates that match their preferences. Traditional methods for creating candidate profiles predominantly rely on questionnaire responses, a time-intensive and costly process. To address these challenges, we introduce a data-centric methodology utilizing generative artificial intelligence (GenAI), culminating in creating political avatars. These political avatars are engineered using cutting-edge large language models (LLMs), including GPT-4 and Bard. They are adept at processing and interpreting data primarily sourced from Twitter and leveraging bespoke, self-trained datasets. Integrating advanced AI technology with diverse data sources equips political avatars with unprecedented analytical and predictive capabilities, setting a new standard in political analysis. Unlike traditional methods, political avatars are adept at emulating the responses of real politicians or experts, showcasing a remarkable capacity to interact with VAA surveys. This novel approach presents the potential to either compete with or enhance the insights traditionally obtained from human experts. Another critical aspect of our study is comparing political avatars and previous research employing question-answering (QA) models based on advanced natural language processing (NLP) techniques for political profiling. This comparative analysis reveals that Political Avatars offer a significantly more robust solution for profile construction. While QA models provide structured responses based on specific queries, political avatars bring an element of dynamism and depth, capable of generating nuanced, context-aware responses. This shift from static, questionnaire-based profiling to dynamic, AI-driven avatars marks a substantial leap in political analysis. Generative AI in crafting Political Avatars introduces a transformative element to data analysis. This approach facilitates a layered and more sophisticated interpretation of political stances, moving beyond the limitations of traditional profiling methods. By employing political avatars, our methodology not only streamlines the profiling process but also enriches the quality of insights derived, paving the way for a more nuanced understanding of the political landscape.",
         "https://www.semanticscholar.org/paper/3084188f92330fa837a87b6ca422b28ae1ca713c",
         "1"
        ],
        [
         "37",
         "C",
         "Kaate, I; Salminen, J; Jung, SG; Xuan, TTT; Hyhnen, E; Azem, JY; Jansen, BJ",
         null,
         null,
         "ACM",
         "Kaate, Ilkka; Salminen, Joni; Jung, Soon-Gyo; Trang Thi Thu Xuan; Hayhanen, Essi; Azem, Jinan Y.; Jansen, Bernard J.",
         null,
         null,
         "You Always Get an Answer: Analyzing Users' Interaction with AI-Generated Personas Given Unanswerable Questions and Risk of Hallucination",
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         "0",
         "you always get an answer analyzing users interaction with ai generated personas given unanswerable questions and risk of hallucination",
         "48ebe4b39ff2dce8d6c026f6cd2cbea8406a9a6e",
         "You Always Get an Answer: Analyzing Users Interaction with AI-Generated Personas Given Unanswerable Questions and Risk of Hallucination",
         "2025",
         "Ilkka Kaate, Joni O. Salminen, Soon-gyo Jung, T. Xuan, Essi Hyhnen, Jinan Y. Azem, Bernard J. Jansen",
         "We investigated the presence and acceptance of hallucinations (i.e., accidental misinformation) of an AI-generated persona system that leverages large language models for persona creation from survey data in a 54-user within-subjects experiment. After interacting with the personas, users were given a task to ask the personas a series of questions, including an unanswerable question, meaning the personas lacked the data to answer the question. The AI-generated persona system provided a plausible but incorrect answer half (52%) of the time, and more than half of the time (57%), the users accepted the incorrect answer, and the rest of the time, users answered the unanswerable question correctly (no answer). We found that when the AI-generated persona hallucinated, the user was significantly more likely to answer the unanswerable question incorrectly. Also, for genders separately, when the AI-generated persona hallucinated, it was significantly more likely for the female user and the male users to answer the unanswerable question incorrectly. We identified four themes in the AI-generated persona's answers and found that users perceive AI-generated persona's answers as long and unclear for the unanswerable question. Findings imply that personas leveraging LLMs require guardrails to ensure that personas clearly state the possibility of data restrictions and hallucinations when asked unanswerable questions.",
         "https://www.semanticscholar.org/paper/48ebe4b39ff2dce8d6c026f6cd2cbea8406a9a6e",
         "3"
        ],
        [
         "38",
         "J",
         "Hadar-Shoval, D; Asraf, K; Mizrachi, Y; Haber, Y; Elyoseph, Z",
         null,
         null,
         null,
         "Hadar-Shoval, Dorit; Asraf, Kfir; Mizrachi, Yonathan; Haber, Yuval; Elyoseph, Zohar",
         null,
         null,
         "Assessing the Alignment of Large Language Models With Human Values for Mental Health Integration: Cross-Sectional Study Using Schwartz's Theory of Basic Values",
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         "0",
         "assessing the alignment of large language models with human values for mental health integration cross sectional study using schwartz s theory of basic values",
         "3a455a00d01fcd45d7797f296eb5b5db331ff7b1",
         "Assessing the Alignment of Large Language Models With Human Values for Mental Health Integration: Cross-Sectional Study Using Schwartzs Theory of Basic Values",
         "2024",
         "D. Hadar-Shoval, K. Asraf, Yonathan Mizrachi, Yuval Haber, Zohar Elyoseph",
         "Background Large language models (LLMs) hold potential for mental health applications. However, their opaque alignment processes may embed biases that shape problematic perspectives. Evaluating the values embedded within LLMs that guide their decision-making have ethical importance. Schwartzs theory of basic values (STBV) provides a framework for quantifying cultural value orientations and has shown utility for examining values in mental health contexts, including cultural, diagnostic, and therapist-client dynamics. Objective This study aimed to (1) evaluate whether the STBV can measure value-like constructs within leading LLMs and (2) determine whether LLMs exhibit distinct value-like patterns from humans and each other. Methods In total, 4 LLMs (Bard, Claude 2, Generative Pretrained Transformer [GPT]-3.5, GPT-4) were anthropomorphized and instructed to complete the Portrait Values QuestionnaireRevised (PVQ-RR) to assess value-like constructs. Their responses over 10 trials were analyzed for reliability and validity. To benchmark the LLMs value profiles, their results were compared to published data from a diverse sample of 53,472 individuals across 49 nations who had completed the PVQ-RR. This allowed us to assess whether the LLMs diverged from established human value patterns across cultural groups. Value profiles were also compared between models via statistical tests. Results The PVQ-RR showed good reliability and validity for quantifying value-like infrastructure within the LLMs. However, substantial divergence emerged between the LLMs value profiles and population data. The models lacked consensus and exhibited distinct motivational biases, reflecting opaque alignment processes. For example, all models prioritized universalism and self-direction, while de-emphasizing achievement, power, and security relative to humans. Successful discriminant analysis differentiated the 4 LLMs distinct value profiles. Further examination found the biased value profiles strongly predicted the LLMs responses when presented with mental health dilemmas requiring choosing between opposing values. This provided further validation for the models embedding distinct motivational value-like constructs that shape their decision-making. Conclusions This study leveraged the STBV to map the motivational value-like infrastructure underpinning leading LLMs. Although the study demonstrated the STBV can effectively characterize value-like infrastructure within LLMs, substantial divergence from human values raises ethical concerns about aligning these models with mental health applications. The biases toward certain cultural value sets pose risks if integrated without proper safeguards. For example, prioritizing universalism could promote unconditional acceptance even when clinically unwise. Furthermore, the differences between the LLMs underscore the need to standardize alignment processes to capture true cultural diversity. Thus, any responsible integration of LLMs into mental health care must account for their embedded biases and motivation mismatches to ensure equitable delivery across diverse populations. Achieving this will require transparency and refinement of alignment techniques to instill comprehensive human values.",
         "https://www.semanticscholar.org/paper/3a455a00d01fcd45d7797f296eb5b5db331ff7b1",
         "36"
        ],
        [
         "39",
         "J",
         "Amirova, A; Fteropoulli, T; Ahmed, N; Cowie, MR; Leibo, JZ",
         null,
         null,
         null,
         "Amirova, Aliya; Fteropoulli, Theodora; Ahmed, Nafiso; Cowie, Martin R.; Leibo, Joel Z.",
         null,
         null,
         "Framework-based qualitative analysis of free responses of Large Language Models: Algorithmic fidelity",
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         "0",
         "framework based qualitative analysis of free responses of large language models algorithmic fidelity",
         "ba5aefce80edc7da110f53fd071f4fbd6b5195b9",
         "Framework-based qualitative analysis of free responses of Large Language Models: Algorithmic fidelity",
         "2023",
         "A. Amirova, T. Fteropoulli, Nafiso Ahmed, Martin R. Cowie, Joel Z. Leibo",
         "Today, with the advent of Large-scale generative Language Models (LLMs) it is now possible to simulate free responses to interview questions such as those traditionally analyzed using qualitative research methods. Qualitative methodology encompasses a broad family of techniques involving manual analysis of open-ended interviews or conversations conducted freely in natural language. Here we consider whether artificial silicon participants generated by LLMs may be productively studied using qualitative analysis methods in such a way as to generate insights that could generalize to real human populations. The key concept in our analysis is algorithmic fidelity, a validity concept capturing the degree to which LLM-generated outputs mirror human sub-populations beliefs and attitudes. By definition, high algorithmic fidelity suggests that latent beliefs elicited from LLMs may generalize to real humans, whereas low algorithmic fidelity renders such research invalid. Here we used an LLM to generate interviews with silicon participants matching specific demographic characteristics one-for-one with a set of human participants. Using framework-based qualitative analysis, we showed the key themes obtained from both human and silicon participants were strikingly similar. However, when we analyzed the structure and tone of the interviews we found even more striking differences. We also found evidence of a hyper-accuracy distortion. We conclude that the LLM we tested (GPT-3.5) does not have sufficient algorithmic fidelity to expect in silico research on it to generalize to real human populations. However, rapid advances in artificial intelligence raise the possibility that algorithmic fidelity may improve in the future. Thus we stress the need to establish epistemic norms now around how to assess the validity of LLM-based qualitative research, especially concerning the need to ensure the representation of heterogeneous lived experiences.",
         "https://www.semanticscholar.org/paper/ba5aefce80edc7da110f53fd071f4fbd6b5195b9",
         "14"
        ],
        [
         "40",
         "J",
         "Sumner, J; Wang, YC; Tan, SY; Chew, EHH; Yip, AW",
         null,
         null,
         null,
         "Sumner, Jennifer; Wang, Yuchen; Tan, Si Ying; Chew, Emily Hwee Hoon; Yip, Alexander Wenjun",
         null,
         null,
         "Perspectives and Experiences With Large Language Models in Health Care: Survey Study",
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         "0",
         "perspectives and experiences with large language models in health care survey study",
         "db593a47eec5f6dbd9f28e88d0e4d7450cc6376b",
         "Perspectives and Experiences With Large Language Models in Health Care: Survey Study",
         "2025",
         "Jennifer Sumner, Yuchen Wang, Si Ying Tan, Emily Hwee Hoon Chew, Alexander Wenjun Yip",
         "Background Large language models (LLMs) are transforming how data is used, including within the health care sector. However, frameworks including the Unified Theory of Acceptance and Use of Technology highlight the importance of understanding the factors that influence technology use for successful implementation. Objective This study aimed to (1) investigate users uptake, perceptions, and experiences regarding LLMs in health care and (2) contextualize survey responses by demographics and professional profiles. Methods An electronic survey was administered to elicit stakeholder perspectives of LLMs (health care providers and support functions), their experiences with LLMs, and their potential impact on functional roles. Survey domains included: demographics (6 questions), user experiences of LLMs (8 questions), motivations for using LLMs (6 questions), and perceived impact on functional roles (4 questions). The survey was launched electronically, targeting health care providers or support staff, health care students, and academics in health-related fields. Respondents were adults (>18 years) aware of LLMs. Results Responses were received from 1083 individuals, of which 845 were analyzable. Of the 845 respondents, 221 had yet to use an LLM. Nonusers were more likely to be health care workers (P<.001), older (P<.001), and female (P<.01). Users primarily adopted LLMs for speed, convenience, and productivity. While 75% (470/624) agreed that the user experience was positive, 46% (294/624) found the generated content unhelpful. Regression analysis showed that the experience with LLMs is more likely to be positive if the user is male (odds ratio [OR] 1.62, CI 1.06-2.48), and increasing age was associated with a reduced likelihood of reporting LLM output as useful (OR 0.98, CI 0.96-0.99). Nonusers compared to LLM users were less likely to report LLMs meeting unmet needs (45%, 99/221 vs 65%, 407/624; OR 0.48, CI 0.35-0.65), and males were more likely to report that LLMs do address unmet needs (OR 1.64, CI 1.18-2.28). Furthermore, nonusers compared to LLM users were less likely to agree that LLMs will improve functional roles (63%, 140/221 vs 75%, 469/624; OR 0.60, CI 0.43-0.85). Free-text opinions highlighted concerns regarding autonomy, outperformance, and reduced demand for care. Respondents also predicted changes to human interactions, including fewer but higher quality interactions and a change in consumer needs as LLMs become more common, which would require provider adaptation. Conclusions Despite the reported benefits of LLMs, nonusersprimarily health care workers, older individuals, and femalesappeared more hesitant to adopt these tools. These findings underscore the need for targeted education and support to address adoption barriers and ensure the successful integration of LLMs in health care. Anticipated role changes, evolving human interactions, and the risk of the digital divide further emphasize the need for careful implementation and ongoing evaluation of LLMs in health care to ensure equity and sustainability.",
         "https://www.semanticscholar.org/paper/db593a47eec5f6dbd9f28e88d0e4d7450cc6376b",
         "1"
        ],
        [
         "41",
         "J",
         "Rdel-Ablass, K; Schliz, K; Schlick, C; Meindl, B; Pahr-Hosbach, S; Schwendemann, H; Rupp, S; Roddewig, M; Miersch, C",
         null,
         null,
         null,
         "Raedel-Ablass, Katharina; Schliz, Klaus; Schlick, Cornelia; Meindl, Benjamin; Pahr-Hosbach, Sandra; Schwendemann, Hanna; Rupp, Stephanie; Roddewig, Marion; Miersch, Claudia",
         null,
         null,
         "Teaching opportunities for anamnesis interviews through AI based teaching role plays: a survey with online learning students from health study programs",
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         "0",
         "teaching opportunities for anamnesis interviews through ai based teaching role plays a survey with online learning students from health study programs",
         "d46b4155182de3a385b8f0b323ca54a201e1c60f",
         "Teaching opportunities for anamnesis interviews through AI based teaching role plays: a survey with online learning students from health study programs",
         "2025",
         "Katharina Rdel-Ablass, Klaus Schliz, Cornelia Schlick, Benjamin Meindl, Sandra Pahr-Hosbach, Hanna Schwendemann, Stephanie Rupp, Marion Roddewig, Claudia Miersch",
         "Background This study presents a novel approach to educational role-playing through an AI-based bot, leveraging GPT-4 to simulate anamnesis interviews in various learning scenarios. Developed collaboratively by an interdisciplinary team of university lecturers and AI experts, the bot provides a platform for students of different health study programs to engage in complex patient-health professional conversations, offering an alternative to traditional role plays with actors or real patients. Methods This study utilized a GPT-4 based digital teaching assistant, implemented through a proprietary chatbot design platform, to train anamnesis interviews in virtual settings with students from different online health care study programs. Students satisfaction, virtual patients accuracy, its realism, and quality were evaluated with a quantitative survey. Results The evaluation of the bot focused on student feedback, highlighting a preference for the AI-driven method due to its immersive and interactive nature. Preliminary results show that students consistently rate the language ability of the AI model positively. More than 80% of students rated the professional and content-related precision of the virtual patient as good to excellent. Even as a text-based chatbot, the vast majority of students see a fairly close to very close relationship to a real anamnesis interview. The results further indicate that students even prefer this training approach to traditional in-person role-plays. Conclusions The study underscores the bots potential as a versatile tool for enriching learning experiences across multiple health disciplines, signaling a meaningful shift in educational practices towards the integration of AI technologies. Supplementary Information The online version contains supplementary material available at 10.1186/s12909-025-06756-0.",
         "https://www.semanticscholar.org/paper/d46b4155182de3a385b8f0b323ca54a201e1c60f",
         "8"
        ],
        [
         "42",
         "J",
         "Lau, C; Zhu, XD; Chan, WY",
         null,
         null,
         null,
         "Lau, Clinton; Zhu, Xiaodan; Chan, Wai-Yip",
         null,
         null,
         "Automatic depression severity assessment with deep learning using parameter-efficient tuning",
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         "0",
         "automatic depression severity assessment with deep learning using parameter efficient tuning",
         "527288d9ded807883d756f1b3503bc39e79e0a06",
         "Automatic depression severity assessment with deep learning using parameter-efficient tuning",
         "2023",
         "Clinton Lau, Xiaodan Zhu, Wai-Yip Chan",
         "Introduction To assist mental health care providers with the assessment of depression, research to develop a standardized, accessible, and non-invasive technique has garnered considerable attention. Our study focuses on the application of deep learning models for automatic assessment of depression severity based on clinical interview transcriptions. Despite the recent success of deep learning, the lack of large-scale high-quality datasets is a major performance bottleneck for many mental health applications. Methods A novel approach is proposed to address the data scarcity problem for depression assessment. It leverages both pretrained large language models and parameter-efficient tuning techniques. The approach is built upon adapting a small set of tunable parameters, known as prefix vectors, to guide a pretrained model towards predicting the Patient Health Questionnaire (PHQ)-8 score of a person. Experiments were conducted on the Distress Analysis Interview Corpus - Wizard of Oz (DAIC-WOZ) benchmark dataset with 189 subjects, partitioned into training, development, and test sets. Model learning was done on the training set. Prediction performance mean and standard deviation of each model, with five randomly-initialized runs, were reported on the development set. Finally, optimized models were evaluated on the test set. Results The proposed model with prefix vectors outperformed all previously published methods, including models which utilized multiple types of data modalities, and achieved the best reported performance on the test set of DAIC-WOZ with a root mean square error of 4.67 and a mean absolute error of 3.80 on the PHQ-8 scale. Compared to conventionally fine-tuned baseline models, prefix-enhanced models were less prone to overfitting by using far fewer training parameters (<6% relatively). Discussion While transfer learning through pretrained large language models can provide a good starting point for downstream learning, prefix vectors can further adapt the pretrained models effectively to the depression assessment task by only adjusting a small number of parameters. The improvement is in part due to the fine-grain flexibility of prefix vector size in adjusting the model's learning capacity. Our results provide evidence that prefix-tuning can be a useful approach in developing tools for automatic depression assessment.",
         "https://www.semanticscholar.org/paper/527288d9ded807883d756f1b3503bc39e79e0a06",
         "20"
        ],
        [
         "43",
         "J",
         "Heston, TF",
         null,
         null,
         null,
         "Heston, Thomas F.",
         null,
         null,
         "Safety of Large Language Models in Addressing Depression",
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         "0",
         "safety of large language models in addressing depression",
         "1554d7e72a8b5bcad108ff1d0c9014ddfaaebd0f",
         "Safety of Large Language Models in Addressing Depression",
         "2023",
         "T. F. Heston",
         "Background Generative artificial intelligence (AI) models, exemplified by systems such as ChatGPT, Bard, and Anthropic, are currently under intense investigation for their potential to address existing gaps in mental health support. One implementation of these large language models involves the development of mental health-focused conversational agents, which utilize pre-structured prompts to facilitate user interaction without requiring specialized knowledge in prompt engineering. However, uncertainties persist regarding the safety and efficacy of these agents in recognizing severe depression and suicidal tendencies. Given the well-established correlation between the severity of depression and the risk of suicide, improperly calibrated conversational agents may inadequately identify and respond to crises. Consequently, it is crucial to investigate whether publicly accessible repositories of mental health-focused conversational agents can consistently and safely address crisis scenarios before considering their adoption in clinical settings. This study assesses the safety of publicly available ChatGPT-3.5 conversational agents by evaluating their responses to a patient simulation indicating worsening depression and suicidality. Methodology This study evaluated ChatGPT-3.5 conversational agents on a publicly available repository specifically designed for mental health counseling. Each conversational agent was evaluated twice by a highly structured patient simulation. First, the simulation indicated escalating suicide risk based on the Patient Health Questionnaire (PHQ-9). For the second patient simulation, the escalating risk was presented in a more generalized manner not associated with an existing risk scale to assess the more generalized ability of the conversational agent to recognize suicidality. Each simulation recorded the exact point at which the conversational agent recommended human support. Then, the simulation continued until the conversational agent stopped entirely and shut down completely, insisting on human intervention. Results All 25 agents available on the public repository FlowGPT.com were evaluated. The point at which the conversational agents referred to a human occurred around the mid-point of the simulation, and definitive shutdown predominantly only happened at the highest risk levels. For the PHQ-9 simulation, the average initial referral and shutdown aligned with PHQ-9 scores of 12 (moderate depression) and 25 (severe depression). Few agents included crisis resources - only two referenced suicide hotlines. Despite the conversational agents insisting on human intervention, 22 out of 25 agents would eventually resume the dialogue if the simulation reverted to a lower risk level. Conclusions Current generative AI-based conversational agents are slow to escalate mental health risk scenarios, postponing referral to a human to potentially dangerous levels. More rigorous testing and oversight of conversational agents are needed before deployment in mental healthcare settings. Additionally, further investigation should explore if sustained engagement worsens outcomes and whether enhanced accessibility outweighs the risks of improper escalation. Advancing AI safety in mental health remains imperative as these technologies continue rapidly advancing.",
         "https://www.semanticscholar.org/paper/1554d7e72a8b5bcad108ff1d0c9014ddfaaebd0f",
         "43"
        ],
        [
         "44",
         "J",
         "Hanss, K; Sarma, K; Glowinski, AL; Krystal, A; Saunders, R; Halls, A; Gorrell, S; Reilly, E",
         null,
         null,
         null,
         "Hanss, Kaitlin; Sarma, Karthik, V; Glowinski, Anne L.; Krystal, Andrew; Saunders, Ramotse; Halls, Andrew; Gorrell, Sasha; Reilly, Erin",
         null,
         null,
         "Assessing the Accuracy and Reliability of Large Language Models in Psychiatry Using Standardized Multiple-Choice Questions: Cross-Sectional Study",
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         "0",
         "assessing the accuracy and reliability of large language models in psychiatry using standardized multiple choice questions cross sectional study",
         "faf47d35147d836bcc03bffda819db2426febac8",
         "Assessing the Accuracy and Reliability of Large Language Models in Psychiatry Using Standardized Multiple-Choice Questions: Cross-Sectional Study",
         "2025",
         "Kaitlin Hanss, Karthik V Sarma, Anne L Glowinski, Andrew Krystal, Ramotse Saunders, Andrew Halls, S. Gorrell, E. Reilly",
         "Background Large language models (LLMs), such as OpenAIs GPT-3.5, GPT-4, and GPT-4o, have garnered early and significant enthusiasm for their potential applications within mental health, ranging from documentation support to chat-bot therapy. Understanding the accuracy and reliability of the psychiatric knowledge stored within the parameters of these models and developing measures of confidence in their responses (ie, the likelihood that an LLM response is accurate) are crucial for the safe and effective integration of these tools into mental health settings. Objective This study aimed to assess the accuracy, reliability, and predictors of accuracy of GPT-3.5 (175 billion parameters), GPT-4 (approximately 1.8 trillion parameters), and GPT-4o (an optimized version of GPT-4 with unknown parameters) with standardized psychiatry multiple-choice questions (MCQs). Methods A cross-sectional study was conducted where 3 commonly available, commercial LLMs (GPT-3.5, GPT-4, and GPT-4o) were tested for their ability to provide answers to single-answer MCQs (N=150) extracted from the Psychiatry Test Preparation and Review Manual. Each model generated answers to every MCQ 10 times. We evaluated the accuracy and reliability of the answers and sought predictors of answer accuracy. Our primary outcome was the proportion of questions answered correctly by each LLM (accuracy). Secondary measures were (1) response consistency to MCQs across 10 trials (reliability), (2) the correlation between MCQ answer accuracy and response consistency, and (3) the correlation between MCQ answer accuracy and model self-reported confidence. Results On the first attempt, GPT-3.5 answered 58.0% (87/150) of MCQs correctly, while GPT-4 and GPT-4o answered 84.0% (126/150) and 87.3% (131/150) correctly, respectively. GPT-4 and GPT-4o showed no difference in performance (P=.51), but they significantly outperformed GPT-3.5 (P<.001). GPT-3.5 exhibited less response consistency on average compared to the other models (P<.001). MCQ response consistency was positively correlated with MCQ accuracy across all models (r=0.340, 0.682, and 0.590 for GPT-3.5, GPT-4, and GPT-4o, respectively; all P<.001), whereas model self-reported confidence showed no correlation with accuracy in the models, except for GPT-3.5, where self-reported confidence was weakly inversely correlated with accuracy (P<.001). Conclusions To our knowledge, this is the first comprehensive evaluation of the general psychiatric knowledge encoded in commercially available LLMs and the first study to assess their reliability and identify predictors of response accuracy within medical domains. The findings suggest that GPT-4 and GPT-4o encode accurate and reliable general psychiatric knowledge and that methods, such as repeated prompting, may provide a measure of LLM response confidence. This work supports the potential of LLMs in mental health settings and motivates further research to assess their performance in more open-ended clinical contexts.",
         "https://www.semanticscholar.org/paper/faf47d35147d836bcc03bffda819db2426febac8",
         "2"
        ],
        [
         "45",
         "J",
         "Alsalamah, SA; AlSalamah, S; Alsalamah, HA; Sheerah, HA; Luther, K; Lu, CT",
         null,
         null,
         null,
         "Alsalamah, Sara A.; AlSalamah, Shada; Alsalamah, Hessah A.; Sheerah, Haytham A.; Luther, Kurt; Lu, Chang-Tien",
         null,
         null,
         "Virtual healthcare bot (VHC-Bot): a Person-centered AI chatbot for transforming patient care and healthcare workforce dynamics",
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         "0",
         "virtual healthcare bot vhc bot a person centered ai chatbot for transforming patient care and healthcare workforce dynamics",
         "4408852e43dcff9da71f1053f6aeefbea10db450",
         "Virtual healthcare bot (VHC-Bot): a Person-centered AI chatbot for transforming patient care and healthcare workforce dynamics",
         "2025",
         "Sara A. Alsalamah, Shada Alsalamah, Hessah A. Alsalamah, Haytham A. Sheerah, Kurt Luther, Chang-Tien Lu",
         null,
         "https://www.semanticscholar.org/paper/4408852e43dcff9da71f1053f6aeefbea10db450",
         "0"
        ],
        [
         "46",
         "J",
         "Nguyen, MH; Sedoc, J; Taylor, CO",
         null,
         null,
         null,
         "Nguyen, Michelle Hoang; Sedoc, Joao; Taylor, Casey Overby",
         null,
         null,
         "Usability, Engagement, and Report Usefulness of Chatbot-Based Family Health History Data Collection: Mixed Methods Analysis",
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         "0",
         "usability engagement and report usefulness of chatbot based family health history data collection mixed methods analysis",
         "cddaccfd097ba11b991829930f95d0abd6a9dade",
         "Usability, Engagement, and Report Usefulness of Chatbot-Based Family Health History Data Collection: Mixed Methods Analysis",
         "2024",
         "M. Nguyen, Joo Sedoc, C. O. Taylor",
         "Background Family health history (FHx) is an important predictor of a persons genetic risk but is not collected by many adults in the United States. Objective This study aims to test and compare the usability, engagement, and report usefulness of 2 web-based methods to collect FHx. Methods This mixed methods study compared FHx data collection using a flow-based chatbot (KIT; the curious interactive test) and a form-based method. KITs design was optimized to reduce user burden. We recruited and randomized individuals from 2 crowdsourced platforms to 1 of the 2 FHx methods. All participants were asked to complete a questionnaire to assess the methods usability, the usefulness of a report summarizing their experience, user-desired chatbot enhancements, and general user experience. Engagement was studied using log data collected by the methods. We used qualitative findings from analyzing free-text comments to supplement the primary quantitative results. Results Participants randomized to KIT reported higher usability than those randomized to the form, with a mean System Usability Scale score of 80.2 versus 61.9 (P<.001), respectively. The engagement analysis reflected design differences in the onboarding process. KIT users spent less time entering FHx information and reported more conditions than form users (mean 5.90 vs 7.97 min; P=.04; and mean 7.8 vs 10.1 conditions; P=.04). Both KIT and form users somewhat agreed that the report was useful (Likert scale ratings of 4.08 and 4.29, respectively). Among desired enhancements, personalization was the highest-rated feature (188/205, 91.7% rated medium- to high-priority). Qualitative analyses revealed positive and negative characteristics of both KIT and the form-based method. Among respondents randomized to KIT, most indicated it was easy to use and navigate and that they could respond to and understand user prompts. Negative comments addressed KITs personality, conversational pace, and ability to manage errors. For KIT and form respondents, qualitative results revealed common themes, including a desire for more information about conditions and a mutual appreciation for the multiple-choice button response format. Respondents also said they wanted to report health information beyond KITs prompts (eg, personal health history) and for KIT to provide more personalized responses. Conclusions We showed that KIT provided a usable way to collect FHx. We also identified design considerations to improve chatbot-based FHx data collection: First, the final report summarizing the FHx collection experience should be enhanced to provide more value for patients. Second, the onboarding chatbot prompt may impact data quality and should be carefully considered. Finally, we highlighted several areas that could be improved by moving from a flow-based chatbot to a large language model implementation strategy.",
         "https://www.semanticscholar.org/paper/cddaccfd097ba11b991829930f95d0abd6a9dade",
         "2"
        ],
        [
         "47",
         "J",
         "Safrai, M; Azaria, A",
         null,
         null,
         null,
         "Safrai, Myriam; Azaria, Amos",
         null,
         null,
         "Does small talk with a medical provider affect ChatGPT's medical counsel? Performance of ChatGPT on USMLE with and without distractions",
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         "0",
         "does small talk with a medical provider affect chatgpt s medical counsel performance of chatgpt on usmle with and without distractions",
         "dc8ed1d85c4674181746ffe8f08e86e00d0054ff",
         "Does small talk with a medical provider affect ChatGPT's medical counsel? Performance of ChatGPT on USMLE with and without distractions.",
         "2024",
         "Myriam Safrai, A. Azaria",
         "Efforts are being made to improve the time effectiveness of healthcare providers. Artificial intelligence tools can help transcript and summarize physician-patient encounters and produce medical notes and medical recommendations. However, in addition to medical information, discussion between healthcare and patients includes small talk and other information irrelevant to medical concerns. As Large Language Models (LLMs) are predictive models building their response based on the words in the prompts, there is a risk that small talk and irrelevant information may alter the response and the suggestion given. Therefore, this study aims to investigate the impact of medical data mixed with small talk on the accuracy of medical advice provided by ChatGPT. USMLE step 3 questions were used as a model for relevant medical data. We use both multiple-choice and open-ended questions. First, we gathered small talk sentences from human participants using the Mechanical Turk platform. Second, both sets of USLME questions were arranged in a pattern where each sentence from the original questions was followed by a small talk sentence. ChatGPT 3.5 and 4 were asked to answer both sets of questions with and without the small talk sentences. Finally, a board-certified physician analyzed the answers by ChatGPT and compared them to the formal correct answer. The analysis results demonstrate that the ability of ChatGPT-3.5 to answer correctly was impaired when small talk was added to medical data (66.8% vs. 56.6%; p = 0.025). Specifically, for multiple-choice questions (72.1% vs. 68.9%; p = 0.67) and for the open questions (61.5% vs. 44.3%; p = 0.01), respectively. In contrast, small talk phrases did not impair ChatGPT-4 ability in both types of questions (83.6% and 66.2%, respectively). According to these results, ChatGPT-4 seems more accurate than the earlier 3.5 version, and it appears that small talk does not impair its capability to provide medical recommendations. Our results are an important first step in understanding the potential and limitations of utilizing ChatGPT and other LLMs for physician-patient interactions, which include casual conversations.",
         "https://www.semanticscholar.org/paper/dc8ed1d85c4674181746ffe8f08e86e00d0054ff",
         "1"
        ],
        [
         "48",
         "J",
         "Patsia, O; Giannopoulos, A; Giannakis, I",
         null,
         null,
         null,
         "Patsia, Ourania; Giannopoulos, Antonios; Giannakis, Iraklis",
         null,
         null,
         "GPR Full-Waveform Inversion With Deep-Learning Forward Modeling: A Case Study From Non-Destructive Testing",
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         "0",
         "gpr full waveform inversion with deep learning forward modeling a case study from non destructive testing",
         "0be15269dffa995e0c2859ed9c354ad4e916632b",
         "GPR Full-Waveform Inversion With Deep-Learning Forward Modeling: A Case Study From Non-Destructive Testing",
         "2023",
         "O. Patsia, A. Giannopoulos, I. Giannakis",
         "Numerical modeling of ground penetrating radars (GPRs), such as the finite-difference time-domain (FDTD) method, has been extensively used to enhance the interpretation of GPR data and as a key component of full-waveform inversion (FWI). A major drawback of numerical solvers, especially within the context of FWI, is that they are still computationally expensive requiring often unattainable computational resources and access to high-performance computing (HPC). In this work, we present a near real-time deep-learning forward solver for GPR data that can generate entire B-scans, given certain model parameters as inputs. The machine-learning (ML) model is tuned for reinforced concrete slab scenarios, but the same rationale can be applied in a straightforward manner to other applications as well. The training was performed using entirely synthetic data, where a 3-D digital twin based on the 2000-MHz palm antenna from Geophysical Survey Systems, Inc. (GSSI) was included in FDTD simulations for the training set. The accuracy of the deep-learning solver is demonstrated with both synthetic and real data from reinforced concrete slabs. The predicted ML responses were in very good agreement with FDTD, showing a high degree of accuracy. The ML solver is then used as part of an FWI algorithm to characterize the concrete slab and estimate the depth and radius of the buried rebars. Coupled FWI with an ML-based forward solver results in significantly less execution times compared to conventional FWI using numerical solvers. The high accuracy of the proposed FWI, combined with the efficiency and speed of the ML-based forward solver, make the proposed scheme an ideal tool for characterizing concrete structures in nondestructive testing.",
         "https://www.semanticscholar.org/paper/0be15269dffa995e0c2859ed9c354ad4e916632b",
         "15"
        ],
        [
         "49",
         "J",
         "Putek, J; Szepietowski, JC",
         null,
         null,
         null,
         "Putek, Justyna; Szepietowski, Jacek C.",
         null,
         null,
         "Alexithymia in people with tattoos",
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         "0",
         "alexithymia in people with tattoos",
         "ecaff1dd1b14f06daf698e6eaa4a5926928bc27a",
         "Alexithymia in people with tattoos",
         "2024",
         "Justyna Putek, J. Szepietowski",
         "Introduction Tattoos are a form of body modifications. Alexithymia is a complex personality structure that includes emotional and cognitive deficits such as difficulty in recognizing and describing feelings. Aim To assess the prevalence of alexithymia among tattooed individuals. Moreover, we aimed to check if the type of tattoo is related to alexithymia. Material and methods This was a cross-sectional survey, conducted on 403 individuals from Poland. 200 of them had tattoos and were assigned to the study group, and 203 of them had no tattoos and were assigned to the control group. Results Most respondents (24%) had one tattoo. Most tattoos (29.8%) were situated on forearms and palms, had a plant motif (21.8%) and were done to express personality of the respondents (20.7%). In the research group 80 (19.9%) respondents were classified as alexithymic ones. Out of them, 47 (11.7%) individuals had tattoos and 33 (8.9%) belonged to the non-tattooed group. 35 (17.5%) respondents with non-verbal tattoos were screened as alexithymic while 12 (6%) individuals with verbal, personal tattoos were classified as alexithymic ones (p < 0.05). Twenty-two (11%) respondents who did their tattoos for psychological reasons and 25 (12.5%) individuals who did their tattoos for aesthetic reasons were classified as alexithymic (NS). Conclusions Subjects with tattoos should be regarded as a group with increased prevalence of alexithymia. Individuals with non-verbal tattoos had a higher tendency to be screened as alexithymic as alexithymic ones. Motivation for getting the tattoo does not seem to have a significant impact on the prevalence of alexithymia.",
         "https://www.semanticscholar.org/paper/ecaff1dd1b14f06daf698e6eaa4a5926928bc27a",
         "0"
        ]
       ],
       "shape": {
        "columns": 80,
        "rows": 51
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Publication Type</th>\n",
       "      <th>Authors</th>\n",
       "      <th>Book Authors</th>\n",
       "      <th>Book Editors</th>\n",
       "      <th>Book Group Authors</th>\n",
       "      <th>Author Full Names</th>\n",
       "      <th>Book Author Full Names</th>\n",
       "      <th>Group Authors</th>\n",
       "      <th>title_WoS</th>\n",
       "      <th>Source Title</th>\n",
       "      <th>...</th>\n",
       "      <th>UT (Unique WOS ID)</th>\n",
       "      <th>Web of Science Record</th>\n",
       "      <th>norm_title</th>\n",
       "      <th>paperId</th>\n",
       "      <th>title_SS</th>\n",
       "      <th>year</th>\n",
       "      <th>authors</th>\n",
       "      <th>abstract</th>\n",
       "      <th>url</th>\n",
       "      <th>citationCount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>J</td>\n",
       "      <td>Ferreira, G; Amidei, J; Nieto, R; Kaltenbrunne...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Ferreira, Gregorio; Amidei, Jacopo; Nieto, Rub...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>How Well Do Simulated Population Samples with ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>how well do simulated population samples with ...</td>\n",
       "      <td>25f383b7a807392696073801959dcc1c1aadd2bb</td>\n",
       "      <td>How Well Do Simulated Population Samples with ...</td>\n",
       "      <td>2025</td>\n",
       "      <td>Gregorio Ferreira, Jacopo Amidei, Rubn Nieto,...</td>\n",
       "      <td>Background: Advances in artificial intelligenc...</td>\n",
       "      <td>https://www.semanticscholar.org/paper/25f383b7...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>C</td>\n",
       "      <td>Kane, D; Parke, J; Jo, Y; Bak, J</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Bouamor, H; Pino, J; Bali, K</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Kane, Dongjun; Parke, JoonSuk; Jo, Yohan; Bak,...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>From Values to Opinions: Predicting Human Beha...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>from values to opinions predicting human behav...</td>\n",
       "      <td>52e963c40a5083d5403cebf4d4782271aaa06994</td>\n",
       "      <td>From Values to Opinions: Predicting Human Beha...</td>\n",
       "      <td>2023</td>\n",
       "      <td>Dongjun Kang, Joonsuk Park, Yohan Jo, Jinyeong...</td>\n",
       "      <td>Being able to predict people's opinions on iss...</td>\n",
       "      <td>https://www.semanticscholar.org/paper/52e963c4...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>J</td>\n",
       "      <td>Bisbee, J; Clinton, JD; Dorff, C; Kenkel, B; L...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Bisbee, James; Clinton, Joshua D.; Dorff, Cass...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Synthetic Replacements for Human Survey Data? ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>synthetic replacements for human survey data t...</td>\n",
       "      <td>58d735a54d3aba79ad3bffbfa2433d8e5ee27313</td>\n",
       "      <td>Synthetic Replacements for Human Survey Data? ...</td>\n",
       "      <td>2024</td>\n",
       "      <td>James Bisbee, Joshua D. Clinton, C. Dorff, Bre...</td>\n",
       "      <td>\\n Large language models (LLMs) offer new rese...</td>\n",
       "      <td>https://www.semanticscholar.org/paper/58d735a5...</td>\n",
       "      <td>74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>J</td>\n",
       "      <td>Liu, HJ; Cao, Y; Wu, X; Qiu, C; Gu, JG; Liu, M...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Liu, Haijiang; Cao, Yong; Wu, Xun; Qiu, Chen; ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Towards realistic evaluation of cultural value...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>towards realistic evaluation of cultural value...</td>\n",
       "      <td>3ab59b3d4a4b2e89f7eda93a950eeaa77b37332e</td>\n",
       "      <td>Towards realistic evaluation of cultural value...</td>\n",
       "      <td>2025</td>\n",
       "      <td>Haijiang Liu, Yong Cao, Xun Wu, Chen Qiu, Jing...</td>\n",
       "      <td>None</td>\n",
       "      <td>https://www.semanticscholar.org/paper/3ab59b3d...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>J</td>\n",
       "      <td>Boelaert, J; Coavoux, S; Ollion, E; Petev, I; ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Boelaert, Julien; Coavoux, Samuel; Ollion, Eti...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Machine Bias. How Do Generative Language Model...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>machine bias how do generative language models...</td>\n",
       "      <td>45f9ea8d0dc1a7e6c56ff6e1f23c8e632687d2a7</td>\n",
       "      <td>Machine Bias. How Do Generative Language Model...</td>\n",
       "      <td>2025</td>\n",
       "      <td>J. Boelaert, Samuel Coavoux, tienne Ollion, I...</td>\n",
       "      <td>Generative artificial intelligence (AI) is inc...</td>\n",
       "      <td>https://www.semanticscholar.org/paper/45f9ea8d...</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>J</td>\n",
       "      <td>Qu, Y; Wang, J</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Qu, Yao; Wang, Jue</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Performance and biases of Large Language Model...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>performance and biases of large language model...</td>\n",
       "      <td>e6d14d140c4faaf8f3d9f47e61cc5c6091bccf1e</td>\n",
       "      <td>Performance and Biases of Large Language Model...</td>\n",
       "      <td>2024</td>\n",
       "      <td>Yao Qu, Jue Wang</td>\n",
       "      <td>None</td>\n",
       "      <td>https://www.semanticscholar.org/paper/e6d14d14...</td>\n",
       "      <td>46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>C</td>\n",
       "      <td>Nguyen, H; Nguyen, V; Lpez-Fierro, S; Ludovis...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ASSOC COMPUTING MACHINERY</td>\n",
       "      <td>Ha Nguyen; Nguyen, Victoria; Lopez-Fierro, Sar...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Simulating Climate Change Discussion with Larg...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>simulating climate change discussion with larg...</td>\n",
       "      <td>dd95064d28ee5d123a6a284422bbba3d443f0416</td>\n",
       "      <td>Simulating Climate Change Discussion with Larg...</td>\n",
       "      <td>2024</td>\n",
       "      <td>Ha Nguyen, Victoria Nguyen, Sarah Lpez-Fierr...</td>\n",
       "      <td>Large language models (LLMs) have shown promis...</td>\n",
       "      <td>https://www.semanticscholar.org/paper/dd95064d...</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>J</td>\n",
       "      <td>Salecha, A; Ireland, ME; Subrahmanya, S; Sedoc...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Salecha, Aadesh; Ireland, Molly E.; Subrahmany...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Large language models display human-like socia...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>large language models display human like socia...</td>\n",
       "      <td>8253104f5b1481d8557380d2dc5dab03ff9a7716</td>\n",
       "      <td>Large language models display human-like socia...</td>\n",
       "      <td>2024</td>\n",
       "      <td>Aadesh Salecha, Molly E. Ireland, Shashanka Su...</td>\n",
       "      <td>Abstract Large language models (LLMs) are beco...</td>\n",
       "      <td>https://www.semanticscholar.org/paper/8253104f...</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>J</td>\n",
       "      <td>Yao, JC; Zhang, HJ; Ou, J; Zuo, DY; Yang, Z; D...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Yao, Junchi; Zhang, Hongjie; Ou, Jie; Zuo, Din...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Social opinions prediction utilizes fusing dyn...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>social opinions prediction utilizes fusing dyn...</td>\n",
       "      <td>392de716c8f6610f080ba655e885935c20ac6c73</td>\n",
       "      <td>Social opinions prediction utilizes fusing dyn...</td>\n",
       "      <td>2024</td>\n",
       "      <td>Junchi Yao, Hongjie Zhang, Jie Ou, Dingyi Zuo,...</td>\n",
       "      <td>In the context where social media emerges as a...</td>\n",
       "      <td>https://www.semanticscholar.org/paper/392de716...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>C</td>\n",
       "      <td>Hmlinen, P; Tavast, M; Kunnari, A</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ACM</td>\n",
       "      <td>Hamalainen, Perttu; Tavast, Mikke; Kunnari, Anton</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Evaluating Large Language Models in Generating...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>evaluating large language models in generating...</td>\n",
       "      <td>0ffd57884d7957f6b5634b9fa24843dc3759668f</td>\n",
       "      <td>Evaluating Large Language Models in Generating...</td>\n",
       "      <td>2023</td>\n",
       "      <td>Perttu Hmlinen, Mikke Tavast, Anton Kunnari</td>\n",
       "      <td>Collecting data is one of the bottlenecks of H...</td>\n",
       "      <td>https://www.semanticscholar.org/paper/0ffd5788...</td>\n",
       "      <td>218</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>J</td>\n",
       "      <td>Zhang, S; Xu, J; Alvero, AJ</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Zhang, Simone; Xu, Janet; Alvero, A. J.</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Generative AI Meets Open-Ended Survey Response...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>generative ai meets open ended survey response...</td>\n",
       "      <td>8398dfa4d015b3784654a77b3913b62a1f68eed8</td>\n",
       "      <td>Generative AI Meets Open-Ended Survey Response...</td>\n",
       "      <td>2025</td>\n",
       "      <td>Simone Zhang, Janet Xu, AJ Alvero</td>\n",
       "      <td>The growing popularity of generative artificia...</td>\n",
       "      <td>https://www.semanticscholar.org/paper/8398dfa4...</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>J</td>\n",
       "      <td>Zhang, BY; Chen, T; Wang, X; Li, Q; Zhang, WS;...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Zhang, Baoyu; Chen, Tao; Wang, Xiao; Li, Qiang...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Decoding Activist Public Opinion in Decentrali...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>decoding activist public opinion in decentrali...</td>\n",
       "      <td>4949ff97cf5e7c31ed9a057cbbde4b95d3ddd1f8</td>\n",
       "      <td>Decoding Activist Public Opinion in Decentrali...</td>\n",
       "      <td>2024</td>\n",
       "      <td>Baoyu Zhang, Tao Chen, Xiao Wang, Qiang Li, We...</td>\n",
       "      <td>Based on an investigation of online public opi...</td>\n",
       "      <td>https://www.semanticscholar.org/paper/4949ff97...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>J</td>\n",
       "      <td>Gao, C; Lan, XC; Li, N; Yuan, Y; Ding, JT; Zho...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Gao, Chen; Lan, Xiaochong; Li, Nian; Yuan, Yua...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Large language models empowered agent-based mo...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>large language models empowered agent based mo...</td>\n",
       "      <td>592ac35991e583fc37c26ee6659d2deb85142ad9</td>\n",
       "      <td>Large Language Models Empowered Agent-based Mo...</td>\n",
       "      <td>2023</td>\n",
       "      <td>Chen Gao, Xiaochong Lan, Nian Li, Yuan Yuan, J...</td>\n",
       "      <td>Agent-based modeling and simulation have evolv...</td>\n",
       "      <td>https://www.semanticscholar.org/paper/592ac359...</td>\n",
       "      <td>182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>C</td>\n",
       "      <td>AlKhamissi, B; ElNokrashy, M; AlKhamissi, M; D...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Ku, LW; Martins, A; Srikumar, V</td>\n",
       "      <td>NaN</td>\n",
       "      <td>AlKhamissi, Badr; ElNokrashy, Muhammad; AlKham...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Investigating Cultural Alignment of Large Lang...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>investigating cultural alignment of large lang...</td>\n",
       "      <td>b1890367317f0657c08ed96be4c474035b34b485</td>\n",
       "      <td>Investigating Cultural Alignment of Large Lang...</td>\n",
       "      <td>2024</td>\n",
       "      <td>Badr AlKhamissi, Muhammad N. ElNokrashy, Mai A...</td>\n",
       "      <td>The intricate relationship between language an...</td>\n",
       "      <td>https://www.semanticscholar.org/paper/b1890367...</td>\n",
       "      <td>78</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>J</td>\n",
       "      <td>Zhao, XJ; Wang, H; Dai, CX; Tang, JC; Deng, KX...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Zhao, Xinjie; Wang, Hao; Dai, Chengxiao; Tang,...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Multi-Stage Simulation of Residents' Disaster ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>multi stage simulation of residents disaster r...</td>\n",
       "      <td>6d2077c8f4864103780b160501cd207005d045c8</td>\n",
       "      <td>Multi-Stage Simulation of Residents Disaster ...</td>\n",
       "      <td>2025</td>\n",
       "      <td>Xinjie Zhao, Hao Wang, Chengxiao Dai, Jiacheng...</td>\n",
       "      <td>The escalating frequency and complexity of nat...</td>\n",
       "      <td>https://www.semanticscholar.org/paper/6d2077c8...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>J</td>\n",
       "      <td>de Winter, JCF; Driessen, T; Dodou, D</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>de Winter, Joost C. F.; Driessen, Tom; Dodou, ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>The use of ChatGPT for personality research: A...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>the use of chatgpt for personality research ad...</td>\n",
       "      <td>781703bc7e4fb90766824ee808097171afa223b3</td>\n",
       "      <td>The use of ChatGPT for personality research: A...</td>\n",
       "      <td>2024</td>\n",
       "      <td>J. D. de Winter, Tom Driessen, Dimitra Dodou</td>\n",
       "      <td>None</td>\n",
       "      <td>https://www.semanticscholar.org/paper/781703bc...</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>J</td>\n",
       "      <td>Rakovics, Z; Rakovics, M</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Rakovics, Zsofia; Rakovics, Marton</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Exploring the potential and limitations of lar...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>exploring the potential and limitations of lar...</td>\n",
       "      <td>6cd94c4fdfd1ddf59b5385919851de2662e412fe</td>\n",
       "      <td>Exploring the potential and limitations of lar...</td>\n",
       "      <td>2024</td>\n",
       "      <td>Zsfia Rakovics, Mrton Rakovics</td>\n",
       "      <td>Social and linguistic differences encoded in v...</td>\n",
       "      <td>https://www.semanticscholar.org/paper/6cd94c4f...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>J</td>\n",
       "      <td>Leung, HW; Bovy, J</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Leung, Henry W.; Bovy, Jo</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Towards an astronomical foundation model for s...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>towards an astronomical foundation model for s...</td>\n",
       "      <td>264cb7a7dbee1303ff9e0ebe2dac78646271a2fb</td>\n",
       "      <td>Towards an astronomical foundation model for s...</td>\n",
       "      <td>2023</td>\n",
       "      <td>Henry W. Leung, J. Bovy</td>\n",
       "      <td>Rapid strides are currently being made in the ...</td>\n",
       "      <td>https://www.semanticscholar.org/paper/264cb7a7...</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>J</td>\n",
       "      <td>Mburu, TK; Rong, KX; McColley, CJ; Werth, A</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Mburu, Ted K.; Rong, Kangxuan; McColley, Campb...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Methodological foundations for artificial inte...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>methodological foundations for artificial inte...</td>\n",
       "      <td>54b63afefc315b5f051f4a19fe413ef6c544c9fd</td>\n",
       "      <td>Methodological foundations for artificial inte...</td>\n",
       "      <td>2025</td>\n",
       "      <td>Ted K. Mburu, Kangxuan Rong, Campbell J. McCol...</td>\n",
       "      <td>This study investigates the use of large langu...</td>\n",
       "      <td>https://www.semanticscholar.org/paper/54b63afe...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>J</td>\n",
       "      <td>Zhang, KH; Dong, CQ; Guo, YF; Zhou, W; Yu, G; ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Zhang, Kaihang; Dong, Changqi; Guo, Yifeng; Zh...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Lagged Stance Interactions and Counter-Spiral ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>lagged stance interactions and counter spiral ...</td>\n",
       "      <td>bc270ab2e00f78691c8fd16548809e3609dedee2</td>\n",
       "      <td>Lagged Stance Interactions and Counter-Spiral ...</td>\n",
       "      <td>2025</td>\n",
       "      <td>Kaihang Zhang, Changqi Dong, Yifeng Guo, Wuai ...</td>\n",
       "      <td>Understanding the dynamics of public opinion f...</td>\n",
       "      <td>https://www.semanticscholar.org/paper/bc270ab2...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>J</td>\n",
       "      <td>Campos, M; Farinhas, A; Zerva, C; Figueiredo, ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Campos, Margarida; Farinhas, Antonio; Zerva, C...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Conformal Prediction for Natural Language Proc...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>conformal prediction for natural language proc...</td>\n",
       "      <td>346fdbda3ecf4775819fced0cfed78357bee8128</td>\n",
       "      <td>Conformal Prediction for Natural Language Proc...</td>\n",
       "      <td>2024</td>\n",
       "      <td>Margarida M. Campos, Antnio Farinhas, Chrysou...</td>\n",
       "      <td>Abstract The rapid proliferation of large lang...</td>\n",
       "      <td>https://www.semanticscholar.org/paper/346fdbda...</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>C</td>\n",
       "      <td>Cheng, M; Piccardi, T; Yang, DY</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Bouamor, H; Pino, J; Bali, K</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Cheng, Myra; Piccardi, Tiziano; Yang, Diyi</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>CoMPosT: Characterizing and Evaluating Caricat...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>compost characterizing and evaluating caricatu...</td>\n",
       "      <td>7a4fe2f003241ad97bf1778e527cb0306fa90da2</td>\n",
       "      <td>CoMPosT: Characterizing and Evaluating Caricat...</td>\n",
       "      <td>2023</td>\n",
       "      <td>Myra Cheng, Tiziano Piccardi, Diyi Yang</td>\n",
       "      <td>Recent work has aimed to capture nuances of hu...</td>\n",
       "      <td>https://www.semanticscholar.org/paper/7a4fe2f0...</td>\n",
       "      <td>89</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>J</td>\n",
       "      <td>Kaur, A; Budko, A; Liu, K; Eaton, E; Steitz, B...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Kaur, Amarpreet; Budko, Alexander; Liu, Katrin...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Automating Responses to Patient Portal Message...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>automating responses to patient portal message...</td>\n",
       "      <td>caa3c4eb1ede700f03eef5b4f25a18b08c88d832</td>\n",
       "      <td>Automating Responses to Patient Portal Message...</td>\n",
       "      <td>2024</td>\n",
       "      <td>Amarpreet Kaur, Alexander Budko, Katrina Liu, ...</td>\n",
       "      <td>Background: Patient portals serve as vital bri...</td>\n",
       "      <td>https://www.semanticscholar.org/paper/caa3c4eb...</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>J</td>\n",
       "      <td>Ji, J; Kim, J; Kim, Y</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Ji, Junyung; Kim, Jiwoo; Kim, Younghoon</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Predicting Missing Values in Survey Data Using...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>predicting missing values in survey data using...</td>\n",
       "      <td>bdeeaf207e2563f39ad27a9d9511d8573b5bff95</td>\n",
       "      <td>Predicting Missing Values in Survey Data Using...</td>\n",
       "      <td>2024</td>\n",
       "      <td>Junyung Ji, Jiwoo Kim, Younghoon Kim</td>\n",
       "      <td>Survey data play a crucial role in various res...</td>\n",
       "      <td>https://www.semanticscholar.org/paper/bdeeaf20...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>J</td>\n",
       "      <td>Goli, A; Singh, A</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Goli, Ali; Singh, Amandeep</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Frontiers: Can Large Language Models Capture H...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>frontiers can large language models capture hu...</td>\n",
       "      <td>0377c4c20d86e3a23cb5c22d89b3cb488c31a564</td>\n",
       "      <td>Frontiers: Can Large Language Models Capture H...</td>\n",
       "      <td>2024</td>\n",
       "      <td>Ali Goli, Amandeep Singh</td>\n",
       "      <td>This paper examines the potential of large lan...</td>\n",
       "      <td>https://www.semanticscholar.org/paper/0377c4c2...</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>C</td>\n",
       "      <td>Liu, YH; Chen, XY; Zhang, XQ; Gao, X; Zhang, J...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Larson, K</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Liu, Yuhan; Chen, Xiuying; Zhang, Xiaoqing; Ga...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>From Skepticism to Acceptance: Simulating the ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>from skepticism to acceptance simulating the a...</td>\n",
       "      <td>1bd4b8be136072c8f56114f2f8479aaed2ad6d9b</td>\n",
       "      <td>From Skepticism to Acceptance: Simulating the ...</td>\n",
       "      <td>2024</td>\n",
       "      <td>Yuhan Liu, Xiuying Chen, Xiaoqing Zhang, Xing ...</td>\n",
       "      <td>In the digital era, the rapid propagation of f...</td>\n",
       "      <td>https://www.semanticscholar.org/paper/1bd4b8be...</td>\n",
       "      <td>44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>J</td>\n",
       "      <td>Ferreira, G; Amidei, J; Nieto, R; Kaltenbrunne...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Ferreira, Gregorio; Amidei, Jacopo; Nieto, Rub...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Matching GPT-simulated Populations with Real O...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>matching gpt simulated populations with real o...</td>\n",
       "      <td>e186d394a49ab2866a8b1248a99e6f1637a238fe</td>\n",
       "      <td>Matching GPT-simulated Populations with Real O...</td>\n",
       "      <td>2025</td>\n",
       "      <td>Gregorio Ferreira, Jacopo Amidei, Rubn Nieto,...</td>\n",
       "      <td>This article analyzes how well OpenAIs LLM GP...</td>\n",
       "      <td>https://www.semanticscholar.org/paper/e186d394...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>C</td>\n",
       "      <td>Scarlatos, A; Baker, RS; Lan, A</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ACM</td>\n",
       "      <td>Scarlatos, Alexander; Baker, Ryan S.; Lan, Andrew</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Exploring Knowledge Tracing in Tutor-Student D...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>exploring knowledge tracing in tutor student d...</td>\n",
       "      <td>06e9ec37cc25980544d0a78b5aa4893dafc65fd3</td>\n",
       "      <td>Exploring Knowledge Tracing in Tutor-Student D...</td>\n",
       "      <td>2024</td>\n",
       "      <td>Alexander Scarlatos, Ryan S. Baker, Andrew Lan</td>\n",
       "      <td>Recent advances in large language models (LLMs...</td>\n",
       "      <td>https://www.semanticscholar.org/paper/06e9ec37...</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>C</td>\n",
       "      <td>Steinmacher, I; Penney, JM; Felizardo, KR; Gar...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ACM</td>\n",
       "      <td>Steinmacher, Igor; Penney, Jacob Mcauley; Feli...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Can ChatGPT emulate humans in software enginee...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>can chatgpt emulate humans in software enginee...</td>\n",
       "      <td>2a77ac8d1c36ccf9f222cf0ae16e251ac6b13e86</td>\n",
       "      <td>Can ChatGPT emulate humans in software enginee...</td>\n",
       "      <td>2024</td>\n",
       "      <td>Igor Steinmacher, Jacob Penney, K. Felizardo, ...</td>\n",
       "      <td>Context: There is a growing belief in the lite...</td>\n",
       "      <td>https://www.semanticscholar.org/paper/2a77ac8d...</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>J</td>\n",
       "      <td>Wahidur, RSM; Tashdeed, I; Kaur, M; Lee, HN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Wahidur, Rahman S. M.; Tashdeed, Ishmam; Kaur,...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Enhancing Zero-Shot Crypto Sentiment With Fine...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>enhancing zero shot crypto sentiment with fine...</td>\n",
       "      <td>bcdc44ef48ffadbdaa3bd5cacfe9ddb9b9f48750</td>\n",
       "      <td>Enhancing Zero-Shot Crypto Sentiment With Fine...</td>\n",
       "      <td>2023</td>\n",
       "      <td>Rahman S M Wahidur, Ishmam Tashdeed, Manjit Ka...</td>\n",
       "      <td>Blockchain technology has revolutionized the f...</td>\n",
       "      <td>https://www.semanticscholar.org/paper/bcdc44ef...</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>C</td>\n",
       "      <td>Hwang, E; Majumder, BP; Tandon, N</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Bouamor, H; Pino, J; Bali K</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Hwang, EunJeong; Majumder, Bodhisattwa Prasad;...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Aligning Language Models to User Opinions</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>aligning language models to user opinions</td>\n",
       "      <td>5db0f55332839c408e3049cea1a6ad48fefba70c</td>\n",
       "      <td>Aligning Language Models to User Opinions</td>\n",
       "      <td>2023</td>\n",
       "      <td>EunJeong Hwang, Bodhisattwa Prasad Majumder, N...</td>\n",
       "      <td>An important aspect of developing LLMs that in...</td>\n",
       "      <td>https://www.semanticscholar.org/paper/5db0f553...</td>\n",
       "      <td>82</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>C</td>\n",
       "      <td>Min, Y; Jeong, JW</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Eck, U; Sra, M; Stefanucci, J; Sugimoto, M; Ta...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Min, Yewon; Jeong, Jin-Woo</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Public Speaking Q&amp;A Practice with LLM-Generate...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>public speaking q a practice with llm generate...</td>\n",
       "      <td>3b36ec5f47076620dc7735f8aba55d9c3c3e6b32</td>\n",
       "      <td>Public Speaking Q&amp;A Practice with LLM-Generate...</td>\n",
       "      <td>2024</td>\n",
       "      <td>Yewon Min, Jin-Woo Jeong</td>\n",
       "      <td>This paper introduces a novel VR-based Q&amp;A pra...</td>\n",
       "      <td>https://www.semanticscholar.org/paper/3b36ec5f...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>C</td>\n",
       "      <td>Liu, A; Diab, M; Fried, D</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Martins, A; Srikumar, V; Ku, LW</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Liu, Andy; Diab, Mona; Fried, Daniel</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Evaluating Large Language Model Biases in Pers...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>evaluating large language model biases in pers...</td>\n",
       "      <td>ae03f10729959435ecefc0e90cba4cbe8438a10b</td>\n",
       "      <td>Evaluating Large Language Model Biases in Pers...</td>\n",
       "      <td>2024</td>\n",
       "      <td>Andy Liu, Mona T. Diab, Daniel Fried</td>\n",
       "      <td>The task of persona-steered text generation re...</td>\n",
       "      <td>https://www.semanticscholar.org/paper/ae03f107...</td>\n",
       "      <td>49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>J</td>\n",
       "      <td>Mishra, T; Sutanto, E; Rossanti, R; Pant, N; A...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Mishra, Tanisha; Sutanto, Edward; Rossanti, Ri...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Use of large language models as artificial int...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>use of large language models as artificial int...</td>\n",
       "      <td>0c1e396f7f23d34ebad01dac29de6898f18ae63e</td>\n",
       "      <td>Use of large language models as artificial int...</td>\n",
       "      <td>2024</td>\n",
       "      <td>Tanisha Mishra, Edward Sutanto, Rini Rossanti,...</td>\n",
       "      <td>With breakthroughs in Natural Language Process...</td>\n",
       "      <td>https://www.semanticscholar.org/paper/0c1e396f...</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>J</td>\n",
       "      <td>Teferra, BG; Perivolaris, A; Hsiang, WN; Sidha...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Teferra, Bazen Gashaw; Perivolaris, Argyrios; ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Leveraging large language models for automated...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>leveraging large language models for automated...</td>\n",
       "      <td>d0deb3ffd586a886b435d67c1b3aad89eeeaf358</td>\n",
       "      <td>Leveraging large language models for automated...</td>\n",
       "      <td>2025</td>\n",
       "      <td>Bazen Gashaw Teferra, Argyrios Perivolaris, We...</td>\n",
       "      <td>Mental health diagnoses possess unique challen...</td>\n",
       "      <td>https://www.semanticscholar.org/paper/d0deb3ff...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>J</td>\n",
       "      <td>Bachmann, F; van der Weijden, D; Heitz, L; Sar...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Bachmann, Fynn; van der Weijden, Daan; Heitz, ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Adaptive political surveys and GPT-4: Tackling...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>adaptive political surveys and gpt 4 tackling ...</td>\n",
       "      <td>1d1097d378555393b73b492995121ab880fff142</td>\n",
       "      <td>Adaptive political surveys and GPT-4: Tackling...</td>\n",
       "      <td>2025</td>\n",
       "      <td>Fynn Bachmann, Daan van der Weijden, Lucien He...</td>\n",
       "      <td>Adaptive questionnaires dynamically select the...</td>\n",
       "      <td>https://www.semanticscholar.org/paper/1d1097d3...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>C</td>\n",
       "      <td>Mancera, J; Tern, L</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Liao, HC; Cid, DD; Macadar, MA; Bernardini, F</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Mancera, Jose; Teran, Luis</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>From GenAI to Political Profiling Avatars: A D...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>from genai to political profiling avatars a da...</td>\n",
       "      <td>3084188f92330fa837a87b6ca422b28ae1ca713c</td>\n",
       "      <td>From GenAI to Political Profiling Avatars: A D...</td>\n",
       "      <td>2024</td>\n",
       "      <td>Jos Alberto Mancera Andrade, Luis Tern</td>\n",
       "      <td>Voting advice applications (VAAs) are pivotal ...</td>\n",
       "      <td>https://www.semanticscholar.org/paper/3084188f...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>C</td>\n",
       "      <td>Kaate, I; Salminen, J; Jung, SG; Xuan, TTT; H...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ACM</td>\n",
       "      <td>Kaate, Ilkka; Salminen, Joni; Jung, Soon-Gyo; ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>You Always Get an Answer: Analyzing Users' Int...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>you always get an answer analyzing users inter...</td>\n",
       "      <td>48ebe4b39ff2dce8d6c026f6cd2cbea8406a9a6e</td>\n",
       "      <td>You Always Get an Answer: Analyzing Users I...</td>\n",
       "      <td>2025</td>\n",
       "      <td>Ilkka Kaate, Joni O. Salminen, Soon-gyo Jung, ...</td>\n",
       "      <td>We investigated the presence and acceptance of...</td>\n",
       "      <td>https://www.semanticscholar.org/paper/48ebe4b3...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>J</td>\n",
       "      <td>Hadar-Shoval, D; Asraf, K; Mizrachi, Y; Haber,...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Hadar-Shoval, Dorit; Asraf, Kfir; Mizrachi, Yo...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Assessing the Alignment of Large Language Mode...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>assessing the alignment of large language mode...</td>\n",
       "      <td>3a455a00d01fcd45d7797f296eb5b5db331ff7b1</td>\n",
       "      <td>Assessing the Alignment of Large Language Mode...</td>\n",
       "      <td>2024</td>\n",
       "      <td>D. Hadar-Shoval, K. Asraf, Yonathan Mizrachi, ...</td>\n",
       "      <td>Background Large language models (LLMs) hold p...</td>\n",
       "      <td>https://www.semanticscholar.org/paper/3a455a00...</td>\n",
       "      <td>36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>J</td>\n",
       "      <td>Amirova, A; Fteropoulli, T; Ahmed, N; Cowie, M...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Amirova, Aliya; Fteropoulli, Theodora; Ahmed, ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Framework-based qualitative analysis of free r...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>framework based qualitative analysis of free r...</td>\n",
       "      <td>ba5aefce80edc7da110f53fd071f4fbd6b5195b9</td>\n",
       "      <td>Framework-based qualitative analysis of free r...</td>\n",
       "      <td>2023</td>\n",
       "      <td>A. Amirova, T. Fteropoulli, Nafiso Ahmed, Mart...</td>\n",
       "      <td>Today, with the advent of Large-scale generati...</td>\n",
       "      <td>https://www.semanticscholar.org/paper/ba5aefce...</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>J</td>\n",
       "      <td>Sumner, J; Wang, YC; Tan, SY; Chew, EHH; Yip, AW</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Sumner, Jennifer; Wang, Yuchen; Tan, Si Ying; ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Perspectives and Experiences With Large Langua...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>perspectives and experiences with large langua...</td>\n",
       "      <td>db593a47eec5f6dbd9f28e88d0e4d7450cc6376b</td>\n",
       "      <td>Perspectives and Experiences With Large Langua...</td>\n",
       "      <td>2025</td>\n",
       "      <td>Jennifer Sumner, Yuchen Wang, Si Ying Tan, Emi...</td>\n",
       "      <td>Background Large language models (LLMs) are tr...</td>\n",
       "      <td>https://www.semanticscholar.org/paper/db593a47...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>J</td>\n",
       "      <td>Rdel-Ablass, K; Schliz, K; Schlick, C; Meindl...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Raedel-Ablass, Katharina; Schliz, Klaus; Schli...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Teaching opportunities for anamnesis interview...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>teaching opportunities for anamnesis interview...</td>\n",
       "      <td>d46b4155182de3a385b8f0b323ca54a201e1c60f</td>\n",
       "      <td>Teaching opportunities for anamnesis interview...</td>\n",
       "      <td>2025</td>\n",
       "      <td>Katharina Rdel-Ablass, Klaus Schliz, Cornelia...</td>\n",
       "      <td>Background This study presents a novel approac...</td>\n",
       "      <td>https://www.semanticscholar.org/paper/d46b4155...</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>J</td>\n",
       "      <td>Lau, C; Zhu, XD; Chan, WY</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Lau, Clinton; Zhu, Xiaodan; Chan, Wai-Yip</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Automatic depression severity assessment with ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>automatic depression severity assessment with ...</td>\n",
       "      <td>527288d9ded807883d756f1b3503bc39e79e0a06</td>\n",
       "      <td>Automatic depression severity assessment with ...</td>\n",
       "      <td>2023</td>\n",
       "      <td>Clinton Lau, Xiaodan Zhu, Wai-Yip Chan</td>\n",
       "      <td>Introduction To assist mental health care prov...</td>\n",
       "      <td>https://www.semanticscholar.org/paper/527288d9...</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>J</td>\n",
       "      <td>Heston, TF</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Heston, Thomas F.</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Safety of Large Language Models in Addressing ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>safety of large language models in addressing ...</td>\n",
       "      <td>1554d7e72a8b5bcad108ff1d0c9014ddfaaebd0f</td>\n",
       "      <td>Safety of Large Language Models in Addressing ...</td>\n",
       "      <td>2023</td>\n",
       "      <td>T. F. Heston</td>\n",
       "      <td>Background Generative artificial intelligence ...</td>\n",
       "      <td>https://www.semanticscholar.org/paper/1554d7e7...</td>\n",
       "      <td>43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>J</td>\n",
       "      <td>Hanss, K; Sarma, K; Glowinski, AL; Krystal, A;...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Hanss, Kaitlin; Sarma, Karthik, V; Glowinski, ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Assessing the Accuracy and Reliability of Larg...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>assessing the accuracy and reliability of larg...</td>\n",
       "      <td>faf47d35147d836bcc03bffda819db2426febac8</td>\n",
       "      <td>Assessing the Accuracy and Reliability of Larg...</td>\n",
       "      <td>2025</td>\n",
       "      <td>Kaitlin Hanss, Karthik V Sarma, Anne L Glowins...</td>\n",
       "      <td>Background Large language models (LLMs), such ...</td>\n",
       "      <td>https://www.semanticscholar.org/paper/faf47d35...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>J</td>\n",
       "      <td>Alsalamah, SA; AlSalamah, S; Alsalamah, HA; Sh...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Alsalamah, Sara A.; AlSalamah, Shada; Alsalama...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Virtual healthcare bot (VHC-Bot): a Person-cen...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>virtual healthcare bot vhc bot a person center...</td>\n",
       "      <td>4408852e43dcff9da71f1053f6aeefbea10db450</td>\n",
       "      <td>Virtual healthcare bot (VHC-Bot): a Person-cen...</td>\n",
       "      <td>2025</td>\n",
       "      <td>Sara A. Alsalamah, Shada Alsalamah, Hessah A. ...</td>\n",
       "      <td>None</td>\n",
       "      <td>https://www.semanticscholar.org/paper/4408852e...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>J</td>\n",
       "      <td>Nguyen, MH; Sedoc, J; Taylor, CO</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Nguyen, Michelle Hoang; Sedoc, Joao; Taylor, C...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Usability, Engagement, and Report Usefulness o...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>usability engagement and report usefulness of ...</td>\n",
       "      <td>cddaccfd097ba11b991829930f95d0abd6a9dade</td>\n",
       "      <td>Usability, Engagement, and Report Usefulness o...</td>\n",
       "      <td>2024</td>\n",
       "      <td>M. Nguyen, Joo Sedoc, C. O. Taylor</td>\n",
       "      <td>Background Family health history (FHx) is an i...</td>\n",
       "      <td>https://www.semanticscholar.org/paper/cddaccfd...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>J</td>\n",
       "      <td>Safrai, M; Azaria, A</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Safrai, Myriam; Azaria, Amos</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Does small talk with a medical provider affect...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>does small talk with a medical provider affect...</td>\n",
       "      <td>dc8ed1d85c4674181746ffe8f08e86e00d0054ff</td>\n",
       "      <td>Does small talk with a medical provider affect...</td>\n",
       "      <td>2024</td>\n",
       "      <td>Myriam Safrai, A. Azaria</td>\n",
       "      <td>Efforts are being made to improve the time eff...</td>\n",
       "      <td>https://www.semanticscholar.org/paper/dc8ed1d8...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>J</td>\n",
       "      <td>Patsia, O; Giannopoulos, A; Giannakis, I</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Patsia, Ourania; Giannopoulos, Antonios; Giann...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>GPR Full-Waveform Inversion With Deep-Learning...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>gpr full waveform inversion with deep learning...</td>\n",
       "      <td>0be15269dffa995e0c2859ed9c354ad4e916632b</td>\n",
       "      <td>GPR Full-Waveform Inversion With Deep-Learning...</td>\n",
       "      <td>2023</td>\n",
       "      <td>O. Patsia, A. Giannopoulos, I. Giannakis</td>\n",
       "      <td>Numerical modeling of ground penetrating radar...</td>\n",
       "      <td>https://www.semanticscholar.org/paper/0be15269...</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>J</td>\n",
       "      <td>Putek, J; Szepietowski, JC</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Putek, Justyna; Szepietowski, Jacek C.</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Alexithymia in people with tattoos</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>alexithymia in people with tattoos</td>\n",
       "      <td>ecaff1dd1b14f06daf698e6eaa4a5926928bc27a</td>\n",
       "      <td>Alexithymia in people with tattoos</td>\n",
       "      <td>2024</td>\n",
       "      <td>Justyna Putek, J. Szepietowski</td>\n",
       "      <td>Introduction Tattoos are a form of body modifi...</td>\n",
       "      <td>https://www.semanticscholar.org/paper/ecaff1dd...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>J</td>\n",
       "      <td>Nadi, M; Aboghazleh, R; Dabbas, WF; Ibrahim, B...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Nadi, Mustafa; Aboghazleh, Refat; Dabbas, Wale...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Carotico-Clinoid Ligament Ossification: Unprov...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>carotico clinoid ligament ossification unprove...</td>\n",
       "      <td>242d9d92f6e2c91acb66e975ecf888c797c3676f</td>\n",
       "      <td>Carotico-Clinoid Ligament Ossification: Unprov...</td>\n",
       "      <td>2025</td>\n",
       "      <td>Mustafa Nadi, R. Aboghazleh, Waleed F Dabbas, ...</td>\n",
       "      <td>None</td>\n",
       "      <td>https://www.semanticscholar.org/paper/242d9d92...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>51 rows  80 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Publication Type                                            Authors  \\\n",
       "0                 J  Ferreira, G; Amidei, J; Nieto, R; Kaltenbrunne...   \n",
       "1                 C                   Kane, D; Parke, J; Jo, Y; Bak, J   \n",
       "2                 J  Bisbee, J; Clinton, JD; Dorff, C; Kenkel, B; L...   \n",
       "3                 J  Liu, HJ; Cao, Y; Wu, X; Qiu, C; Gu, JG; Liu, M...   \n",
       "4                 J  Boelaert, J; Coavoux, S; Ollion, E; Petev, I; ...   \n",
       "5                 J                                     Qu, Y; Wang, J   \n",
       "6                 C  Nguyen, H; Nguyen, V; Lpez-Fierro, S; Ludovis...   \n",
       "7                 J  Salecha, A; Ireland, ME; Subrahmanya, S; Sedoc...   \n",
       "8                 J  Yao, JC; Zhang, HJ; Ou, J; Zuo, DY; Yang, Z; D...   \n",
       "9                 C               Hmlinen, P; Tavast, M; Kunnari, A   \n",
       "10                J                        Zhang, S; Xu, J; Alvero, AJ   \n",
       "11                J  Zhang, BY; Chen, T; Wang, X; Li, Q; Zhang, WS;...   \n",
       "12                J  Gao, C; Lan, XC; Li, N; Yuan, Y; Ding, JT; Zho...   \n",
       "13                C  AlKhamissi, B; ElNokrashy, M; AlKhamissi, M; D...   \n",
       "14                J  Zhao, XJ; Wang, H; Dai, CX; Tang, JC; Deng, KX...   \n",
       "15                J              de Winter, JCF; Driessen, T; Dodou, D   \n",
       "16                J                           Rakovics, Z; Rakovics, M   \n",
       "17                J                                 Leung, HW; Bovy, J   \n",
       "18                J        Mburu, TK; Rong, KX; McColley, CJ; Werth, A   \n",
       "19                J  Zhang, KH; Dong, CQ; Guo, YF; Zhou, W; Yu, G; ...   \n",
       "20                J  Campos, M; Farinhas, A; Zerva, C; Figueiredo, ...   \n",
       "21                C                    Cheng, M; Piccardi, T; Yang, DY   \n",
       "22                J  Kaur, A; Budko, A; Liu, K; Eaton, E; Steitz, B...   \n",
       "23                J                              Ji, J; Kim, J; Kim, Y   \n",
       "24                J                                  Goli, A; Singh, A   \n",
       "25                C  Liu, YH; Chen, XY; Zhang, XQ; Gao, X; Zhang, J...   \n",
       "26                J  Ferreira, G; Amidei, J; Nieto, R; Kaltenbrunne...   \n",
       "27                C                    Scarlatos, A; Baker, RS; Lan, A   \n",
       "28                C  Steinmacher, I; Penney, JM; Felizardo, KR; Gar...   \n",
       "29                J        Wahidur, RSM; Tashdeed, I; Kaur, M; Lee, HN   \n",
       "30                C                  Hwang, E; Majumder, BP; Tandon, N   \n",
       "31                C                                  Min, Y; Jeong, JW   \n",
       "32                C                          Liu, A; Diab, M; Fried, D   \n",
       "33                J  Mishra, T; Sutanto, E; Rossanti, R; Pant, N; A...   \n",
       "34                J  Teferra, BG; Perivolaris, A; Hsiang, WN; Sidha...   \n",
       "35                J  Bachmann, F; van der Weijden, D; Heitz, L; Sar...   \n",
       "36                C                               Mancera, J; Tern, L   \n",
       "37                C  Kaate, I; Salminen, J; Jung, SG; Xuan, TTT; H...   \n",
       "38                J  Hadar-Shoval, D; Asraf, K; Mizrachi, Y; Haber,...   \n",
       "39                J  Amirova, A; Fteropoulli, T; Ahmed, N; Cowie, M...   \n",
       "40                J   Sumner, J; Wang, YC; Tan, SY; Chew, EHH; Yip, AW   \n",
       "41                J  Rdel-Ablass, K; Schliz, K; Schlick, C; Meindl...   \n",
       "42                J                          Lau, C; Zhu, XD; Chan, WY   \n",
       "43                J                                         Heston, TF   \n",
       "44                J  Hanss, K; Sarma, K; Glowinski, AL; Krystal, A;...   \n",
       "45                J  Alsalamah, SA; AlSalamah, S; Alsalamah, HA; Sh...   \n",
       "46                J                   Nguyen, MH; Sedoc, J; Taylor, CO   \n",
       "47                J                               Safrai, M; Azaria, A   \n",
       "48                J           Patsia, O; Giannopoulos, A; Giannakis, I   \n",
       "49                J                         Putek, J; Szepietowski, JC   \n",
       "50                J  Nadi, M; Aboghazleh, R; Dabbas, WF; Ibrahim, B...   \n",
       "\n",
       "    Book Authors                                       Book Editors  \\\n",
       "0            NaN                                                NaN   \n",
       "1            NaN                       Bouamor, H; Pino, J; Bali, K   \n",
       "2            NaN                                                NaN   \n",
       "3            NaN                                                NaN   \n",
       "4            NaN                                                NaN   \n",
       "5            NaN                                                NaN   \n",
       "6            NaN                                                NaN   \n",
       "7            NaN                                                NaN   \n",
       "8            NaN                                                NaN   \n",
       "9            NaN                                                NaN   \n",
       "10           NaN                                                NaN   \n",
       "11           NaN                                                NaN   \n",
       "12           NaN                                                NaN   \n",
       "13           NaN                    Ku, LW; Martins, A; Srikumar, V   \n",
       "14           NaN                                                NaN   \n",
       "15           NaN                                                NaN   \n",
       "16           NaN                                                NaN   \n",
       "17           NaN                                                NaN   \n",
       "18           NaN                                                NaN   \n",
       "19           NaN                                                NaN   \n",
       "20           NaN                                                NaN   \n",
       "21           NaN                       Bouamor, H; Pino, J; Bali, K   \n",
       "22           NaN                                                NaN   \n",
       "23           NaN                                                NaN   \n",
       "24           NaN                                                NaN   \n",
       "25           NaN                                          Larson, K   \n",
       "26           NaN                                                NaN   \n",
       "27           NaN                                                NaN   \n",
       "28           NaN                                                NaN   \n",
       "29           NaN                                                NaN   \n",
       "30           NaN                        Bouamor, H; Pino, J; Bali K   \n",
       "31           NaN  Eck, U; Sra, M; Stefanucci, J; Sugimoto, M; Ta...   \n",
       "32           NaN                    Martins, A; Srikumar, V; Ku, LW   \n",
       "33           NaN                                                NaN   \n",
       "34           NaN                                                NaN   \n",
       "35           NaN                                                NaN   \n",
       "36           NaN      Liao, HC; Cid, DD; Macadar, MA; Bernardini, F   \n",
       "37           NaN                                                NaN   \n",
       "38           NaN                                                NaN   \n",
       "39           NaN                                                NaN   \n",
       "40           NaN                                                NaN   \n",
       "41           NaN                                                NaN   \n",
       "42           NaN                                                NaN   \n",
       "43           NaN                                                NaN   \n",
       "44           NaN                                                NaN   \n",
       "45           NaN                                                NaN   \n",
       "46           NaN                                                NaN   \n",
       "47           NaN                                                NaN   \n",
       "48           NaN                                                NaN   \n",
       "49           NaN                                                NaN   \n",
       "50           NaN                                                NaN   \n",
       "\n",
       "           Book Group Authors  \\\n",
       "0                         NaN   \n",
       "1                         NaN   \n",
       "2                         NaN   \n",
       "3                         NaN   \n",
       "4                         NaN   \n",
       "5                         NaN   \n",
       "6   ASSOC COMPUTING MACHINERY   \n",
       "7                         NaN   \n",
       "8                         NaN   \n",
       "9                         ACM   \n",
       "10                        NaN   \n",
       "11                        NaN   \n",
       "12                        NaN   \n",
       "13                        NaN   \n",
       "14                        NaN   \n",
       "15                        NaN   \n",
       "16                        NaN   \n",
       "17                        NaN   \n",
       "18                        NaN   \n",
       "19                        NaN   \n",
       "20                        NaN   \n",
       "21                        NaN   \n",
       "22                        NaN   \n",
       "23                        NaN   \n",
       "24                        NaN   \n",
       "25                        NaN   \n",
       "26                        NaN   \n",
       "27                        ACM   \n",
       "28                        ACM   \n",
       "29                        NaN   \n",
       "30                        NaN   \n",
       "31                        NaN   \n",
       "32                        NaN   \n",
       "33                        NaN   \n",
       "34                        NaN   \n",
       "35                        NaN   \n",
       "36                        NaN   \n",
       "37                        ACM   \n",
       "38                        NaN   \n",
       "39                        NaN   \n",
       "40                        NaN   \n",
       "41                        NaN   \n",
       "42                        NaN   \n",
       "43                        NaN   \n",
       "44                        NaN   \n",
       "45                        NaN   \n",
       "46                        NaN   \n",
       "47                        NaN   \n",
       "48                        NaN   \n",
       "49                        NaN   \n",
       "50                        NaN   \n",
       "\n",
       "                                    Author Full Names  Book Author Full Names  \\\n",
       "0   Ferreira, Gregorio; Amidei, Jacopo; Nieto, Rub...                     NaN   \n",
       "1   Kane, Dongjun; Parke, JoonSuk; Jo, Yohan; Bak,...                     NaN   \n",
       "2   Bisbee, James; Clinton, Joshua D.; Dorff, Cass...                     NaN   \n",
       "3   Liu, Haijiang; Cao, Yong; Wu, Xun; Qiu, Chen; ...                     NaN   \n",
       "4   Boelaert, Julien; Coavoux, Samuel; Ollion, Eti...                     NaN   \n",
       "5                                  Qu, Yao; Wang, Jue                     NaN   \n",
       "6   Ha Nguyen; Nguyen, Victoria; Lopez-Fierro, Sar...                     NaN   \n",
       "7   Salecha, Aadesh; Ireland, Molly E.; Subrahmany...                     NaN   \n",
       "8   Yao, Junchi; Zhang, Hongjie; Ou, Jie; Zuo, Din...                     NaN   \n",
       "9   Hamalainen, Perttu; Tavast, Mikke; Kunnari, Anton                     NaN   \n",
       "10            Zhang, Simone; Xu, Janet; Alvero, A. J.                     NaN   \n",
       "11  Zhang, Baoyu; Chen, Tao; Wang, Xiao; Li, Qiang...                     NaN   \n",
       "12  Gao, Chen; Lan, Xiaochong; Li, Nian; Yuan, Yua...                     NaN   \n",
       "13  AlKhamissi, Badr; ElNokrashy, Muhammad; AlKham...                     NaN   \n",
       "14  Zhao, Xinjie; Wang, Hao; Dai, Chengxiao; Tang,...                     NaN   \n",
       "15  de Winter, Joost C. F.; Driessen, Tom; Dodou, ...                     NaN   \n",
       "16                 Rakovics, Zsofia; Rakovics, Marton                     NaN   \n",
       "17                          Leung, Henry W.; Bovy, Jo                     NaN   \n",
       "18  Mburu, Ted K.; Rong, Kangxuan; McColley, Campb...                     NaN   \n",
       "19  Zhang, Kaihang; Dong, Changqi; Guo, Yifeng; Zh...                     NaN   \n",
       "20  Campos, Margarida; Farinhas, Antonio; Zerva, C...                     NaN   \n",
       "21         Cheng, Myra; Piccardi, Tiziano; Yang, Diyi                     NaN   \n",
       "22  Kaur, Amarpreet; Budko, Alexander; Liu, Katrin...                     NaN   \n",
       "23            Ji, Junyung; Kim, Jiwoo; Kim, Younghoon                     NaN   \n",
       "24                         Goli, Ali; Singh, Amandeep                     NaN   \n",
       "25  Liu, Yuhan; Chen, Xiuying; Zhang, Xiaoqing; Ga...                     NaN   \n",
       "26  Ferreira, Gregorio; Amidei, Jacopo; Nieto, Rub...                     NaN   \n",
       "27  Scarlatos, Alexander; Baker, Ryan S.; Lan, Andrew                     NaN   \n",
       "28  Steinmacher, Igor; Penney, Jacob Mcauley; Feli...                     NaN   \n",
       "29  Wahidur, Rahman S. M.; Tashdeed, Ishmam; Kaur,...                     NaN   \n",
       "30  Hwang, EunJeong; Majumder, Bodhisattwa Prasad;...                     NaN   \n",
       "31                         Min, Yewon; Jeong, Jin-Woo                     NaN   \n",
       "32               Liu, Andy; Diab, Mona; Fried, Daniel                     NaN   \n",
       "33  Mishra, Tanisha; Sutanto, Edward; Rossanti, Ri...                     NaN   \n",
       "34  Teferra, Bazen Gashaw; Perivolaris, Argyrios; ...                     NaN   \n",
       "35  Bachmann, Fynn; van der Weijden, Daan; Heitz, ...                     NaN   \n",
       "36                         Mancera, Jose; Teran, Luis                     NaN   \n",
       "37  Kaate, Ilkka; Salminen, Joni; Jung, Soon-Gyo; ...                     NaN   \n",
       "38  Hadar-Shoval, Dorit; Asraf, Kfir; Mizrachi, Yo...                     NaN   \n",
       "39  Amirova, Aliya; Fteropoulli, Theodora; Ahmed, ...                     NaN   \n",
       "40  Sumner, Jennifer; Wang, Yuchen; Tan, Si Ying; ...                     NaN   \n",
       "41  Raedel-Ablass, Katharina; Schliz, Klaus; Schli...                     NaN   \n",
       "42          Lau, Clinton; Zhu, Xiaodan; Chan, Wai-Yip                     NaN   \n",
       "43                                  Heston, Thomas F.                     NaN   \n",
       "44  Hanss, Kaitlin; Sarma, Karthik, V; Glowinski, ...                     NaN   \n",
       "45  Alsalamah, Sara A.; AlSalamah, Shada; Alsalama...                     NaN   \n",
       "46  Nguyen, Michelle Hoang; Sedoc, Joao; Taylor, C...                     NaN   \n",
       "47                       Safrai, Myriam; Azaria, Amos                     NaN   \n",
       "48  Patsia, Ourania; Giannopoulos, Antonios; Giann...                     NaN   \n",
       "49             Putek, Justyna; Szepietowski, Jacek C.                     NaN   \n",
       "50  Nadi, Mustafa; Aboghazleh, Refat; Dabbas, Wale...                     NaN   \n",
       "\n",
       "    Group Authors                                          title_WoS  \\\n",
       "0             NaN  How Well Do Simulated Population Samples with ...   \n",
       "1             NaN  From Values to Opinions: Predicting Human Beha...   \n",
       "2             NaN  Synthetic Replacements for Human Survey Data? ...   \n",
       "3             NaN  Towards realistic evaluation of cultural value...   \n",
       "4             NaN  Machine Bias. How Do Generative Language Model...   \n",
       "5             NaN  Performance and biases of Large Language Model...   \n",
       "6             NaN  Simulating Climate Change Discussion with Larg...   \n",
       "7             NaN  Large language models display human-like socia...   \n",
       "8             NaN  Social opinions prediction utilizes fusing dyn...   \n",
       "9             NaN  Evaluating Large Language Models in Generating...   \n",
       "10            NaN  Generative AI Meets Open-Ended Survey Response...   \n",
       "11            NaN  Decoding Activist Public Opinion in Decentrali...   \n",
       "12            NaN  Large language models empowered agent-based mo...   \n",
       "13            NaN  Investigating Cultural Alignment of Large Lang...   \n",
       "14            NaN  Multi-Stage Simulation of Residents' Disaster ...   \n",
       "15            NaN  The use of ChatGPT for personality research: A...   \n",
       "16            NaN  Exploring the potential and limitations of lar...   \n",
       "17            NaN  Towards an astronomical foundation model for s...   \n",
       "18            NaN  Methodological foundations for artificial inte...   \n",
       "19            NaN  Lagged Stance Interactions and Counter-Spiral ...   \n",
       "20            NaN  Conformal Prediction for Natural Language Proc...   \n",
       "21            NaN  CoMPosT: Characterizing and Evaluating Caricat...   \n",
       "22            NaN  Automating Responses to Patient Portal Message...   \n",
       "23            NaN  Predicting Missing Values in Survey Data Using...   \n",
       "24            NaN  Frontiers: Can Large Language Models Capture H...   \n",
       "25            NaN  From Skepticism to Acceptance: Simulating the ...   \n",
       "26            NaN  Matching GPT-simulated Populations with Real O...   \n",
       "27            NaN  Exploring Knowledge Tracing in Tutor-Student D...   \n",
       "28            NaN  Can ChatGPT emulate humans in software enginee...   \n",
       "29            NaN  Enhancing Zero-Shot Crypto Sentiment With Fine...   \n",
       "30            NaN          Aligning Language Models to User Opinions   \n",
       "31            NaN  Public Speaking Q&A Practice with LLM-Generate...   \n",
       "32            NaN  Evaluating Large Language Model Biases in Pers...   \n",
       "33            NaN  Use of large language models as artificial int...   \n",
       "34            NaN  Leveraging large language models for automated...   \n",
       "35            NaN  Adaptive political surveys and GPT-4: Tackling...   \n",
       "36            NaN  From GenAI to Political Profiling Avatars: A D...   \n",
       "37            NaN  You Always Get an Answer: Analyzing Users' Int...   \n",
       "38            NaN  Assessing the Alignment of Large Language Mode...   \n",
       "39            NaN  Framework-based qualitative analysis of free r...   \n",
       "40            NaN  Perspectives and Experiences With Large Langua...   \n",
       "41            NaN  Teaching opportunities for anamnesis interview...   \n",
       "42            NaN  Automatic depression severity assessment with ...   \n",
       "43            NaN  Safety of Large Language Models in Addressing ...   \n",
       "44            NaN  Assessing the Accuracy and Reliability of Larg...   \n",
       "45            NaN  Virtual healthcare bot (VHC-Bot): a Person-cen...   \n",
       "46            NaN  Usability, Engagement, and Report Usefulness o...   \n",
       "47            NaN  Does small talk with a medical provider affect...   \n",
       "48            NaN  GPR Full-Waveform Inversion With Deep-Learning...   \n",
       "49            NaN                 Alexithymia in people with tattoos   \n",
       "50            NaN  Carotico-Clinoid Ligament Ossification: Unprov...   \n",
       "\n",
       "    Source Title  ...  UT (Unique WOS ID)  Web of Science Record  \\\n",
       "0            NaN  ...                 NaN                      0   \n",
       "1            NaN  ...                 NaN                      0   \n",
       "2            NaN  ...                 NaN                      0   \n",
       "3            NaN  ...                 NaN                      0   \n",
       "4            NaN  ...                 NaN                      0   \n",
       "5            NaN  ...                 NaN                      0   \n",
       "6            NaN  ...                 NaN                      0   \n",
       "7            NaN  ...                 NaN                      0   \n",
       "8            NaN  ...                 NaN                      0   \n",
       "9            NaN  ...                 NaN                      0   \n",
       "10           NaN  ...                 NaN                      0   \n",
       "11           NaN  ...                 NaN                      0   \n",
       "12           NaN  ...                 NaN                      0   \n",
       "13           NaN  ...                 NaN                      0   \n",
       "14           NaN  ...                 NaN                      0   \n",
       "15           NaN  ...                 NaN                      0   \n",
       "16           NaN  ...                 NaN                      0   \n",
       "17           NaN  ...                 NaN                      0   \n",
       "18           NaN  ...                 NaN                      0   \n",
       "19           NaN  ...                 NaN                      0   \n",
       "20           NaN  ...                 NaN                      0   \n",
       "21           NaN  ...                 NaN                      0   \n",
       "22           NaN  ...                 NaN                      0   \n",
       "23           NaN  ...                 NaN                      0   \n",
       "24           NaN  ...                 NaN                      0   \n",
       "25           NaN  ...                 NaN                      0   \n",
       "26           NaN  ...                 NaN                      0   \n",
       "27           NaN  ...                 NaN                      0   \n",
       "28           NaN  ...                 NaN                      0   \n",
       "29           NaN  ...                 NaN                      0   \n",
       "30           NaN  ...                 NaN                      0   \n",
       "31           NaN  ...                 NaN                      0   \n",
       "32           NaN  ...                 NaN                      0   \n",
       "33           NaN  ...                 NaN                      0   \n",
       "34           NaN  ...                 NaN                      0   \n",
       "35           NaN  ...                 NaN                      0   \n",
       "36           NaN  ...                 NaN                      0   \n",
       "37           NaN  ...                 NaN                      0   \n",
       "38           NaN  ...                 NaN                      0   \n",
       "39           NaN  ...                 NaN                      0   \n",
       "40           NaN  ...                 NaN                      0   \n",
       "41           NaN  ...                 NaN                      0   \n",
       "42           NaN  ...                 NaN                      0   \n",
       "43           NaN  ...                 NaN                      0   \n",
       "44           NaN  ...                 NaN                      0   \n",
       "45           NaN  ...                 NaN                      0   \n",
       "46           NaN  ...                 NaN                      0   \n",
       "47           NaN  ...                 NaN                      0   \n",
       "48           NaN  ...                 NaN                      0   \n",
       "49           NaN  ...                 NaN                      0   \n",
       "50           NaN  ...                 NaN                      0   \n",
       "\n",
       "                                           norm_title  \\\n",
       "0   how well do simulated population samples with ...   \n",
       "1   from values to opinions predicting human behav...   \n",
       "2   synthetic replacements for human survey data t...   \n",
       "3   towards realistic evaluation of cultural value...   \n",
       "4   machine bias how do generative language models...   \n",
       "5   performance and biases of large language model...   \n",
       "6   simulating climate change discussion with larg...   \n",
       "7   large language models display human like socia...   \n",
       "8   social opinions prediction utilizes fusing dyn...   \n",
       "9   evaluating large language models in generating...   \n",
       "10  generative ai meets open ended survey response...   \n",
       "11  decoding activist public opinion in decentrali...   \n",
       "12  large language models empowered agent based mo...   \n",
       "13  investigating cultural alignment of large lang...   \n",
       "14  multi stage simulation of residents disaster r...   \n",
       "15  the use of chatgpt for personality research ad...   \n",
       "16  exploring the potential and limitations of lar...   \n",
       "17  towards an astronomical foundation model for s...   \n",
       "18  methodological foundations for artificial inte...   \n",
       "19  lagged stance interactions and counter spiral ...   \n",
       "20  conformal prediction for natural language proc...   \n",
       "21  compost characterizing and evaluating caricatu...   \n",
       "22  automating responses to patient portal message...   \n",
       "23  predicting missing values in survey data using...   \n",
       "24  frontiers can large language models capture hu...   \n",
       "25  from skepticism to acceptance simulating the a...   \n",
       "26  matching gpt simulated populations with real o...   \n",
       "27  exploring knowledge tracing in tutor student d...   \n",
       "28  can chatgpt emulate humans in software enginee...   \n",
       "29  enhancing zero shot crypto sentiment with fine...   \n",
       "30          aligning language models to user opinions   \n",
       "31  public speaking q a practice with llm generate...   \n",
       "32  evaluating large language model biases in pers...   \n",
       "33  use of large language models as artificial int...   \n",
       "34  leveraging large language models for automated...   \n",
       "35  adaptive political surveys and gpt 4 tackling ...   \n",
       "36  from genai to political profiling avatars a da...   \n",
       "37  you always get an answer analyzing users inter...   \n",
       "38  assessing the alignment of large language mode...   \n",
       "39  framework based qualitative analysis of free r...   \n",
       "40  perspectives and experiences with large langua...   \n",
       "41  teaching opportunities for anamnesis interview...   \n",
       "42  automatic depression severity assessment with ...   \n",
       "43  safety of large language models in addressing ...   \n",
       "44  assessing the accuracy and reliability of larg...   \n",
       "45  virtual healthcare bot vhc bot a person center...   \n",
       "46  usability engagement and report usefulness of ...   \n",
       "47  does small talk with a medical provider affect...   \n",
       "48  gpr full waveform inversion with deep learning...   \n",
       "49                 alexithymia in people with tattoos   \n",
       "50  carotico clinoid ligament ossification unprove...   \n",
       "\n",
       "                                     paperId  \\\n",
       "0   25f383b7a807392696073801959dcc1c1aadd2bb   \n",
       "1   52e963c40a5083d5403cebf4d4782271aaa06994   \n",
       "2   58d735a54d3aba79ad3bffbfa2433d8e5ee27313   \n",
       "3   3ab59b3d4a4b2e89f7eda93a950eeaa77b37332e   \n",
       "4   45f9ea8d0dc1a7e6c56ff6e1f23c8e632687d2a7   \n",
       "5   e6d14d140c4faaf8f3d9f47e61cc5c6091bccf1e   \n",
       "6   dd95064d28ee5d123a6a284422bbba3d443f0416   \n",
       "7   8253104f5b1481d8557380d2dc5dab03ff9a7716   \n",
       "8   392de716c8f6610f080ba655e885935c20ac6c73   \n",
       "9   0ffd57884d7957f6b5634b9fa24843dc3759668f   \n",
       "10  8398dfa4d015b3784654a77b3913b62a1f68eed8   \n",
       "11  4949ff97cf5e7c31ed9a057cbbde4b95d3ddd1f8   \n",
       "12  592ac35991e583fc37c26ee6659d2deb85142ad9   \n",
       "13  b1890367317f0657c08ed96be4c474035b34b485   \n",
       "14  6d2077c8f4864103780b160501cd207005d045c8   \n",
       "15  781703bc7e4fb90766824ee808097171afa223b3   \n",
       "16  6cd94c4fdfd1ddf59b5385919851de2662e412fe   \n",
       "17  264cb7a7dbee1303ff9e0ebe2dac78646271a2fb   \n",
       "18  54b63afefc315b5f051f4a19fe413ef6c544c9fd   \n",
       "19  bc270ab2e00f78691c8fd16548809e3609dedee2   \n",
       "20  346fdbda3ecf4775819fced0cfed78357bee8128   \n",
       "21  7a4fe2f003241ad97bf1778e527cb0306fa90da2   \n",
       "22  caa3c4eb1ede700f03eef5b4f25a18b08c88d832   \n",
       "23  bdeeaf207e2563f39ad27a9d9511d8573b5bff95   \n",
       "24  0377c4c20d86e3a23cb5c22d89b3cb488c31a564   \n",
       "25  1bd4b8be136072c8f56114f2f8479aaed2ad6d9b   \n",
       "26  e186d394a49ab2866a8b1248a99e6f1637a238fe   \n",
       "27  06e9ec37cc25980544d0a78b5aa4893dafc65fd3   \n",
       "28  2a77ac8d1c36ccf9f222cf0ae16e251ac6b13e86   \n",
       "29  bcdc44ef48ffadbdaa3bd5cacfe9ddb9b9f48750   \n",
       "30  5db0f55332839c408e3049cea1a6ad48fefba70c   \n",
       "31  3b36ec5f47076620dc7735f8aba55d9c3c3e6b32   \n",
       "32  ae03f10729959435ecefc0e90cba4cbe8438a10b   \n",
       "33  0c1e396f7f23d34ebad01dac29de6898f18ae63e   \n",
       "34  d0deb3ffd586a886b435d67c1b3aad89eeeaf358   \n",
       "35  1d1097d378555393b73b492995121ab880fff142   \n",
       "36  3084188f92330fa837a87b6ca422b28ae1ca713c   \n",
       "37  48ebe4b39ff2dce8d6c026f6cd2cbea8406a9a6e   \n",
       "38  3a455a00d01fcd45d7797f296eb5b5db331ff7b1   \n",
       "39  ba5aefce80edc7da110f53fd071f4fbd6b5195b9   \n",
       "40  db593a47eec5f6dbd9f28e88d0e4d7450cc6376b   \n",
       "41  d46b4155182de3a385b8f0b323ca54a201e1c60f   \n",
       "42  527288d9ded807883d756f1b3503bc39e79e0a06   \n",
       "43  1554d7e72a8b5bcad108ff1d0c9014ddfaaebd0f   \n",
       "44  faf47d35147d836bcc03bffda819db2426febac8   \n",
       "45  4408852e43dcff9da71f1053f6aeefbea10db450   \n",
       "46  cddaccfd097ba11b991829930f95d0abd6a9dade   \n",
       "47  dc8ed1d85c4674181746ffe8f08e86e00d0054ff   \n",
       "48  0be15269dffa995e0c2859ed9c354ad4e916632b   \n",
       "49  ecaff1dd1b14f06daf698e6eaa4a5926928bc27a   \n",
       "50  242d9d92f6e2c91acb66e975ecf888c797c3676f   \n",
       "\n",
       "                                             title_SS  year  \\\n",
       "0   How Well Do Simulated Population Samples with ...  2025   \n",
       "1   From Values to Opinions: Predicting Human Beha...  2023   \n",
       "2   Synthetic Replacements for Human Survey Data? ...  2024   \n",
       "3   Towards realistic evaluation of cultural value...  2025   \n",
       "4   Machine Bias. How Do Generative Language Model...  2025   \n",
       "5   Performance and Biases of Large Language Model...  2024   \n",
       "6   Simulating Climate Change Discussion with Larg...  2024   \n",
       "7   Large language models display human-like socia...  2024   \n",
       "8   Social opinions prediction utilizes fusing dyn...  2024   \n",
       "9   Evaluating Large Language Models in Generating...  2023   \n",
       "10  Generative AI Meets Open-Ended Survey Response...  2025   \n",
       "11  Decoding Activist Public Opinion in Decentrali...  2024   \n",
       "12  Large Language Models Empowered Agent-based Mo...  2023   \n",
       "13  Investigating Cultural Alignment of Large Lang...  2024   \n",
       "14  Multi-Stage Simulation of Residents Disaster ...  2025   \n",
       "15  The use of ChatGPT for personality research: A...  2024   \n",
       "16  Exploring the potential and limitations of lar...  2024   \n",
       "17  Towards an astronomical foundation model for s...  2023   \n",
       "18  Methodological foundations for artificial inte...  2025   \n",
       "19  Lagged Stance Interactions and Counter-Spiral ...  2025   \n",
       "20  Conformal Prediction for Natural Language Proc...  2024   \n",
       "21  CoMPosT: Characterizing and Evaluating Caricat...  2023   \n",
       "22  Automating Responses to Patient Portal Message...  2024   \n",
       "23  Predicting Missing Values in Survey Data Using...  2024   \n",
       "24  Frontiers: Can Large Language Models Capture H...  2024   \n",
       "25  From Skepticism to Acceptance: Simulating the ...  2024   \n",
       "26  Matching GPT-simulated Populations with Real O...  2025   \n",
       "27  Exploring Knowledge Tracing in Tutor-Student D...  2024   \n",
       "28  Can ChatGPT emulate humans in software enginee...  2024   \n",
       "29  Enhancing Zero-Shot Crypto Sentiment With Fine...  2023   \n",
       "30          Aligning Language Models to User Opinions  2023   \n",
       "31  Public Speaking Q&A Practice with LLM-Generate...  2024   \n",
       "32  Evaluating Large Language Model Biases in Pers...  2024   \n",
       "33  Use of large language models as artificial int...  2024   \n",
       "34  Leveraging large language models for automated...  2025   \n",
       "35  Adaptive political surveys and GPT-4: Tackling...  2025   \n",
       "36  From GenAI to Political Profiling Avatars: A D...  2024   \n",
       "37  You Always Get an Answer: Analyzing Users I...  2025   \n",
       "38  Assessing the Alignment of Large Language Mode...  2024   \n",
       "39  Framework-based qualitative analysis of free r...  2023   \n",
       "40  Perspectives and Experiences With Large Langua...  2025   \n",
       "41  Teaching opportunities for anamnesis interview...  2025   \n",
       "42  Automatic depression severity assessment with ...  2023   \n",
       "43  Safety of Large Language Models in Addressing ...  2023   \n",
       "44  Assessing the Accuracy and Reliability of Larg...  2025   \n",
       "45  Virtual healthcare bot (VHC-Bot): a Person-cen...  2025   \n",
       "46  Usability, Engagement, and Report Usefulness o...  2024   \n",
       "47  Does small talk with a medical provider affect...  2024   \n",
       "48  GPR Full-Waveform Inversion With Deep-Learning...  2023   \n",
       "49                 Alexithymia in people with tattoos  2024   \n",
       "50  Carotico-Clinoid Ligament Ossification: Unprov...  2025   \n",
       "\n",
       "                                              authors  \\\n",
       "0   Gregorio Ferreira, Jacopo Amidei, Rubn Nieto,...   \n",
       "1   Dongjun Kang, Joonsuk Park, Yohan Jo, Jinyeong...   \n",
       "2   James Bisbee, Joshua D. Clinton, C. Dorff, Bre...   \n",
       "3   Haijiang Liu, Yong Cao, Xun Wu, Chen Qiu, Jing...   \n",
       "4   J. Boelaert, Samuel Coavoux, tienne Ollion, I...   \n",
       "5                                    Yao Qu, Jue Wang   \n",
       "6   Ha Nguyen, Victoria Nguyen, Sarah Lpez-Fierr...   \n",
       "7   Aadesh Salecha, Molly E. Ireland, Shashanka Su...   \n",
       "8   Junchi Yao, Hongjie Zhang, Jie Ou, Dingyi Zuo,...   \n",
       "9      Perttu Hmlinen, Mikke Tavast, Anton Kunnari   \n",
       "10                  Simone Zhang, Janet Xu, AJ Alvero   \n",
       "11  Baoyu Zhang, Tao Chen, Xiao Wang, Qiang Li, We...   \n",
       "12  Chen Gao, Xiaochong Lan, Nian Li, Yuan Yuan, J...   \n",
       "13  Badr AlKhamissi, Muhammad N. ElNokrashy, Mai A...   \n",
       "14  Xinjie Zhao, Hao Wang, Chengxiao Dai, Jiacheng...   \n",
       "15       J. D. de Winter, Tom Driessen, Dimitra Dodou   \n",
       "16                   Zsfia Rakovics, Mrton Rakovics   \n",
       "17                            Henry W. Leung, J. Bovy   \n",
       "18  Ted K. Mburu, Kangxuan Rong, Campbell J. McCol...   \n",
       "19  Kaihang Zhang, Changqi Dong, Yifeng Guo, Wuai ...   \n",
       "20  Margarida M. Campos, Antnio Farinhas, Chrysou...   \n",
       "21            Myra Cheng, Tiziano Piccardi, Diyi Yang   \n",
       "22  Amarpreet Kaur, Alexander Budko, Katrina Liu, ...   \n",
       "23               Junyung Ji, Jiwoo Kim, Younghoon Kim   \n",
       "24                           Ali Goli, Amandeep Singh   \n",
       "25  Yuhan Liu, Xiuying Chen, Xiaoqing Zhang, Xing ...   \n",
       "26  Gregorio Ferreira, Jacopo Amidei, Rubn Nieto,...   \n",
       "27     Alexander Scarlatos, Ryan S. Baker, Andrew Lan   \n",
       "28  Igor Steinmacher, Jacob Penney, K. Felizardo, ...   \n",
       "29  Rahman S M Wahidur, Ishmam Tashdeed, Manjit Ka...   \n",
       "30  EunJeong Hwang, Bodhisattwa Prasad Majumder, N...   \n",
       "31                           Yewon Min, Jin-Woo Jeong   \n",
       "32               Andy Liu, Mona T. Diab, Daniel Fried   \n",
       "33  Tanisha Mishra, Edward Sutanto, Rini Rossanti,...   \n",
       "34  Bazen Gashaw Teferra, Argyrios Perivolaris, We...   \n",
       "35  Fynn Bachmann, Daan van der Weijden, Lucien He...   \n",
       "36           Jos Alberto Mancera Andrade, Luis Tern   \n",
       "37  Ilkka Kaate, Joni O. Salminen, Soon-gyo Jung, ...   \n",
       "38  D. Hadar-Shoval, K. Asraf, Yonathan Mizrachi, ...   \n",
       "39  A. Amirova, T. Fteropoulli, Nafiso Ahmed, Mart...   \n",
       "40  Jennifer Sumner, Yuchen Wang, Si Ying Tan, Emi...   \n",
       "41  Katharina Rdel-Ablass, Klaus Schliz, Cornelia...   \n",
       "42             Clinton Lau, Xiaodan Zhu, Wai-Yip Chan   \n",
       "43                                       T. F. Heston   \n",
       "44  Kaitlin Hanss, Karthik V Sarma, Anne L Glowins...   \n",
       "45  Sara A. Alsalamah, Shada Alsalamah, Hessah A. ...   \n",
       "46                M. Nguyen, Joo Sedoc, C. O. Taylor   \n",
       "47                           Myriam Safrai, A. Azaria   \n",
       "48           O. Patsia, A. Giannopoulos, I. Giannakis   \n",
       "49                     Justyna Putek, J. Szepietowski   \n",
       "50  Mustafa Nadi, R. Aboghazleh, Waleed F Dabbas, ...   \n",
       "\n",
       "                                             abstract  \\\n",
       "0   Background: Advances in artificial intelligenc...   \n",
       "1   Being able to predict people's opinions on iss...   \n",
       "2   \\n Large language models (LLMs) offer new rese...   \n",
       "3                                                None   \n",
       "4   Generative artificial intelligence (AI) is inc...   \n",
       "5                                                None   \n",
       "6   Large language models (LLMs) have shown promis...   \n",
       "7   Abstract Large language models (LLMs) are beco...   \n",
       "8   In the context where social media emerges as a...   \n",
       "9   Collecting data is one of the bottlenecks of H...   \n",
       "10  The growing popularity of generative artificia...   \n",
       "11  Based on an investigation of online public opi...   \n",
       "12  Agent-based modeling and simulation have evolv...   \n",
       "13  The intricate relationship between language an...   \n",
       "14  The escalating frequency and complexity of nat...   \n",
       "15                                               None   \n",
       "16  Social and linguistic differences encoded in v...   \n",
       "17  Rapid strides are currently being made in the ...   \n",
       "18  This study investigates the use of large langu...   \n",
       "19  Understanding the dynamics of public opinion f...   \n",
       "20  Abstract The rapid proliferation of large lang...   \n",
       "21  Recent work has aimed to capture nuances of hu...   \n",
       "22  Background: Patient portals serve as vital bri...   \n",
       "23  Survey data play a crucial role in various res...   \n",
       "24  This paper examines the potential of large lan...   \n",
       "25  In the digital era, the rapid propagation of f...   \n",
       "26  This article analyzes how well OpenAIs LLM GP...   \n",
       "27  Recent advances in large language models (LLMs...   \n",
       "28  Context: There is a growing belief in the lite...   \n",
       "29  Blockchain technology has revolutionized the f...   \n",
       "30  An important aspect of developing LLMs that in...   \n",
       "31  This paper introduces a novel VR-based Q&A pra...   \n",
       "32  The task of persona-steered text generation re...   \n",
       "33  With breakthroughs in Natural Language Process...   \n",
       "34  Mental health diagnoses possess unique challen...   \n",
       "35  Adaptive questionnaires dynamically select the...   \n",
       "36  Voting advice applications (VAAs) are pivotal ...   \n",
       "37  We investigated the presence and acceptance of...   \n",
       "38  Background Large language models (LLMs) hold p...   \n",
       "39  Today, with the advent of Large-scale generati...   \n",
       "40  Background Large language models (LLMs) are tr...   \n",
       "41  Background This study presents a novel approac...   \n",
       "42  Introduction To assist mental health care prov...   \n",
       "43  Background Generative artificial intelligence ...   \n",
       "44  Background Large language models (LLMs), such ...   \n",
       "45                                               None   \n",
       "46  Background Family health history (FHx) is an i...   \n",
       "47  Efforts are being made to improve the time eff...   \n",
       "48  Numerical modeling of ground penetrating radar...   \n",
       "49  Introduction Tattoos are a form of body modifi...   \n",
       "50                                               None   \n",
       "\n",
       "                                                  url  citationCount  \n",
       "0   https://www.semanticscholar.org/paper/25f383b7...              0  \n",
       "1   https://www.semanticscholar.org/paper/52e963c4...              4  \n",
       "2   https://www.semanticscholar.org/paper/58d735a5...             74  \n",
       "3   https://www.semanticscholar.org/paper/3ab59b3d...              2  \n",
       "4   https://www.semanticscholar.org/paper/45f9ea8d...              9  \n",
       "5   https://www.semanticscholar.org/paper/e6d14d14...             46  \n",
       "6   https://www.semanticscholar.org/paper/dd95064d...             16  \n",
       "7   https://www.semanticscholar.org/paper/8253104f...             25  \n",
       "8   https://www.semanticscholar.org/paper/392de716...              5  \n",
       "9   https://www.semanticscholar.org/paper/0ffd5788...            218  \n",
       "10  https://www.semanticscholar.org/paper/8398dfa4...             10  \n",
       "11  https://www.semanticscholar.org/paper/4949ff97...              2  \n",
       "12  https://www.semanticscholar.org/paper/592ac359...            182  \n",
       "13  https://www.semanticscholar.org/paper/b1890367...             78  \n",
       "14  https://www.semanticscholar.org/paper/6d2077c8...              1  \n",
       "15  https://www.semanticscholar.org/paper/781703bc...             19  \n",
       "16  https://www.semanticscholar.org/paper/6cd94c4f...              1  \n",
       "17  https://www.semanticscholar.org/paper/264cb7a7...             24  \n",
       "18  https://www.semanticscholar.org/paper/54b63afe...              1  \n",
       "19  https://www.semanticscholar.org/paper/bc270ab2...              0  \n",
       "20  https://www.semanticscholar.org/paper/346fdbda...             22  \n",
       "21  https://www.semanticscholar.org/paper/7a4fe2f0...             89  \n",
       "22  https://www.semanticscholar.org/paper/caa3c4eb...              7  \n",
       "23  https://www.semanticscholar.org/paper/bdeeaf20...              2  \n",
       "24  https://www.semanticscholar.org/paper/0377c4c2...             31  \n",
       "25  https://www.semanticscholar.org/paper/1bd4b8be...             44  \n",
       "26  https://www.semanticscholar.org/paper/e186d394...              2  \n",
       "27  https://www.semanticscholar.org/paper/06e9ec37...             14  \n",
       "28  https://www.semanticscholar.org/paper/2a77ac8d...              7  \n",
       "29  https://www.semanticscholar.org/paper/bcdc44ef...             17  \n",
       "30  https://www.semanticscholar.org/paper/5db0f553...             82  \n",
       "31  https://www.semanticscholar.org/paper/3b36ec5f...              5  \n",
       "32  https://www.semanticscholar.org/paper/ae03f107...             49  \n",
       "33  https://www.semanticscholar.org/paper/0c1e396f...             14  \n",
       "34  https://www.semanticscholar.org/paper/d0deb3ff...              0  \n",
       "35  https://www.semanticscholar.org/paper/1d1097d3...              1  \n",
       "36  https://www.semanticscholar.org/paper/3084188f...              1  \n",
       "37  https://www.semanticscholar.org/paper/48ebe4b3...              3  \n",
       "38  https://www.semanticscholar.org/paper/3a455a00...             36  \n",
       "39  https://www.semanticscholar.org/paper/ba5aefce...             14  \n",
       "40  https://www.semanticscholar.org/paper/db593a47...              1  \n",
       "41  https://www.semanticscholar.org/paper/d46b4155...              8  \n",
       "42  https://www.semanticscholar.org/paper/527288d9...             20  \n",
       "43  https://www.semanticscholar.org/paper/1554d7e7...             43  \n",
       "44  https://www.semanticscholar.org/paper/faf47d35...              2  \n",
       "45  https://www.semanticscholar.org/paper/4408852e...              0  \n",
       "46  https://www.semanticscholar.org/paper/cddaccfd...              2  \n",
       "47  https://www.semanticscholar.org/paper/dc8ed1d8...              1  \n",
       "48  https://www.semanticscholar.org/paper/0be15269...             15  \n",
       "49  https://www.semanticscholar.org/paper/ecaff1dd...              0  \n",
       "50  https://www.semanticscholar.org/paper/242d9d92...              0  \n",
       "\n",
       "[51 rows x 80 columns]"
      ]
     },
     "execution_count": 185,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Normalize titles for matching\n",
    "df_results_wos['norm_title'] = df_results_wos['title'].map(normalize_title)\n",
    "df_SS_g7['norm_title'] = df_SS_g7['title'].map(normalize_title)\n",
    "\n",
    "# Find intersection of normalized titles\n",
    "common_norm_titles = set(df_results_wos['norm_title']).intersection(set(df_SS_g7['norm_title']))\n",
    "\n",
    "# Filter both dataframes to only those with common titles\n",
    "df_common = df_results_wos[df_results_wos['norm_title'].isin(common_norm_titles)].copy()\n",
    "df_common = df_common.merge(\n",
    "    df_SS_g7[df_SS_g7['norm_title'].isin(common_norm_titles)],\n",
    "    on='norm_title',\n",
    "    suffixes=('_WoS', '_SS')\n",
    ")\n",
    "\n",
    "df_common"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "id": "15ae5cfb",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Publication Type",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "Authors",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "Book Authors",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Book Editors",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "Book Group Authors",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "Author Full Names",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "Book Author Full Names",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Group Authors",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "title",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Source Title",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Book Series Title",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Book Series Subtitle",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Language",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Document Type",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Conference Title",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Conference Date",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Conference Location",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Conference Sponsor",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Conference Host",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Author Keywords",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Keywords Plus",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Abstract",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Addresses",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Affiliations",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Reprint Addresses",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Email Addresses",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Researcher Ids",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "ORCIDs",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Funding Orgs",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Funding Name Preferred",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Funding Text",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Cited References",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Cited Reference Count",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Times Cited, WoS Core",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Times Cited, All Databases",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "180 Day Usage Count",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Since 2013 Usage Count",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Publisher",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Publisher City",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Publisher Address",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "ISSN",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "eISSN",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "ISBN",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Journal Abbreviation",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Journal ISO Abbreviation",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Publication Date",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Publication Year",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Volume",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Issue",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Part Number",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Supplement",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Special Issue",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Meeting Abstract",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Start Page",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "End Page",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Article Number",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "DOI",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "DOI Link",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Book DOI",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Early Access Date",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Number of Pages",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "WoS Categories",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Web of Science Index",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Research Areas",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "IDS Number",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Pubmed Id",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Open Access Designations",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Highly Cited Status",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Hot Paper Status",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Date of Export",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "UT (Unique WOS ID)",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Web of Science Record",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "norm_title",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "paperId",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "year",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "authors",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "abstract",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "url",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "citationCount",
         "rawType": "float64",
         "type": "float"
        }
       ],
       "ref": "7dabac1e-7039-4a7f-83cb-5c2781c819df",
       "rows": [
        [
         "0",
         "C",
         "Kaiser, C; Kaiser, J; Manewitsch, V; Rau, L; Schallner, R",
         null,
         null,
         "ACM",
         "Kaiser, Carolin; Kaiser, Jakob; Manewitsch, Vladimir; Rau, Lea; Schallner, Rene",
         null,
         null,
         "Simulating Human Opinions with Large Language Models",
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         "0.0",
         "simulating human opinions with large language models",
         null,
         null,
         null,
         null,
         null,
         null
        ],
        [
         "1",
         "J",
         "Ferreira, G; Amidei, J; Nieto, R; Kaltenbrunner, A",
         null,
         null,
         null,
         "Ferreira, Gregorio; Amidei, Jacopo; Nieto, Ruben; Kaltenbrunner, Andreas",
         null,
         null,
         "How Well Do Simulated Population Samples with GPT-4 Align with Real Ones? The Case of the Eysenck Personality Questionnaire Revised-Abbreviated Personality Test",
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         "0.0",
         "how well do simulated population samples with gpt 4 align with real ones the case of the eysenck personality questionnaire revised abbreviated personality test",
         null,
         null,
         null,
         null,
         null,
         null
        ],
        [
         "2",
         "C",
         "Kane, D; Parke, J; Jo, Y; Bak, J",
         null,
         "Bouamor, H; Pino, J; Bali, K",
         null,
         "Kane, Dongjun; Parke, JoonSuk; Jo, Yohan; Bak, JinYeong",
         null,
         null,
         "From Values to Opinions: Predicting Human Behaviors and Stances Using Value-Injected Large Language Models",
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         "0.0",
         "from values to opinions predicting human behaviors and stances using value injected large language models",
         null,
         null,
         null,
         null,
         null,
         null
        ],
        [
         "3",
         "J",
         "Arora, N; Chakraborty, I; Nishimura, Y",
         null,
         null,
         null,
         "Arora, Neeraj; Chakraborty, Ishita; Nishimura, Yohei",
         null,
         null,
         "AI-Human Hybrids for Marketing Research: Leveraging Large Language Models (LLMs) as Collaborators",
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         "0.0",
         "ai human hybrids for marketing research leveraging large language models llms as collaborators",
         null,
         null,
         null,
         null,
         null,
         null
        ],
        [
         "4",
         "J",
         "Antal, M; Beder, N",
         null,
         null,
         null,
         "Antal, Margit; Beder, Norbert",
         null,
         null,
         "Eysenck Personality Questionnaire: A Comparative Study of Humans and Large Language Models Through Repeated Administrations",
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         "0.0",
         "eysenck personality questionnaire a comparative study of humans and large language models through repeated administrations",
         null,
         null,
         null,
         null,
         null,
         null
        ],
        [
         "5",
         "J",
         "Bisbee, J; Clinton, JD; Dorff, C; Kenkel, B; Larson, JM",
         null,
         null,
         null,
         "Bisbee, James; Clinton, Joshua D.; Dorff, Cassy; Kenkel, Brenton; Larson, Jennifer M.",
         null,
         null,
         "Synthetic Replacements for Human Survey Data? The Perils of Large Language Models",
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         "0.0",
         "synthetic replacements for human survey data the perils of large language models",
         null,
         null,
         null,
         null,
         null,
         null
        ],
        [
         "6",
         "J",
         "Liu, HJ; Cao, Y; Wu, X; Qiu, C; Gu, JG; Liu, MF; Hershcovich, D",
         null,
         null,
         null,
         "Liu, Haijiang; Cao, Yong; Wu, Xun; Qiu, Chen; Gu, Jinguang; Liu, Maofu; Hershcovich, Daniel",
         null,
         null,
         "Towards realistic evaluation of cultural value alignment in large language models: Diversity enhancement for survey response simulation",
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         "0.0",
         "towards realistic evaluation of cultural value alignment in large language models diversity enhancement for survey response simulation",
         null,
         null,
         null,
         null,
         null,
         null
        ],
        [
         "7",
         "J",
         "Lee, SG; Peng, TQ; Goldberg, MH; Rosenthal, SA; Kotcher, JE; Maibach, EW; Leiserowitz, A",
         null,
         null,
         null,
         "Lee, Sanguk; Peng, Tai-Quan; Goldberg, Matthew H.; Rosenthal, Seth A.; Kotcher, John E.; Maibach, Edward W.; Leiserowitz, Anthony",
         null,
         null,
         "Can large language models estimate public opinion about global warming? An empirical assessment of algorithmic fidelity and bias",
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         "0.0",
         "can large language models estimate public opinion about global warming an empirical assessment of algorithmic fidelity and bias",
         null,
         null,
         null,
         null,
         null,
         null
        ],
        [
         "8",
         "J",
         "Boelaert, J; Coavoux, S; Ollion, E; Petev, I; Prg, P",
         null,
         null,
         null,
         "Boelaert, Julien; Coavoux, Samuel; Ollion, Etienne; Petev, Ivaylo; Prag, Patrick",
         null,
         null,
         "Machine Bias. How Do Generative Language Models Answer Opinion Polls?",
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         "0.0",
         "machine bias how do generative language models answer opinion polls",
         null,
         null,
         null,
         null,
         null,
         null
        ],
        [
         "9",
         "J",
         "Qu, Y; Wang, J",
         null,
         null,
         null,
         "Qu, Yao; Wang, Jue",
         null,
         null,
         "Performance and biases of Large Language Models in public opinion simulation",
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         "0.0",
         "performance and biases of large language models in public opinion simulation",
         null,
         null,
         null,
         null,
         null,
         null
        ],
        [
         "10",
         "C",
         "Gao, S; Gao, BL; Wei, P; Guo, JP; Yuan, M; Han, C; Xu, YY",
         null,
         "Xiao, X; Yao, J",
         null,
         "Gao, Song; Gao, Bolin; Wei, Peng; Guo, Jianpeng; Yuan, Meng; Han, Cheng; Xu, Yueyun",
         null,
         null,
         "Application of foundation models for autonomous driving: a survey of data synthesis",
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         "0.0",
         "application of foundation models for autonomous driving a survey of data synthesis",
         null,
         null,
         null,
         null,
         null,
         null
        ],
        [
         "11",
         "C",
         "Nguyen, H; Nguyen, V; Lpez-Fierro, S; Ludovise, S; Santagata, R",
         null,
         null,
         "ASSOC COMPUTING MACHINERY",
         "Ha Nguyen; Nguyen, Victoria; Lopez-Fierro, Sariah; Ludovise, Sara; Santagata, Rossella",
         null,
         null,
         "Simulating Climate Change Discussion with Large Language Models: Considerations for Science Communication at Scale",
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         "0.0",
         "simulating climate change discussion with large language models considerations for science communication at scale",
         null,
         null,
         null,
         null,
         null,
         null
        ],
        [
         "12",
         "J",
         "Alonso, SLN; Ozili, PK; Hernndez, BMS; Pacheco, LM",
         null,
         null,
         null,
         "Alonso, Sergio Luis Nanez; Ozili, Peterson K.; Hernandez, Beatriz Maria Sastre; Pacheco, Luis Miguel",
         null,
         null,
         "Evaluating the acceptance of CBDCs: experimental research with artificial intelligence (AI) generated synthetic response",
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         "0.0",
         "evaluating the acceptance of cbdcs experimental research with artificial intelligence ai generated synthetic response",
         null,
         null,
         null,
         null,
         null,
         null
        ],
        [
         "13",
         "J",
         "Salecha, A; Ireland, ME; Subrahmanya, S; Sedoc, J; Ungar, LH; Eichstaedt, JC",
         null,
         null,
         null,
         "Salecha, Aadesh; Ireland, Molly E.; Subrahmanya, Shashanka; Sedoc, Joao; Ungar, Lyle H.; Eichstaedt, Johannes C.",
         null,
         null,
         "Large language models display human-like social desirability biases in Big Five personality surveys",
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         "0.0",
         "large language models display human like social desirability biases in big five personality surveys",
         null,
         null,
         null,
         null,
         null,
         null
        ],
        [
         "14",
         "J",
         "Lehtonen, E; Buder-Grndahl, T; Nordhoff, S",
         null,
         null,
         null,
         "Lehtonen, Esko; Buder-Grondahl, Tommi; Nordhoff, Sina",
         null,
         null,
         "Revealing the Influence of Semantic Similarity on Survey Responses: A Synthetic Data Generation Approach",
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         "0.0",
         "revealing the influence of semantic similarity on survey responses a synthetic data generation approach",
         null,
         null,
         null,
         null,
         null,
         null
        ],
        [
         "15",
         "J",
         "Yao, JC; Zhang, HJ; Ou, J; Zuo, DY; Yang, Z; Dong, ZC",
         null,
         null,
         null,
         "Yao, Junchi; Zhang, Hongjie; Ou, Jie; Zuo, Dingyi; Yang, Zheng; Dong, Zhicheng",
         null,
         null,
         "Social opinions prediction utilizes fusing dynamics equation with LLM-based agents",
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         "0.0",
         "social opinions prediction utilizes fusing dynamics equation with llm based agents",
         null,
         null,
         null,
         null,
         null,
         null
        ],
        [
         "16",
         "C",
         "Hmlinen, P; Tavast, M; Kunnari, A",
         null,
         null,
         "ACM",
         "Hamalainen, Perttu; Tavast, Mikke; Kunnari, Anton",
         null,
         null,
         "Evaluating Large Language Models in Generating Synthetic HCI Research Data: a Case Study",
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         "0.0",
         "evaluating large language models in generating synthetic hci research data a case study",
         null,
         null,
         null,
         null,
         null,
         null
        ],
        [
         "17",
         "J",
         "Zhang, S; Xu, J; Alvero, AJ",
         null,
         null,
         null,
         "Zhang, Simone; Xu, Janet; Alvero, A. J.",
         null,
         null,
         "Generative AI Meets Open-Ended Survey Responses: Research Participant Use of AI and Homogenization",
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         "0.0",
         "generative ai meets open ended survey responses research participant use of ai and homogenization",
         null,
         null,
         null,
         null,
         null,
         null
        ],
        [
         "18",
         "J",
         "Zhang, BY; Chen, T; Wang, X; Li, Q; Zhang, WS; Wang, FY",
         null,
         null,
         null,
         "Zhang, Baoyu; Chen, Tao; Wang, Xiao; Li, Qiang; Zhang, Weishan; Wang, Fei-Yue",
         null,
         null,
         "Decoding Activist Public Opinion in Decentralized Self-Organized Protests Using LLM",
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         "0.0",
         "decoding activist public opinion in decentralized self organized protests using llm",
         null,
         null,
         null,
         null,
         null,
         null
        ],
        [
         "19",
         "J",
         "von der Heyde, L; Haensch, AC; Wenz, A",
         null,
         null,
         null,
         "von der Heyde, Leah; Haensch, Anna-Carolina; Wenz, Alexander",
         null,
         null,
         "Vox Populi, Vox AI? Using Large Language Models to Estimate German Vote Choice",
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         "0.0",
         "vox populi vox ai using large language models to estimate german vote choice",
         null,
         null,
         null,
         null,
         null,
         null
        ],
        [
         "20",
         "J",
         "Gao, C; Lan, XC; Li, N; Yuan, Y; Ding, JT; Zhou, ZL; Xu, FL; Li, Y",
         null,
         null,
         null,
         "Gao, Chen; Lan, Xiaochong; Li, Nian; Yuan, Yuan; Ding, Jingtao; Zhou, Zhilun; Xu, Fengli; Li, Yong",
         null,
         null,
         "Large language models empowered agent-based modeling and simulation: a survey and perspectives",
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         "0.0",
         "large language models empowered agent based modeling and simulation a survey and perspectives",
         null,
         null,
         null,
         null,
         null,
         null
        ],
        [
         "21",
         "C",
         "Tan, Z; Li, DW; Wang, S; Beigi, A; Jiang, BH; Bhattacharjee, A; Karami, M; Li, JD; Cheng, L; Liu, H",
         null,
         "Al-Onaizan, Y; Bansal, M; Chen, YN",
         null,
         "Tan, Zhen; Li, Dawei; Wang, Song; Beigi, Alimohammad; Jiang, Bohan; Bhattacharjee, Amrita; Karami, Mansooreh; Li, Jundong; Cheng, Lu; Liu, Huan",
         null,
         null,
         "Large Language Models for Data Annotation and Synthesis: A Survey",
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         "0.0",
         "large language models for data annotation and synthesis a survey",
         null,
         null,
         null,
         null,
         null,
         null
        ],
        [
         "22",
         "J",
         "Jung, SG; Salminen, J; Aldous, KK; Jansen, BJ",
         null,
         null,
         null,
         "Jung, Soon-Gyo; Salminen, Joni; Aldous, Kholoud Khalil; Jansen, Bernard J.",
         null,
         null,
         "PersonaCraft: Leveraging language models for data-driven persona development",
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         "0.0",
         "personacraft leveraging language models for data driven persona development",
         null,
         null,
         null,
         null,
         null,
         null
        ],
        [
         "23",
         "J",
         "Cho, S; Kim, J; Kim, JH",
         null,
         null,
         null,
         "Cho, Suhyun; Kim, Jaeyun; Kim, Jang Hyun",
         null,
         null,
         "LLM-Based Doppelganger Models: Leveraging Synthetic Data for Human-Like Responses in Survey Simulations",
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         "0.0",
         "llm based doppelganger models leveraging synthetic data for human like responses in survey simulations",
         null,
         null,
         null,
         null,
         null,
         null
        ],
        [
         "24",
         "C",
         "Kaur, A; Aird, A; Borman, H; Nicastro, A; Leontjeva, A; Pizzato, L; Jermyn, D",
         null,
         null,
         "ACM",
         "Kaur, Arshnoor; Aird, Amanda; Borman, Harris; Nicastro, Andrea; Leontjeva, Anna; Pizzato, Luiz; Jermyn, Dan",
         null,
         null,
         "Synthetic Voices: Evaluating the Fidelity of LLM-Generated Personas in Representing People's FinancialWellbeing",
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         "0.0",
         "synthetic voices evaluating the fidelity of llm generated personas in representing people s financialwellbeing",
         null,
         null,
         null,
         null,
         null,
         null
        ],
        [
         "25",
         "J",
         "Ding, GZ; Liu, ZR; Li, S; Cao, J; Ye, ZH",
         null,
         null,
         null,
         "Ding, Guozhu; Liu, Zuer; Li, Shan; Cao, Jie; Ye, Zhuohai",
         null,
         null,
         "Impact of mindset types and social community compositions on opinion dynamics: A large language model-based multi-agent simulation study",
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         "0.0",
         "impact of mindset types and social community compositions on opinion dynamics a large language model based multi agent simulation study",
         null,
         null,
         null,
         null,
         null,
         null
        ],
        [
         "26",
         "C",
         "AlKhamissi, B; ElNokrashy, M; AlKhamissi, M; Diab, M",
         null,
         "Ku, LW; Martins, A; Srikumar, V",
         null,
         "AlKhamissi, Badr; ElNokrashy, Muhammad; AlKhamissi, Mai; Diab, Mona",
         null,
         null,
         "Investigating Cultural Alignment of Large Language Models",
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         "0.0",
         "investigating cultural alignment of large language models",
         null,
         null,
         null,
         null,
         null,
         null
        ],
        [
         "27",
         "J",
         "Zhao, XJ; Wang, H; Dai, CX; Tang, JC; Deng, KX; Zhong, ZH; Kong, FY; Wang, SY; Morikawa, S",
         null,
         null,
         null,
         "Zhao, Xinjie; Wang, Hao; Dai, Chengxiao; Tang, Jiacheng; Deng, Kaixin; Zhong, Zhihua; Kong, Fanying; Wang, Shiyun; Morikawa, So",
         null,
         null,
         "Multi-Stage Simulation of Residents' Disaster Risk Perception and Decision-Making Behavior: An Exploratory Study on Large Language Model-Driven Social-Cognitive Agent Framework",
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         "0.0",
         "multi stage simulation of residents disaster risk perception and decision making behavior an exploratory study on large language model driven social cognitive agent framework",
         null,
         null,
         null,
         null,
         null,
         null
        ],
        [
         "28",
         "J",
         "de Winter, JCF; Driessen, T; Dodou, D",
         null,
         null,
         null,
         "de Winter, Joost C. F.; Driessen, Tom; Dodou, Dimitra",
         null,
         null,
         "The use of ChatGPT for personality research: Administering questionnaires using generated personas",
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         "0.0",
         "the use of chatgpt for personality research administering questionnaires using generated personas",
         null,
         null,
         null,
         null,
         null,
         null
        ],
        [
         "29",
         "C",
         "Brasoveanu, AMP; Scharl, A; Nixon, LJB; Andonie, R",
         null,
         "Banissi, E; Datia, N; Pires, JM; Ursyn, A; Nazemi, K; Kovalerchuk, B; Andonie, R; Gavrilova, M; Nakayama, M; Nguyen, QV; Mabakane, MS; Rusu, A; Sciarrone, F; Temperini, M; Bouali, F; Venturini, G; Huang, T",
         null,
         "Brasoveanu, Adrian M. P.; Scharl, Arno; Nixon, Lyndon J. B.; Andonie, Razvan",
         null,
         null,
         "Visualizing Large Language Models: A Brief Survey",
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         "0.0",
         "visualizing large language models a brief survey",
         null,
         null,
         null,
         null,
         null,
         null
        ],
        [
         "30",
         "J",
         "Rakovics, Z; Rakovics, M",
         null,
         null,
         null,
         "Rakovics, Zsofia; Rakovics, Marton",
         null,
         null,
         "Exploring the potential and limitations of large language models as virtual respondents for social science research",
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         "0.0",
         "exploring the potential and limitations of large language models as virtual respondents for social science research",
         null,
         null,
         null,
         null,
         null,
         null
        ],
        [
         "31",
         "C",
         "Omata, M; Shimizu, A",
         null,
         "Ardito, C; Lanzilotti, R; Malizia, A; Petrie, H; Piccinno, A; Desolda, G; Inkpen, K",
         null,
         "Omata, Masaki; Shimizu, Atsuki",
         null,
         null,
         "A Proposal for Discreet Auxiliary Figures for Reducing VR Sickness and for Not Obstructing FOV",
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         "0.0",
         "a proposal for discreet auxiliary figures for reducing vr sickness and for not obstructing fov",
         null,
         null,
         null,
         null,
         null,
         null
        ],
        [
         "32",
         "J",
         "Leung, HW; Bovy, J",
         null,
         null,
         null,
         "Leung, Henry W.; Bovy, Jo",
         null,
         null,
         "Towards an astronomical foundation model for stars with a transformer-based model",
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         "0.0",
         "towards an astronomical foundation model for stars with a transformer based model",
         null,
         null,
         null,
         null,
         null,
         null
        ],
        [
         "33",
         "J",
         "Mburu, TK; Rong, KX; McColley, CJ; Werth, A",
         null,
         null,
         null,
         "Mburu, Ted K.; Rong, Kangxuan; McColley, Campbell J.; Werth, Alexandra",
         null,
         null,
         "Methodological foundations for artificial intelligence-driven survey question generation",
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         "0.0",
         "methodological foundations for artificial intelligence driven survey question generation",
         null,
         null,
         null,
         null,
         null,
         null
        ],
        [
         "34",
         "C",
         "Li, YH; Wang, SF; Ding, H; Chen, H",
         null,
         null,
         "ACM",
         "Li, Yinheng; Wang, Shaofei; Ding, Han; Chen, Hang",
         null,
         null,
         "Large Language Models in Finance: A Survey",
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         "0.0",
         "large language models in finance a survey",
         null,
         null,
         null,
         null,
         null,
         null
        ],
        [
         "35",
         "J",
         "Timothy, TR",
         null,
         null,
         null,
         "Timothy, Tyrese Raku",
         null,
         null,
         "AI-driven fabrication of healthcare survey data: methods, motivations, and ethical implications",
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         "0.0",
         "ai driven fabrication of healthcare survey data methods motivations and ethical implications",
         null,
         null,
         null,
         null,
         null,
         null
        ],
        [
         "36",
         "J",
         "Zhang, KH; Dong, CQ; Guo, YF; Zhou, W; Yu, G; Mi, JN",
         null,
         null,
         null,
         "Zhang, Kaihang; Dong, Changqi; Guo, Yifeng; Zhou, Wuai; Yu, Guang; Mi, Jianing",
         null,
         null,
         "Lagged Stance Interactions and Counter-Spiral of Silence: A Data-Driven Analysis and Agent-Based Modeling of Technical Public Opinion Events",
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         "0.0",
         "lagged stance interactions and counter spiral of silence a data driven analysis and agent based modeling of technical public opinion events",
         null,
         null,
         null,
         null,
         null,
         null
        ],
        [
         "37",
         "C",
         "Zhao, XX; Qiu, Y",
         null,
         "Rau, PLP",
         null,
         "Zhao, Xiaoxuan; Qiu, Yue",
         null,
         null,
         "Insight Through Dialogue: A Practical Exploration of AIGC in Cross-cultural Design Research",
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         "0.0",
         "insight through dialogue a practical exploration of aigc in cross cultural design research",
         null,
         null,
         null,
         null,
         null,
         null
        ],
        [
         "38",
         "J",
         "Zhang, ZC; Wu, HN; Zhang, EL; Zhai, GT; Lin, WS",
         null,
         null,
         null,
         "Zhang, Zicheng; Wu, Haoning; Zhang, Erli; Zhai, Guangtao; Lin, Weisi",
         null,
         null,
         "Q-BENCH+: A Benchmark for Multi-Modal Foundation Models on Low-Level Vision From Single Images to Pairs",
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         "0.0",
         "q bench a benchmark for multi modal foundation models on low level vision from single images to pairs",
         null,
         null,
         null,
         null,
         null,
         null
        ],
        [
         "39",
         "J",
         "Campos, M; Farinhas, A; Zerva, C; Figueiredo, MAT; Martins, AFT",
         null,
         null,
         null,
         "Campos, Margarida; Farinhas, Antonio; Zerva, Chrysoula; Figueiredo, Mario A. T.; Martins, Andre F. T.",
         null,
         null,
         "Conformal Prediction for Natural Language Processing: A Survey",
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         "0.0",
         "conformal prediction for natural language processing a survey",
         null,
         null,
         null,
         null,
         null,
         null
        ],
        [
         "40",
         "J",
         "Wilden, J; Riley, RH",
         null,
         null,
         null,
         "Wilden, J; Riley, RH",
         null,
         null,
         "Personal digital assistant (PDA) use amongst anaesthetists: An Australian survey",
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         "0.0",
         "personal digital assistant pda use amongst anaesthetists an australian survey",
         null,
         null,
         null,
         null,
         null,
         null
        ],
        [
         "41",
         "J",
         "Zheng, JY; Wang, X; Hosio, S; Xu, XX; Lee, LH",
         null,
         null,
         null,
         "Zheng, Jingyao; Wang, Xian; Hosio, Simo; Xu, Xiaoxian; Lee, Lik-Hang",
         null,
         null,
         "LMLPA: Language Model Linguistic Personality Assessment",
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         "0.0",
         "lmlpa language model linguistic personality assessment",
         null,
         null,
         null,
         null,
         null,
         null
        ],
        [
         "42",
         "C",
         "Cheng, M; Piccardi, T; Yang, DY",
         null,
         "Bouamor, H; Pino, J; Bali, K",
         null,
         "Cheng, Myra; Piccardi, Tiziano; Yang, Diyi",
         null,
         null,
         "CoMPosT: Characterizing and Evaluating Caricature in LLM Simulations",
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         "0.0",
         "compost characterizing and evaluating caricature in llm simulations",
         null,
         null,
         null,
         null,
         null,
         null
        ],
        [
         "43",
         "C",
         "Dobre, SC; Popescu, E",
         null,
         null,
         "IEEE",
         "Dobre, Stefania-Carmen; Popescu, Elvira",
         null,
         null,
         "Exploring Students' Perception and Experience with ChatGPT and Critical Thinking in a Higher Education Context",
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         "0.0",
         "exploring students perception and experience with chatgpt and critical thinking in a higher education context",
         null,
         null,
         null,
         null,
         null,
         null
        ],
        [
         "44",
         "J",
         "Kaur, A; Budko, A; Liu, K; Eaton, E; Steitz, BD; Johnson, KB",
         null,
         null,
         null,
         "Kaur, Amarpreet; Budko, Alexander; Liu, Katrina; Eaton, Eric; Steitz, Bryan D.; Johnson, Kevin B.",
         null,
         null,
         "Automating Responses to Patient Portal Messages Using Generative AI",
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         "0.0",
         "automating responses to patient portal messages using generative ai",
         null,
         null,
         null,
         null,
         null,
         null
        ],
        [
         "45",
         "J",
         "Ji, J; Kim, J; Kim, Y",
         null,
         null,
         null,
         "Ji, Junyung; Kim, Jiwoo; Kim, Younghoon",
         null,
         null,
         "Predicting Missing Values in Survey Data Using Prompt Engineering for Addressing Item Non-Response",
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         "0.0",
         "predicting missing values in survey data using prompt engineering for addressing item non response",
         null,
         null,
         null,
         null,
         null,
         null
        ],
        [
         "46",
         "J",
         "Cisar, P",
         null,
         null,
         null,
         "Cisar, Peter",
         null,
         null,
         "The Place and Role of Honeypot Solutions in Network Intrusion Detection Systems",
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         "0.0",
         "the place and role of honeypot solutions in network intrusion detection systems",
         null,
         null,
         null,
         null,
         null,
         null
        ],
        [
         "47",
         "J",
         "Goli, A; Singh, A",
         null,
         null,
         null,
         "Goli, Ali; Singh, Amandeep",
         null,
         null,
         "Frontiers: Can Large Language Models Capture Human Preferences?",
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         "0.0",
         "frontiers can large language models capture human preferences",
         null,
         null,
         null,
         null,
         null,
         null
        ],
        [
         "48",
         "C",
         "Zhao, RB; Xie, ZW; Zhuang, YP; Li, HX; Yu, PLH",
         null,
         "Kashihara, A; Jiang, B; Rodrigo, MM; Sugay, JO",
         null,
         "Zhao, Ruibin; Xie, Zhiwei; Zhuang, Yipeng; Li, Huixian; Yu, Philip L. H.",
         null,
         null,
         "Enhancing Language Learning Through Multimodal AI-Driven Feedback on Picture Descriptions: An Eye-Tracking Study",
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         "0.0",
         "enhancing language learning through multimodal ai driven feedback on picture descriptions an eye tracking study",
         null,
         null,
         null,
         null,
         null,
         null
        ],
        [
         "49",
         "J",
         "Hur, JK; Heffner, J; Feng, GW; Joormann, J; Rutledge, RB",
         null,
         null,
         null,
         "Hur, Jihyun K.; Heffner, Joseph; Feng, Gloria W.; Joormann, Jutta; Rutledge, Robb B.",
         null,
         null,
         "Language sentiment predicts changes in depressive symptoms",
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         "0.0",
         "language sentiment predicts changes in depressive symptoms",
         null,
         null,
         null,
         null,
         null,
         null
        ]
       ],
       "shape": {
        "columns": 79,
        "rows": 2919
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Publication Type</th>\n",
       "      <th>Authors</th>\n",
       "      <th>Book Authors</th>\n",
       "      <th>Book Editors</th>\n",
       "      <th>Book Group Authors</th>\n",
       "      <th>Author Full Names</th>\n",
       "      <th>Book Author Full Names</th>\n",
       "      <th>Group Authors</th>\n",
       "      <th>title</th>\n",
       "      <th>Source Title</th>\n",
       "      <th>...</th>\n",
       "      <th>Date of Export</th>\n",
       "      <th>UT (Unique WOS ID)</th>\n",
       "      <th>Web of Science Record</th>\n",
       "      <th>norm_title</th>\n",
       "      <th>paperId</th>\n",
       "      <th>year</th>\n",
       "      <th>authors</th>\n",
       "      <th>abstract</th>\n",
       "      <th>url</th>\n",
       "      <th>citationCount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>C</td>\n",
       "      <td>Kaiser, C; Kaiser, J; Manewitsch, V; Rau, L; S...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ACM</td>\n",
       "      <td>Kaiser, Carolin; Kaiser, Jakob; Manewitsch, Vl...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Simulating Human Opinions with Large Language ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>simulating human opinions with large language ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>J</td>\n",
       "      <td>Ferreira, G; Amidei, J; Nieto, R; Kaltenbrunne...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Ferreira, Gregorio; Amidei, Jacopo; Nieto, Rub...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>How Well Do Simulated Population Samples with ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>how well do simulated population samples with ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>C</td>\n",
       "      <td>Kane, D; Parke, J; Jo, Y; Bak, J</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Bouamor, H; Pino, J; Bali, K</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Kane, Dongjun; Parke, JoonSuk; Jo, Yohan; Bak,...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>From Values to Opinions: Predicting Human Beha...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>from values to opinions predicting human behav...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>J</td>\n",
       "      <td>Arora, N; Chakraborty, I; Nishimura, Y</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Arora, Neeraj; Chakraborty, Ishita; Nishimura,...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>AI-Human Hybrids for Marketing Research: Lever...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>ai human hybrids for marketing research levera...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>J</td>\n",
       "      <td>Antal, M; Beder, N</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Antal, Margit; Beder, Norbert</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Eysenck Personality Questionnaire: A Comparati...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>eysenck personality questionnaire a comparativ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2914</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Generating Interpretations of Policy Announcem...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>generating interpretations of policy announcem...</td>\n",
       "      <td>00837a426339a384df537eaaac69e52480c8e8b5</td>\n",
       "      <td>2024.0</td>\n",
       "      <td>Andreas Marfurt, Ashley Thornton, David Sylvan...</td>\n",
       "      <td>Recent advances in language modeling have focu...</td>\n",
       "      <td>https://www.semanticscholar.org/paper/00837a42...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2915</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Demystifying diagnosis: an efficient deep lear...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>demystifying diagnosis an efficient deep learn...</td>\n",
       "      <td>0081eedf01655a7c541e52c8fb6a04b8da18e9f4</td>\n",
       "      <td>2025.0</td>\n",
       "      <td>Ahmed Alzahrani, Muhammad Ali Raza, Muhammad Z...</td>\n",
       "      <td>As per a WHO survey conducted in 2023, more th...</td>\n",
       "      <td>https://www.semanticscholar.org/paper/0081eedf...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2916</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Usability Testing of ChatGPT Website as a Medi...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>usability testing of chatgpt website as a medi...</td>\n",
       "      <td>00798a978fa3f62624668109bb414bb4add1ff32</td>\n",
       "      <td>2023.0</td>\n",
       "      <td>Harry Ma'ruf, Bayu Rima Aditya, Elis Hernawati...</td>\n",
       "      <td>This study aims to determine the level of usab...</td>\n",
       "      <td>https://www.semanticscholar.org/paper/00798a97...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2917</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Artificial Intelligence for Urban Safety: A Ca...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>artificial intelligence for urban safety a cas...</td>\n",
       "      <td>0043df60e07f3c5f6d8aece33aa999f036c35c00</td>\n",
       "      <td>2024.0</td>\n",
       "      <td>Alessandro Marceddu, Massimo Miccoli, Alessand...</td>\n",
       "      <td>Abstract. This study explores the application ...</td>\n",
       "      <td>https://www.semanticscholar.org/paper/0043df60...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2918</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Future Trends in AI: Data Management and Analy...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>future trends in ai data management and analys...</td>\n",
       "      <td>003f273d1bda250dbd24b4dcf043dfabf558dfc9</td>\n",
       "      <td>2025.0</td>\n",
       "      <td></td>\n",
       "      <td>Introduction: This study offers a thorough ana...</td>\n",
       "      <td>https://www.semanticscholar.org/paper/003f273d...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2919 rows  79 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Publication Type                                            Authors  \\\n",
       "0                   C  Kaiser, C; Kaiser, J; Manewitsch, V; Rau, L; S...   \n",
       "1                   J  Ferreira, G; Amidei, J; Nieto, R; Kaltenbrunne...   \n",
       "2                   C                   Kane, D; Parke, J; Jo, Y; Bak, J   \n",
       "3                   J             Arora, N; Chakraborty, I; Nishimura, Y   \n",
       "4                   J                                 Antal, M; Beder, N   \n",
       "...               ...                                                ...   \n",
       "2914              NaN                                                NaN   \n",
       "2915              NaN                                                NaN   \n",
       "2916              NaN                                                NaN   \n",
       "2917              NaN                                                NaN   \n",
       "2918              NaN                                                NaN   \n",
       "\n",
       "      Book Authors                  Book Editors Book Group Authors  \\\n",
       "0              NaN                           NaN                ACM   \n",
       "1              NaN                           NaN                NaN   \n",
       "2              NaN  Bouamor, H; Pino, J; Bali, K                NaN   \n",
       "3              NaN                           NaN                NaN   \n",
       "4              NaN                           NaN                NaN   \n",
       "...            ...                           ...                ...   \n",
       "2914           NaN                           NaN                NaN   \n",
       "2915           NaN                           NaN                NaN   \n",
       "2916           NaN                           NaN                NaN   \n",
       "2917           NaN                           NaN                NaN   \n",
       "2918           NaN                           NaN                NaN   \n",
       "\n",
       "                                      Author Full Names  \\\n",
       "0     Kaiser, Carolin; Kaiser, Jakob; Manewitsch, Vl...   \n",
       "1     Ferreira, Gregorio; Amidei, Jacopo; Nieto, Rub...   \n",
       "2     Kane, Dongjun; Parke, JoonSuk; Jo, Yohan; Bak,...   \n",
       "3     Arora, Neeraj; Chakraborty, Ishita; Nishimura,...   \n",
       "4                         Antal, Margit; Beder, Norbert   \n",
       "...                                                 ...   \n",
       "2914                                                NaN   \n",
       "2915                                                NaN   \n",
       "2916                                                NaN   \n",
       "2917                                                NaN   \n",
       "2918                                                NaN   \n",
       "\n",
       "      Book Author Full Names  Group Authors  \\\n",
       "0                        NaN            NaN   \n",
       "1                        NaN            NaN   \n",
       "2                        NaN            NaN   \n",
       "3                        NaN            NaN   \n",
       "4                        NaN            NaN   \n",
       "...                      ...            ...   \n",
       "2914                     NaN            NaN   \n",
       "2915                     NaN            NaN   \n",
       "2916                     NaN            NaN   \n",
       "2917                     NaN            NaN   \n",
       "2918                     NaN            NaN   \n",
       "\n",
       "                                                  title  Source Title  ...  \\\n",
       "0     Simulating Human Opinions with Large Language ...           NaN  ...   \n",
       "1     How Well Do Simulated Population Samples with ...           NaN  ...   \n",
       "2     From Values to Opinions: Predicting Human Beha...           NaN  ...   \n",
       "3     AI-Human Hybrids for Marketing Research: Lever...           NaN  ...   \n",
       "4     Eysenck Personality Questionnaire: A Comparati...           NaN  ...   \n",
       "...                                                 ...           ...  ...   \n",
       "2914  Generating Interpretations of Policy Announcem...           NaN  ...   \n",
       "2915  Demystifying diagnosis: an efficient deep lear...           NaN  ...   \n",
       "2916  Usability Testing of ChatGPT Website as a Medi...           NaN  ...   \n",
       "2917  Artificial Intelligence for Urban Safety: A Ca...           NaN  ...   \n",
       "2918  Future Trends in AI: Data Management and Analy...           NaN  ...   \n",
       "\n",
       "      Date of Export  UT (Unique WOS ID)  Web of Science Record  \\\n",
       "0                NaN                 NaN                    0.0   \n",
       "1                NaN                 NaN                    0.0   \n",
       "2                NaN                 NaN                    0.0   \n",
       "3                NaN                 NaN                    0.0   \n",
       "4                NaN                 NaN                    0.0   \n",
       "...              ...                 ...                    ...   \n",
       "2914             NaN                 NaN                    NaN   \n",
       "2915             NaN                 NaN                    NaN   \n",
       "2916             NaN                 NaN                    NaN   \n",
       "2917             NaN                 NaN                    NaN   \n",
       "2918             NaN                 NaN                    NaN   \n",
       "\n",
       "                                             norm_title  \\\n",
       "0     simulating human opinions with large language ...   \n",
       "1     how well do simulated population samples with ...   \n",
       "2     from values to opinions predicting human behav...   \n",
       "3     ai human hybrids for marketing research levera...   \n",
       "4     eysenck personality questionnaire a comparativ...   \n",
       "...                                                 ...   \n",
       "2914  generating interpretations of policy announcem...   \n",
       "2915  demystifying diagnosis an efficient deep learn...   \n",
       "2916  usability testing of chatgpt website as a medi...   \n",
       "2917  artificial intelligence for urban safety a cas...   \n",
       "2918  future trends in ai data management and analys...   \n",
       "\n",
       "                                       paperId    year  \\\n",
       "0                                          NaN     NaN   \n",
       "1                                          NaN     NaN   \n",
       "2                                          NaN     NaN   \n",
       "3                                          NaN     NaN   \n",
       "4                                          NaN     NaN   \n",
       "...                                        ...     ...   \n",
       "2914  00837a426339a384df537eaaac69e52480c8e8b5  2024.0   \n",
       "2915  0081eedf01655a7c541e52c8fb6a04b8da18e9f4  2025.0   \n",
       "2916  00798a978fa3f62624668109bb414bb4add1ff32  2023.0   \n",
       "2917  0043df60e07f3c5f6d8aece33aa999f036c35c00  2024.0   \n",
       "2918  003f273d1bda250dbd24b4dcf043dfabf558dfc9  2025.0   \n",
       "\n",
       "                                                authors  \\\n",
       "0                                                   NaN   \n",
       "1                                                   NaN   \n",
       "2                                                   NaN   \n",
       "3                                                   NaN   \n",
       "4                                                   NaN   \n",
       "...                                                 ...   \n",
       "2914  Andreas Marfurt, Ashley Thornton, David Sylvan...   \n",
       "2915  Ahmed Alzahrani, Muhammad Ali Raza, Muhammad Z...   \n",
       "2916  Harry Ma'ruf, Bayu Rima Aditya, Elis Hernawati...   \n",
       "2917  Alessandro Marceddu, Massimo Miccoli, Alessand...   \n",
       "2918                                                      \n",
       "\n",
       "                                               abstract  \\\n",
       "0                                                   NaN   \n",
       "1                                                   NaN   \n",
       "2                                                   NaN   \n",
       "3                                                   NaN   \n",
       "4                                                   NaN   \n",
       "...                                                 ...   \n",
       "2914  Recent advances in language modeling have focu...   \n",
       "2915  As per a WHO survey conducted in 2023, more th...   \n",
       "2916  This study aims to determine the level of usab...   \n",
       "2917  Abstract. This study explores the application ...   \n",
       "2918  Introduction: This study offers a thorough ana...   \n",
       "\n",
       "                                                    url  citationCount  \n",
       "0                                                   NaN            NaN  \n",
       "1                                                   NaN            NaN  \n",
       "2                                                   NaN            NaN  \n",
       "3                                                   NaN            NaN  \n",
       "4                                                   NaN            NaN  \n",
       "...                                                 ...            ...  \n",
       "2914  https://www.semanticscholar.org/paper/00837a42...            0.0  \n",
       "2915  https://www.semanticscholar.org/paper/0081eedf...            0.0  \n",
       "2916  https://www.semanticscholar.org/paper/00798a97...            0.0  \n",
       "2917  https://www.semanticscholar.org/paper/0043df60...            0.0  \n",
       "2918  https://www.semanticscholar.org/paper/003f273d...            0.0  \n",
       "\n",
       "[2919 rows x 79 columns]"
      ]
     },
     "execution_count": 187,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create a new dataframe that combines papers from both df_results_wos and df_SS_g7 but remove duplicates based on 'norm_title' column\n",
    "df_combined = pd.concat([df_results_wos, df_SS_g7], ignore_index=True).drop_duplicates(subset=['norm_title']).reset_index(drop=True)\n",
    "df_combined"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

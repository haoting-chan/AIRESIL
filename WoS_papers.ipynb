{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ff231391",
   "metadata": {},
   "source": [
    "# WP4.1 Systematic Review of Pre-trained LLMs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4a4bc2ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import unicodedata\n",
    "import re\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cb6e9ed",
   "metadata": {},
   "source": [
    "## Load Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e61d692c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gold list size: 21\n"
     ]
    },
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Title",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Item Type",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "preprint_flag",
         "rawType": "object",
         "type": "string"
        }
       ],
       "ref": "35215826-0ae4-4204-a5b2-bce91351011e",
       "rows": [
        [
         "0",
         "Out of One, Many: Using Language Models to Simulate Human Samples",
         "journalArticle",
         "non-preprint"
        ],
        [
         "1",
         "Examining the Feasibility of Large Language Models as Survey Respondents",
         "preprint",
         "preprint"
        ],
        [
         "2",
         "Donald Trumps in the Virtual Polls: Simulating and Predicting Public Opinions in Surveys Using Large Language Models",
         "preprint",
         "preprint"
        ]
       ],
       "shape": {
        "columns": 3,
        "rows": 3
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Item Type</th>\n",
       "      <th>preprint_flag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Out of One, Many: Using Language Models to Sim...</td>\n",
       "      <td>journalArticle</td>\n",
       "      <td>non-preprint</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Examining the Feasibility of Large Language Mo...</td>\n",
       "      <td>preprint</td>\n",
       "      <td>preprint</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Donald Trumps in the Virtual Polls: Simulating...</td>\n",
       "      <td>preprint</td>\n",
       "      <td>preprint</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Title       Item Type  \\\n",
       "0  Out of One, Many: Using Language Models to Sim...  journalArticle   \n",
       "1  Examining the Feasibility of Large Language Mo...        preprint   \n",
       "2  Donald Trumps in the Virtual Polls: Simulating...        preprint   \n",
       "\n",
       "  preprint_flag  \n",
       "0  non-preprint  \n",
       "1      preprint  \n",
       "2      preprint  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the CSV of Zotero list of papers\n",
    "gold_df = pd.read_csv(\"data/LLM - Survey Proxies.csv\")\n",
    "\n",
    "gold_df = gold_df[[\"Title\", \"Item Type\"]].dropna().drop_duplicates().reset_index(drop=True)\n",
    "gold_df[\"preprint_flag\"] = gold_df[\"Item Type\"].apply(lambda x: \"preprint\" if x == \"preprint\" else \"non-preprint\")\n",
    "\n",
    "print(f\"Gold list size: {len(gold_df)}\")\n",
    "gold_df.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "041262ed",
   "metadata": {},
   "source": [
    "## Measure Recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5d426f7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_title(s: str) -> str:\n",
    "    # Unicode normalize\n",
    "    s = unicodedata.normalize(\"NFKC\", str(s))\n",
    "    # Lowercase\n",
    "    s = s.lower()\n",
    "    # Remove punctuation-like characters\n",
    "    s = re.sub(r\"[^\\w\\s]\", \" \", s)   # keep letters, numbers, underscore, whitespace\n",
    "    # Collapse whitespace\n",
    "    s = re.sub(r\"\\s+\", \" \", s).strip()\n",
    "    return s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7e7c6302",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build lookup from normalized -> original for the gold set\n",
    "gold_df[\"norm\"] = gold_df[\"Title\"].map(normalize_title)\n",
    "\n",
    "# If duplicates normalize to the same string, keep the first original as the representative\n",
    "gold_norm_to_orig = dict(zip(gold_df[\"norm\"], gold_df[\"Title\"]))\n",
    "gold_norm_to_preprint_flag = dict(zip(gold_df[\"norm\"], gold_df[\"preprint_flag\"]))\n",
    "gold_norm_set = set(gold_df[\"norm\"])\n",
    "\n",
    "# Separate sets for preprint and non-preprint\n",
    "gold_preprint_set = set(gold_df[gold_df[\"preprint_flag\"] == \"preprint\"][\"norm\"])\n",
    "gold_non_preprint_set = set(gold_df[gold_df[\"preprint_flag\"] == \"non-preprint\"][\"norm\"])\n",
    "\n",
    "results = []\n",
    "missing_rows = []  # for a detailed table of which gold titles are missing per file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "aa6cb74f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process each of the 10 Excel files\n",
    "for i in range(1, 11):\n",
    "    fname = f\"data/savedrecs ({i}).xls\"\n",
    "    # Read first sheet, only the needed column\n",
    "    try:\n",
    "        xdf = pd.read_excel(fname, engine=\"xlrd\")\n",
    "    except Exception as e:\n",
    "        results.append({\n",
    "            \"file\": fname,\n",
    "            \"error\": str(e),\n",
    "            \"matches_count\": 0,\n",
    "            \"recall\": 0.0,\n",
    "            \"recall_non_preprint\": 0.0,\n",
    "            \"recall_preprint\": 0.0,\n",
    "        })\n",
    "        continue\n",
    "\n",
    "    assert \"Article Title\" in xdf.columns, f\"Expected 'Article Title' in {fname}\"\n",
    "\n",
    "    titles = (\n",
    "        xdf[\"Article Title\"]\n",
    "        .dropna()\n",
    "        .drop_duplicates()\n",
    "        .astype(str)\n",
    "        .tolist()\n",
    "    )\n",
    "    norm_titles = {normalize_title(t) for t in titles}\n",
    "\n",
    "    matched_norm = gold_norm_set & norm_titles\n",
    "    missing_norm = gold_norm_set - norm_titles\n",
    "\n",
    "    # Calculate matches by type\n",
    "    matched_preprint = gold_preprint_set & norm_titles\n",
    "    matched_non_preprint = gold_non_preprint_set & norm_titles\n",
    "\n",
    "    matches_count = len(matched_norm)\n",
    "    recall = matches_count / len(gold_norm_set) if gold_norm_set else 0.0\n",
    "    recall_preprint = len(matched_preprint) / len(gold_preprint_set) if gold_preprint_set else 0.0\n",
    "    recall_non_preprint = len(matched_non_preprint) / len(gold_non_preprint_set) if gold_non_preprint_set else 0.0\n",
    "\n",
    "    # Save per file summary\n",
    "    results.append({\n",
    "        \"file\": fname,\n",
    "        \"matches_count\": matches_count,\n",
    "        \"total_gold\": len(gold_norm_set),\n",
    "        \"recall\": recall,\n",
    "        \"recall_non_preprint\": recall_non_preprint,\n",
    "        \"recall_preprint\": recall_preprint,\n",
    "        \"matched_titles\": [gold_norm_to_orig[n] for n in sorted(matched_norm)],\n",
    "        \"missing_titles\": [gold_norm_to_orig[n] for n in sorted(missing_norm)],\n",
    "    })\n",
    "\n",
    "    # Populate long-form \"missing\" table\n",
    "    for n in sorted(missing_norm):\n",
    "        missing_rows.append({\n",
    "            \"file\": fname,\n",
    "            \"missing_gold_title\": gold_norm_to_orig[n]\n",
    "        })\n",
    "\n",
    "df_WoS_recall = pd.DataFrame(results).sort_values([\"recall\", \"file\"], ascending=[False, True]).reset_index(drop=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b4b3b799",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "file",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "matches_count",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "total_gold",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "recall",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "recall_non_preprint",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "recall_preprint",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "matched_titles",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "missing_titles",
         "rawType": "object",
         "type": "unknown"
        }
       ],
       "ref": "63f69cfb-711e-4ef9-a4f4-1f74d9fdd7c6",
       "rows": [
        [
         "0",
         "data/savedrecs (2).xls",
         "5",
         "21",
         "0.23809523809523808",
         "0.45454545454545453",
         "0.0",
         "['AI–Human Hybrids for Marketing Research: Leveraging Large Language Models (LLMs) as Collaborators', 'Out of One, Many: Using Language Models to Simulate Human Samples', 'Predicting Missing Values in Survey Data Using Prompt Engineering for Addressing Item Non-Response', 'Synthetic Replacements for Human Survey Data? The Perils of Large Language Models', 'Vox Populi, Vox AI? Using Large Language Models to Estimate German Vote Choice']",
         "['Addressing Systematic Non-response Bias with Supervised Fine-Tuning of Large Language Models: A Case Study on German Voting Behaviour', 'AI-Augmented Surveys: Leveraging Large Language Models and Surveys for Opinion Prediction', 'Algorithmic Fidelity of Large Language Models in Generating Synthetic German Public Opinions: A Case Study', 'Are Large Language Models Chameleons? An Attempt to Simulate Social Surveys', 'Can Large Language Models Simulate Human Responses? A Case Study of Stated Preference Experiments in the Context of Heating-related Choices', 'Delving Into the Psychology of Machines: Exploring the Structure of Self-Regulated Learning via LLM-Generated Survey Responses', 'Donald Trumps in the Virtual Polls: Simulating and Predicting Public Opinions in Surveys Using Large Language Models', 'Examining the Feasibility of Large Language Models as Survey Respondents', 'Extracting Affect Aggregates from Longitudinal Social Media Data with Temporal Adapters for Large Language Models', 'Knowledge of cultural moral norms in large language models', 'LLM-Based Doppelgänger Models: Leveraging Synthetic Data for Human-Like Responses in Survey Simulations', 'More Parameters Than Populations: A Systematic Literature Review of Large Language Models within Survey Research', 'Questioning the Survey Responses of Large Language Models', 'Random Silicon Sampling: Simulating Human Sub-Population Opinion Using a Large Language Model Based on Group-Level Demographic Information', 'Synthetic Voices: Evaluating the Fidelity of LLM-Generated Personas in Representing People’s Financial Wellbeing', 'The Potential and Challenges of Evaluating Attitudes, Opinions, and Values in Large Language Models']"
        ],
        [
         "1",
         "data/savedrecs (5).xls",
         "5",
         "21",
         "0.23809523809523808",
         "0.45454545454545453",
         "0.0",
         "['AI–Human Hybrids for Marketing Research: Leveraging Large Language Models (LLMs) as Collaborators', 'Out of One, Many: Using Language Models to Simulate Human Samples', 'Predicting Missing Values in Survey Data Using Prompt Engineering for Addressing Item Non-Response', 'Synthetic Replacements for Human Survey Data? The Perils of Large Language Models', 'Vox Populi, Vox AI? Using Large Language Models to Estimate German Vote Choice']",
         "['Addressing Systematic Non-response Bias with Supervised Fine-Tuning of Large Language Models: A Case Study on German Voting Behaviour', 'AI-Augmented Surveys: Leveraging Large Language Models and Surveys for Opinion Prediction', 'Algorithmic Fidelity of Large Language Models in Generating Synthetic German Public Opinions: A Case Study', 'Are Large Language Models Chameleons? An Attempt to Simulate Social Surveys', 'Can Large Language Models Simulate Human Responses? A Case Study of Stated Preference Experiments in the Context of Heating-related Choices', 'Delving Into the Psychology of Machines: Exploring the Structure of Self-Regulated Learning via LLM-Generated Survey Responses', 'Donald Trumps in the Virtual Polls: Simulating and Predicting Public Opinions in Surveys Using Large Language Models', 'Examining the Feasibility of Large Language Models as Survey Respondents', 'Extracting Affect Aggregates from Longitudinal Social Media Data with Temporal Adapters for Large Language Models', 'Knowledge of cultural moral norms in large language models', 'LLM-Based Doppelgänger Models: Leveraging Synthetic Data for Human-Like Responses in Survey Simulations', 'More Parameters Than Populations: A Systematic Literature Review of Large Language Models within Survey Research', 'Questioning the Survey Responses of Large Language Models', 'Random Silicon Sampling: Simulating Human Sub-Population Opinion Using a Large Language Model Based on Group-Level Demographic Information', 'Synthetic Voices: Evaluating the Fidelity of LLM-Generated Personas in Representing People’s Financial Wellbeing', 'The Potential and Challenges of Evaluating Attitudes, Opinions, and Values in Large Language Models']"
        ],
        [
         "2",
         "data/savedrecs (1).xls",
         "4",
         "21",
         "0.19047619047619047",
         "0.36363636363636365",
         "0.0",
         "['AI–Human Hybrids for Marketing Research: Leveraging Large Language Models (LLMs) as Collaborators', 'Out of One, Many: Using Language Models to Simulate Human Samples', 'Predicting Missing Values in Survey Data Using Prompt Engineering for Addressing Item Non-Response', 'Vox Populi, Vox AI? Using Large Language Models to Estimate German Vote Choice']",
         "['Addressing Systematic Non-response Bias with Supervised Fine-Tuning of Large Language Models: A Case Study on German Voting Behaviour', 'AI-Augmented Surveys: Leveraging Large Language Models and Surveys for Opinion Prediction', 'Algorithmic Fidelity of Large Language Models in Generating Synthetic German Public Opinions: A Case Study', 'Are Large Language Models Chameleons? An Attempt to Simulate Social Surveys', 'Can Large Language Models Simulate Human Responses? A Case Study of Stated Preference Experiments in the Context of Heating-related Choices', 'Delving Into the Psychology of Machines: Exploring the Structure of Self-Regulated Learning via LLM-Generated Survey Responses', 'Donald Trumps in the Virtual Polls: Simulating and Predicting Public Opinions in Surveys Using Large Language Models', 'Examining the Feasibility of Large Language Models as Survey Respondents', 'Extracting Affect Aggregates from Longitudinal Social Media Data with Temporal Adapters for Large Language Models', 'Knowledge of cultural moral norms in large language models', 'LLM-Based Doppelgänger Models: Leveraging Synthetic Data for Human-Like Responses in Survey Simulations', 'More Parameters Than Populations: A Systematic Literature Review of Large Language Models within Survey Research', 'Questioning the Survey Responses of Large Language Models', 'Random Silicon Sampling: Simulating Human Sub-Population Opinion Using a Large Language Model Based on Group-Level Demographic Information', 'Synthetic Replacements for Human Survey Data? The Perils of Large Language Models', 'Synthetic Voices: Evaluating the Fidelity of LLM-Generated Personas in Representing People’s Financial Wellbeing', 'The Potential and Challenges of Evaluating Attitudes, Opinions, and Values in Large Language Models']"
        ],
        [
         "3",
         "data/savedrecs (10).xls",
         "4",
         "21",
         "0.19047619047619047",
         "0.36363636363636365",
         "0.0",
         "['AI–Human Hybrids for Marketing Research: Leveraging Large Language Models (LLMs) as Collaborators', 'Knowledge of cultural moral norms in large language models', 'Synthetic Replacements for Human Survey Data? The Perils of Large Language Models', 'Vox Populi, Vox AI? Using Large Language Models to Estimate German Vote Choice']",
         "['Addressing Systematic Non-response Bias with Supervised Fine-Tuning of Large Language Models: A Case Study on German Voting Behaviour', 'AI-Augmented Surveys: Leveraging Large Language Models and Surveys for Opinion Prediction', 'Algorithmic Fidelity of Large Language Models in Generating Synthetic German Public Opinions: A Case Study', 'Are Large Language Models Chameleons? An Attempt to Simulate Social Surveys', 'Can Large Language Models Simulate Human Responses? A Case Study of Stated Preference Experiments in the Context of Heating-related Choices', 'Delving Into the Psychology of Machines: Exploring the Structure of Self-Regulated Learning via LLM-Generated Survey Responses', 'Donald Trumps in the Virtual Polls: Simulating and Predicting Public Opinions in Surveys Using Large Language Models', 'Examining the Feasibility of Large Language Models as Survey Respondents', 'Extracting Affect Aggregates from Longitudinal Social Media Data with Temporal Adapters for Large Language Models', 'LLM-Based Doppelgänger Models: Leveraging Synthetic Data for Human-Like Responses in Survey Simulations', 'More Parameters Than Populations: A Systematic Literature Review of Large Language Models within Survey Research', 'Out of One, Many: Using Language Models to Simulate Human Samples', 'Predicting Missing Values in Survey Data Using Prompt Engineering for Addressing Item Non-Response', 'Questioning the Survey Responses of Large Language Models', 'Random Silicon Sampling: Simulating Human Sub-Population Opinion Using a Large Language Model Based on Group-Level Demographic Information', 'Synthetic Voices: Evaluating the Fidelity of LLM-Generated Personas in Representing People’s Financial Wellbeing', 'The Potential and Challenges of Evaluating Attitudes, Opinions, and Values in Large Language Models']"
        ],
        [
         "4",
         "data/savedrecs (4).xls",
         "4",
         "21",
         "0.19047619047619047",
         "0.36363636363636365",
         "0.0",
         "['AI–Human Hybrids for Marketing Research: Leveraging Large Language Models (LLMs) as Collaborators', 'Out of One, Many: Using Language Models to Simulate Human Samples', 'Predicting Missing Values in Survey Data Using Prompt Engineering for Addressing Item Non-Response', 'Vox Populi, Vox AI? Using Large Language Models to Estimate German Vote Choice']",
         "['Addressing Systematic Non-response Bias with Supervised Fine-Tuning of Large Language Models: A Case Study on German Voting Behaviour', 'AI-Augmented Surveys: Leveraging Large Language Models and Surveys for Opinion Prediction', 'Algorithmic Fidelity of Large Language Models in Generating Synthetic German Public Opinions: A Case Study', 'Are Large Language Models Chameleons? An Attempt to Simulate Social Surveys', 'Can Large Language Models Simulate Human Responses? A Case Study of Stated Preference Experiments in the Context of Heating-related Choices', 'Delving Into the Psychology of Machines: Exploring the Structure of Self-Regulated Learning via LLM-Generated Survey Responses', 'Donald Trumps in the Virtual Polls: Simulating and Predicting Public Opinions in Surveys Using Large Language Models', 'Examining the Feasibility of Large Language Models as Survey Respondents', 'Extracting Affect Aggregates from Longitudinal Social Media Data with Temporal Adapters for Large Language Models', 'Knowledge of cultural moral norms in large language models', 'LLM-Based Doppelgänger Models: Leveraging Synthetic Data for Human-Like Responses in Survey Simulations', 'More Parameters Than Populations: A Systematic Literature Review of Large Language Models within Survey Research', 'Questioning the Survey Responses of Large Language Models', 'Random Silicon Sampling: Simulating Human Sub-Population Opinion Using a Large Language Model Based on Group-Level Demographic Information', 'Synthetic Replacements for Human Survey Data? The Perils of Large Language Models', 'Synthetic Voices: Evaluating the Fidelity of LLM-Generated Personas in Representing People’s Financial Wellbeing', 'The Potential and Challenges of Evaluating Attitudes, Opinions, and Values in Large Language Models']"
        ],
        [
         "5",
         "data/savedrecs (8).xls",
         "4",
         "21",
         "0.19047619047619047",
         "0.36363636363636365",
         "0.0",
         "['AI–Human Hybrids for Marketing Research: Leveraging Large Language Models (LLMs) as Collaborators', 'Predicting Missing Values in Survey Data Using Prompt Engineering for Addressing Item Non-Response', 'Synthetic Replacements for Human Survey Data? The Perils of Large Language Models', 'Vox Populi, Vox AI? Using Large Language Models to Estimate German Vote Choice']",
         "['Addressing Systematic Non-response Bias with Supervised Fine-Tuning of Large Language Models: A Case Study on German Voting Behaviour', 'AI-Augmented Surveys: Leveraging Large Language Models and Surveys for Opinion Prediction', 'Algorithmic Fidelity of Large Language Models in Generating Synthetic German Public Opinions: A Case Study', 'Are Large Language Models Chameleons? An Attempt to Simulate Social Surveys', 'Can Large Language Models Simulate Human Responses? A Case Study of Stated Preference Experiments in the Context of Heating-related Choices', 'Delving Into the Psychology of Machines: Exploring the Structure of Self-Regulated Learning via LLM-Generated Survey Responses', 'Donald Trumps in the Virtual Polls: Simulating and Predicting Public Opinions in Surveys Using Large Language Models', 'Examining the Feasibility of Large Language Models as Survey Respondents', 'Extracting Affect Aggregates from Longitudinal Social Media Data with Temporal Adapters for Large Language Models', 'Knowledge of cultural moral norms in large language models', 'LLM-Based Doppelgänger Models: Leveraging Synthetic Data for Human-Like Responses in Survey Simulations', 'More Parameters Than Populations: A Systematic Literature Review of Large Language Models within Survey Research', 'Out of One, Many: Using Language Models to Simulate Human Samples', 'Questioning the Survey Responses of Large Language Models', 'Random Silicon Sampling: Simulating Human Sub-Population Opinion Using a Large Language Model Based on Group-Level Demographic Information', 'Synthetic Voices: Evaluating the Fidelity of LLM-Generated Personas in Representing People’s Financial Wellbeing', 'The Potential and Challenges of Evaluating Attitudes, Opinions, and Values in Large Language Models']"
        ],
        [
         "6",
         "data/savedrecs (7).xls",
         "3",
         "21",
         "0.14285714285714285",
         "0.2727272727272727",
         "0.0",
         "['AI–Human Hybrids for Marketing Research: Leveraging Large Language Models (LLMs) as Collaborators', 'Predicting Missing Values in Survey Data Using Prompt Engineering for Addressing Item Non-Response', 'Vox Populi, Vox AI? Using Large Language Models to Estimate German Vote Choice']",
         "['Addressing Systematic Non-response Bias with Supervised Fine-Tuning of Large Language Models: A Case Study on German Voting Behaviour', 'AI-Augmented Surveys: Leveraging Large Language Models and Surveys for Opinion Prediction', 'Algorithmic Fidelity of Large Language Models in Generating Synthetic German Public Opinions: A Case Study', 'Are Large Language Models Chameleons? An Attempt to Simulate Social Surveys', 'Can Large Language Models Simulate Human Responses? A Case Study of Stated Preference Experiments in the Context of Heating-related Choices', 'Delving Into the Psychology of Machines: Exploring the Structure of Self-Regulated Learning via LLM-Generated Survey Responses', 'Donald Trumps in the Virtual Polls: Simulating and Predicting Public Opinions in Surveys Using Large Language Models', 'Examining the Feasibility of Large Language Models as Survey Respondents', 'Extracting Affect Aggregates from Longitudinal Social Media Data with Temporal Adapters for Large Language Models', 'Knowledge of cultural moral norms in large language models', 'LLM-Based Doppelgänger Models: Leveraging Synthetic Data for Human-Like Responses in Survey Simulations', 'More Parameters Than Populations: A Systematic Literature Review of Large Language Models within Survey Research', 'Out of One, Many: Using Language Models to Simulate Human Samples', 'Questioning the Survey Responses of Large Language Models', 'Random Silicon Sampling: Simulating Human Sub-Population Opinion Using a Large Language Model Based on Group-Level Demographic Information', 'Synthetic Replacements for Human Survey Data? The Perils of Large Language Models', 'Synthetic Voices: Evaluating the Fidelity of LLM-Generated Personas in Representing People’s Financial Wellbeing', 'The Potential and Challenges of Evaluating Attitudes, Opinions, and Values in Large Language Models']"
        ],
        [
         "7",
         "data/savedrecs (9).xls",
         "3",
         "21",
         "0.14285714285714285",
         "0.2727272727272727",
         "0.0",
         "['AI–Human Hybrids for Marketing Research: Leveraging Large Language Models (LLMs) as Collaborators', 'Predicting Missing Values in Survey Data Using Prompt Engineering for Addressing Item Non-Response', 'Vox Populi, Vox AI? Using Large Language Models to Estimate German Vote Choice']",
         "['Addressing Systematic Non-response Bias with Supervised Fine-Tuning of Large Language Models: A Case Study on German Voting Behaviour', 'AI-Augmented Surveys: Leveraging Large Language Models and Surveys for Opinion Prediction', 'Algorithmic Fidelity of Large Language Models in Generating Synthetic German Public Opinions: A Case Study', 'Are Large Language Models Chameleons? An Attempt to Simulate Social Surveys', 'Can Large Language Models Simulate Human Responses? A Case Study of Stated Preference Experiments in the Context of Heating-related Choices', 'Delving Into the Psychology of Machines: Exploring the Structure of Self-Regulated Learning via LLM-Generated Survey Responses', 'Donald Trumps in the Virtual Polls: Simulating and Predicting Public Opinions in Surveys Using Large Language Models', 'Examining the Feasibility of Large Language Models as Survey Respondents', 'Extracting Affect Aggregates from Longitudinal Social Media Data with Temporal Adapters for Large Language Models', 'Knowledge of cultural moral norms in large language models', 'LLM-Based Doppelgänger Models: Leveraging Synthetic Data for Human-Like Responses in Survey Simulations', 'More Parameters Than Populations: A Systematic Literature Review of Large Language Models within Survey Research', 'Out of One, Many: Using Language Models to Simulate Human Samples', 'Questioning the Survey Responses of Large Language Models', 'Random Silicon Sampling: Simulating Human Sub-Population Opinion Using a Large Language Model Based on Group-Level Demographic Information', 'Synthetic Replacements for Human Survey Data? The Perils of Large Language Models', 'Synthetic Voices: Evaluating the Fidelity of LLM-Generated Personas in Representing People’s Financial Wellbeing', 'The Potential and Challenges of Evaluating Attitudes, Opinions, and Values in Large Language Models']"
        ],
        [
         "8",
         "data/savedrecs (3).xls",
         "2",
         "21",
         "0.09523809523809523",
         "0.18181818181818182",
         "0.0",
         "['AI–Human Hybrids for Marketing Research: Leveraging Large Language Models (LLMs) as Collaborators', 'Synthetic Replacements for Human Survey Data? The Perils of Large Language Models']",
         "['Addressing Systematic Non-response Bias with Supervised Fine-Tuning of Large Language Models: A Case Study on German Voting Behaviour', 'AI-Augmented Surveys: Leveraging Large Language Models and Surveys for Opinion Prediction', 'Algorithmic Fidelity of Large Language Models in Generating Synthetic German Public Opinions: A Case Study', 'Are Large Language Models Chameleons? An Attempt to Simulate Social Surveys', 'Can Large Language Models Simulate Human Responses? A Case Study of Stated Preference Experiments in the Context of Heating-related Choices', 'Delving Into the Psychology of Machines: Exploring the Structure of Self-Regulated Learning via LLM-Generated Survey Responses', 'Donald Trumps in the Virtual Polls: Simulating and Predicting Public Opinions in Surveys Using Large Language Models', 'Examining the Feasibility of Large Language Models as Survey Respondents', 'Extracting Affect Aggregates from Longitudinal Social Media Data with Temporal Adapters for Large Language Models', 'Knowledge of cultural moral norms in large language models', 'LLM-Based Doppelgänger Models: Leveraging Synthetic Data for Human-Like Responses in Survey Simulations', 'More Parameters Than Populations: A Systematic Literature Review of Large Language Models within Survey Research', 'Out of One, Many: Using Language Models to Simulate Human Samples', 'Predicting Missing Values in Survey Data Using Prompt Engineering for Addressing Item Non-Response', 'Questioning the Survey Responses of Large Language Models', 'Random Silicon Sampling: Simulating Human Sub-Population Opinion Using a Large Language Model Based on Group-Level Demographic Information', 'Synthetic Voices: Evaluating the Fidelity of LLM-Generated Personas in Representing People’s Financial Wellbeing', 'The Potential and Challenges of Evaluating Attitudes, Opinions, and Values in Large Language Models', 'Vox Populi, Vox AI? Using Large Language Models to Estimate German Vote Choice']"
        ],
        [
         "9",
         "data/savedrecs (6).xls",
         "1",
         "21",
         "0.047619047619047616",
         "0.09090909090909091",
         "0.0",
         "['Synthetic Replacements for Human Survey Data? The Perils of Large Language Models']",
         "['Addressing Systematic Non-response Bias with Supervised Fine-Tuning of Large Language Models: A Case Study on German Voting Behaviour', 'AI-Augmented Surveys: Leveraging Large Language Models and Surveys for Opinion Prediction', 'AI–Human Hybrids for Marketing Research: Leveraging Large Language Models (LLMs) as Collaborators', 'Algorithmic Fidelity of Large Language Models in Generating Synthetic German Public Opinions: A Case Study', 'Are Large Language Models Chameleons? An Attempt to Simulate Social Surveys', 'Can Large Language Models Simulate Human Responses? A Case Study of Stated Preference Experiments in the Context of Heating-related Choices', 'Delving Into the Psychology of Machines: Exploring the Structure of Self-Regulated Learning via LLM-Generated Survey Responses', 'Donald Trumps in the Virtual Polls: Simulating and Predicting Public Opinions in Surveys Using Large Language Models', 'Examining the Feasibility of Large Language Models as Survey Respondents', 'Extracting Affect Aggregates from Longitudinal Social Media Data with Temporal Adapters for Large Language Models', 'Knowledge of cultural moral norms in large language models', 'LLM-Based Doppelgänger Models: Leveraging Synthetic Data for Human-Like Responses in Survey Simulations', 'More Parameters Than Populations: A Systematic Literature Review of Large Language Models within Survey Research', 'Out of One, Many: Using Language Models to Simulate Human Samples', 'Predicting Missing Values in Survey Data Using Prompt Engineering for Addressing Item Non-Response', 'Questioning the Survey Responses of Large Language Models', 'Random Silicon Sampling: Simulating Human Sub-Population Opinion Using a Large Language Model Based on Group-Level Demographic Information', 'Synthetic Voices: Evaluating the Fidelity of LLM-Generated Personas in Representing People’s Financial Wellbeing', 'The Potential and Challenges of Evaluating Attitudes, Opinions, and Values in Large Language Models', 'Vox Populi, Vox AI? Using Large Language Models to Estimate German Vote Choice']"
        ]
       ],
       "shape": {
        "columns": 8,
        "rows": 10
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file</th>\n",
       "      <th>matches_count</th>\n",
       "      <th>total_gold</th>\n",
       "      <th>recall</th>\n",
       "      <th>recall_non_preprint</th>\n",
       "      <th>recall_preprint</th>\n",
       "      <th>matched_titles</th>\n",
       "      <th>missing_titles</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>data/savedrecs (2).xls</td>\n",
       "      <td>5</td>\n",
       "      <td>21</td>\n",
       "      <td>0.238095</td>\n",
       "      <td>0.454545</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[AI–Human Hybrids for Marketing Research: Leve...</td>\n",
       "      <td>[Addressing Systematic Non-response Bias with ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>data/savedrecs (5).xls</td>\n",
       "      <td>5</td>\n",
       "      <td>21</td>\n",
       "      <td>0.238095</td>\n",
       "      <td>0.454545</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[AI–Human Hybrids for Marketing Research: Leve...</td>\n",
       "      <td>[Addressing Systematic Non-response Bias with ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>data/savedrecs (1).xls</td>\n",
       "      <td>4</td>\n",
       "      <td>21</td>\n",
       "      <td>0.190476</td>\n",
       "      <td>0.363636</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[AI–Human Hybrids for Marketing Research: Leve...</td>\n",
       "      <td>[Addressing Systematic Non-response Bias with ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>data/savedrecs (10).xls</td>\n",
       "      <td>4</td>\n",
       "      <td>21</td>\n",
       "      <td>0.190476</td>\n",
       "      <td>0.363636</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[AI–Human Hybrids for Marketing Research: Leve...</td>\n",
       "      <td>[Addressing Systematic Non-response Bias with ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>data/savedrecs (4).xls</td>\n",
       "      <td>4</td>\n",
       "      <td>21</td>\n",
       "      <td>0.190476</td>\n",
       "      <td>0.363636</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[AI–Human Hybrids for Marketing Research: Leve...</td>\n",
       "      <td>[Addressing Systematic Non-response Bias with ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>data/savedrecs (8).xls</td>\n",
       "      <td>4</td>\n",
       "      <td>21</td>\n",
       "      <td>0.190476</td>\n",
       "      <td>0.363636</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[AI–Human Hybrids for Marketing Research: Leve...</td>\n",
       "      <td>[Addressing Systematic Non-response Bias with ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>data/savedrecs (7).xls</td>\n",
       "      <td>3</td>\n",
       "      <td>21</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.272727</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[AI–Human Hybrids for Marketing Research: Leve...</td>\n",
       "      <td>[Addressing Systematic Non-response Bias with ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>data/savedrecs (9).xls</td>\n",
       "      <td>3</td>\n",
       "      <td>21</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.272727</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[AI–Human Hybrids for Marketing Research: Leve...</td>\n",
       "      <td>[Addressing Systematic Non-response Bias with ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>data/savedrecs (3).xls</td>\n",
       "      <td>2</td>\n",
       "      <td>21</td>\n",
       "      <td>0.095238</td>\n",
       "      <td>0.181818</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[AI–Human Hybrids for Marketing Research: Leve...</td>\n",
       "      <td>[Addressing Systematic Non-response Bias with ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>data/savedrecs (6).xls</td>\n",
       "      <td>1</td>\n",
       "      <td>21</td>\n",
       "      <td>0.047619</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[Synthetic Replacements for Human Survey Data?...</td>\n",
       "      <td>[Addressing Systematic Non-response Bias with ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      file  matches_count  total_gold    recall  \\\n",
       "0   data/savedrecs (2).xls              5          21  0.238095   \n",
       "1   data/savedrecs (5).xls              5          21  0.238095   \n",
       "2   data/savedrecs (1).xls              4          21  0.190476   \n",
       "3  data/savedrecs (10).xls              4          21  0.190476   \n",
       "4   data/savedrecs (4).xls              4          21  0.190476   \n",
       "5   data/savedrecs (8).xls              4          21  0.190476   \n",
       "6   data/savedrecs (7).xls              3          21  0.142857   \n",
       "7   data/savedrecs (9).xls              3          21  0.142857   \n",
       "8   data/savedrecs (3).xls              2          21  0.095238   \n",
       "9   data/savedrecs (6).xls              1          21  0.047619   \n",
       "\n",
       "   recall_non_preprint  recall_preprint  \\\n",
       "0             0.454545              0.0   \n",
       "1             0.454545              0.0   \n",
       "2             0.363636              0.0   \n",
       "3             0.363636              0.0   \n",
       "4             0.363636              0.0   \n",
       "5             0.363636              0.0   \n",
       "6             0.272727              0.0   \n",
       "7             0.272727              0.0   \n",
       "8             0.181818              0.0   \n",
       "9             0.090909              0.0   \n",
       "\n",
       "                                      matched_titles  \\\n",
       "0  [AI–Human Hybrids for Marketing Research: Leve...   \n",
       "1  [AI–Human Hybrids for Marketing Research: Leve...   \n",
       "2  [AI–Human Hybrids for Marketing Research: Leve...   \n",
       "3  [AI–Human Hybrids for Marketing Research: Leve...   \n",
       "4  [AI–Human Hybrids for Marketing Research: Leve...   \n",
       "5  [AI–Human Hybrids for Marketing Research: Leve...   \n",
       "6  [AI–Human Hybrids for Marketing Research: Leve...   \n",
       "7  [AI–Human Hybrids for Marketing Research: Leve...   \n",
       "8  [AI–Human Hybrids for Marketing Research: Leve...   \n",
       "9  [Synthetic Replacements for Human Survey Data?...   \n",
       "\n",
       "                                      missing_titles  \n",
       "0  [Addressing Systematic Non-response Bias with ...  \n",
       "1  [Addressing Systematic Non-response Bias with ...  \n",
       "2  [Addressing Systematic Non-response Bias with ...  \n",
       "3  [Addressing Systematic Non-response Bias with ...  \n",
       "4  [Addressing Systematic Non-response Bias with ...  \n",
       "5  [Addressing Systematic Non-response Bias with ...  \n",
       "6  [Addressing Systematic Non-response Bias with ...  \n",
       "7  [Addressing Systematic Non-response Bias with ...  \n",
       "8  [Addressing Systematic Non-response Bias with ...  \n",
       "9  [Addressing Systematic Non-response Bias with ...  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_WoS_recall"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "988b2f26",
   "metadata": {},
   "source": [
    "## Measure Recall of '/NEAR'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bd998f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_title(s: str) -> str:\n",
    "    # Unicode normalize\n",
    "    s = unicodedata.normalize(\"NFKC\", str(s))\n",
    "    # Lowercase\n",
    "    s = s.lower()\n",
    "    # Remove punctuation-like characters\n",
    "    s = re.sub(r\"[^\\w\\s]\", \" \", s)   # keep letters, numbers, underscore, whitespace\n",
    "    # Collapse whitespace\n",
    "    s = re.sub(r\"\\s+\", \" \", s).strip()\n",
    "    return s\n",
    "\n",
    "# Build lookup from normalized -> original for the gold set\n",
    "gold_df[\"norm\"] = gold_df[\"Title\"].map(normalize_title)\n",
    "# If duplicates normalize to the same string, keep the first original as the representative\n",
    "gold_norm_to_orig = dict(zip(gold_df[\"norm\"], gold_df[\"Title\"]))\n",
    "gold_norm_set = set(gold_df[\"norm\"])\n",
    "\n",
    "results = []\n",
    "missing_rows = []  # for a detailed table of which gold titles are missing per file\n",
    "\n",
    "for i in range(1, 11):\n",
    "    fname = f\"data/NEARx_tuning/savedrecs{i}.xls\"\n",
    "    # Read first sheet, only the needed column\n",
    "    try:\n",
    "        xdf = pd.read_excel(fname, engine=\"xlrd\")\n",
    "    except Exception as e:\n",
    "        results.append({\n",
    "            \"file\": fname,\n",
    "            \"error\": str(e),\n",
    "            \"matches_count\": 0,\n",
    "            \"recall\": 0.0,\n",
    "        })\n",
    "        continue\n",
    "\n",
    "    assert \"Article Title\" in xdf.columns, f\"Expected 'Article Title' in {fname}\"\n",
    "\n",
    "    titles = (\n",
    "        xdf[\"Article Title\"]\n",
    "        .dropna()\n",
    "        .drop_duplicates()\n",
    "        .astype(str)\n",
    "        .tolist()\n",
    "    )\n",
    "    norm_titles = {normalize_title(t) for t in titles}\n",
    "\n",
    "    matched_norm = gold_norm_set & norm_titles\n",
    "    missing_norm = gold_norm_set - norm_titles\n",
    "\n",
    "    matches_count = len(matched_norm)\n",
    "    recall = matches_count / len(gold_norm_set) if gold_norm_set else 0.0\n",
    "\n",
    "    # Save per file summary\n",
    "    results.append({\n",
    "        \"file\": fname,\n",
    "        \"matches_count\": matches_count,\n",
    "        \"total_gold\": len(gold_norm_set),\n",
    "        \"recall\": recall,\n",
    "        \"matched_titles\": [gold_norm_to_orig[n] for n in sorted(matched_norm)],\n",
    "        \"missing_titles\": [gold_norm_to_orig[n] for n in sorted(missing_norm)],\n",
    "    })\n",
    "\n",
    "    # Populate long-form “missing” table\n",
    "    for n in sorted(missing_norm):\n",
    "        missing_rows.append({\n",
    "            \"file\": fname,\n",
    "            \"missing_gold_title\": gold_norm_to_orig[n]\n",
    "        })\n",
    "\n",
    "summary_df = pd.DataFrame(results).sort_values([\"recall\", \"file\"], ascending=[False, True]).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0b3aa4c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "file",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "matches_count",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "total_gold",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "recall",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "matched_titles",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "missing_titles",
         "rawType": "object",
         "type": "unknown"
        }
       ],
       "ref": "dd978c12-90f6-474b-8be6-1320b3afcacf",
       "rows": [
        [
         "0",
         "savedrecs1.xls",
         "2",
         "13",
         "0.15384615384615385",
         "['AI–Human Hybrids for Marketing Research: Leveraging Large Language Models (LLMs) as Collaborators', 'Synthetic Replacements for Human Survey Data? The Perils of Large Language Models']",
         "['Addressing Systematic Non-response Bias with Supervised Fine-Tuning of Large Language Models: A Case Study on German Voting Behaviour', 'AI-Augmented Surveys: Leveraging Large Language Models and Surveys for Opinion Prediction', 'Are Large Language Models Chameleons? An Attempt to Simulate Social Surveys', 'Delving Into the Psychology of Machines: Exploring the Structure of Self-Regulated Learning via LLM-Generated Survey Responses', 'Donald Trumps in the Virtual Polls: Simulating and Predicting Public Opinions in Surveys Using Large Language Models', 'Examining the Feasibility of Large Language Models as Survey Respondents', 'LLM-Based Doppelgänger Models: Leveraging Synthetic Data for Human-Like Responses in Survey Simulations', 'Predicting Missing Values in Survey Data Using Prompt Engineering for Addressing Item Non-Response', 'Questioning the Survey Responses of Large Language Models', 'Simulating and Analysing Human Survey Responses with Large Language Models: A Case Study in Energy Stated Preference', 'Synthetic Voices: Evaluating the Fidelity of LLM-Generated Personas in Representing People’s Financial Wellbeing']"
        ],
        [
         "1",
         "savedrecs10.xls",
         "2",
         "13",
         "0.15384615384615385",
         "['AI–Human Hybrids for Marketing Research: Leveraging Large Language Models (LLMs) as Collaborators', 'Synthetic Replacements for Human Survey Data? The Perils of Large Language Models']",
         "['Addressing Systematic Non-response Bias with Supervised Fine-Tuning of Large Language Models: A Case Study on German Voting Behaviour', 'AI-Augmented Surveys: Leveraging Large Language Models and Surveys for Opinion Prediction', 'Are Large Language Models Chameleons? An Attempt to Simulate Social Surveys', 'Delving Into the Psychology of Machines: Exploring the Structure of Self-Regulated Learning via LLM-Generated Survey Responses', 'Donald Trumps in the Virtual Polls: Simulating and Predicting Public Opinions in Surveys Using Large Language Models', 'Examining the Feasibility of Large Language Models as Survey Respondents', 'LLM-Based Doppelgänger Models: Leveraging Synthetic Data for Human-Like Responses in Survey Simulations', 'Predicting Missing Values in Survey Data Using Prompt Engineering for Addressing Item Non-Response', 'Questioning the Survey Responses of Large Language Models', 'Simulating and Analysing Human Survey Responses with Large Language Models: A Case Study in Energy Stated Preference', 'Synthetic Voices: Evaluating the Fidelity of LLM-Generated Personas in Representing People’s Financial Wellbeing']"
        ],
        [
         "2",
         "savedrecs2.xls",
         "2",
         "13",
         "0.15384615384615385",
         "['AI–Human Hybrids for Marketing Research: Leveraging Large Language Models (LLMs) as Collaborators', 'Synthetic Replacements for Human Survey Data? The Perils of Large Language Models']",
         "['Addressing Systematic Non-response Bias with Supervised Fine-Tuning of Large Language Models: A Case Study on German Voting Behaviour', 'AI-Augmented Surveys: Leveraging Large Language Models and Surveys for Opinion Prediction', 'Are Large Language Models Chameleons? An Attempt to Simulate Social Surveys', 'Delving Into the Psychology of Machines: Exploring the Structure of Self-Regulated Learning via LLM-Generated Survey Responses', 'Donald Trumps in the Virtual Polls: Simulating and Predicting Public Opinions in Surveys Using Large Language Models', 'Examining the Feasibility of Large Language Models as Survey Respondents', 'LLM-Based Doppelgänger Models: Leveraging Synthetic Data for Human-Like Responses in Survey Simulations', 'Predicting Missing Values in Survey Data Using Prompt Engineering for Addressing Item Non-Response', 'Questioning the Survey Responses of Large Language Models', 'Simulating and Analysing Human Survey Responses with Large Language Models: A Case Study in Energy Stated Preference', 'Synthetic Voices: Evaluating the Fidelity of LLM-Generated Personas in Representing People’s Financial Wellbeing']"
        ],
        [
         "3",
         "savedrecs3.xls",
         "2",
         "13",
         "0.15384615384615385",
         "['AI–Human Hybrids for Marketing Research: Leveraging Large Language Models (LLMs) as Collaborators', 'Synthetic Replacements for Human Survey Data? The Perils of Large Language Models']",
         "['Addressing Systematic Non-response Bias with Supervised Fine-Tuning of Large Language Models: A Case Study on German Voting Behaviour', 'AI-Augmented Surveys: Leveraging Large Language Models and Surveys for Opinion Prediction', 'Are Large Language Models Chameleons? An Attempt to Simulate Social Surveys', 'Delving Into the Psychology of Machines: Exploring the Structure of Self-Regulated Learning via LLM-Generated Survey Responses', 'Donald Trumps in the Virtual Polls: Simulating and Predicting Public Opinions in Surveys Using Large Language Models', 'Examining the Feasibility of Large Language Models as Survey Respondents', 'LLM-Based Doppelgänger Models: Leveraging Synthetic Data for Human-Like Responses in Survey Simulations', 'Predicting Missing Values in Survey Data Using Prompt Engineering for Addressing Item Non-Response', 'Questioning the Survey Responses of Large Language Models', 'Simulating and Analysing Human Survey Responses with Large Language Models: A Case Study in Energy Stated Preference', 'Synthetic Voices: Evaluating the Fidelity of LLM-Generated Personas in Representing People’s Financial Wellbeing']"
        ],
        [
         "4",
         "savedrecs4.xls",
         "2",
         "13",
         "0.15384615384615385",
         "['AI–Human Hybrids for Marketing Research: Leveraging Large Language Models (LLMs) as Collaborators', 'Synthetic Replacements for Human Survey Data? The Perils of Large Language Models']",
         "['Addressing Systematic Non-response Bias with Supervised Fine-Tuning of Large Language Models: A Case Study on German Voting Behaviour', 'AI-Augmented Surveys: Leveraging Large Language Models and Surveys for Opinion Prediction', 'Are Large Language Models Chameleons? An Attempt to Simulate Social Surveys', 'Delving Into the Psychology of Machines: Exploring the Structure of Self-Regulated Learning via LLM-Generated Survey Responses', 'Donald Trumps in the Virtual Polls: Simulating and Predicting Public Opinions in Surveys Using Large Language Models', 'Examining the Feasibility of Large Language Models as Survey Respondents', 'LLM-Based Doppelgänger Models: Leveraging Synthetic Data for Human-Like Responses in Survey Simulations', 'Predicting Missing Values in Survey Data Using Prompt Engineering for Addressing Item Non-Response', 'Questioning the Survey Responses of Large Language Models', 'Simulating and Analysing Human Survey Responses with Large Language Models: A Case Study in Energy Stated Preference', 'Synthetic Voices: Evaluating the Fidelity of LLM-Generated Personas in Representing People’s Financial Wellbeing']"
        ],
        [
         "5",
         "savedrecs5.xls",
         "2",
         "13",
         "0.15384615384615385",
         "['AI–Human Hybrids for Marketing Research: Leveraging Large Language Models (LLMs) as Collaborators', 'Synthetic Replacements for Human Survey Data? The Perils of Large Language Models']",
         "['Addressing Systematic Non-response Bias with Supervised Fine-Tuning of Large Language Models: A Case Study on German Voting Behaviour', 'AI-Augmented Surveys: Leveraging Large Language Models and Surveys for Opinion Prediction', 'Are Large Language Models Chameleons? An Attempt to Simulate Social Surveys', 'Delving Into the Psychology of Machines: Exploring the Structure of Self-Regulated Learning via LLM-Generated Survey Responses', 'Donald Trumps in the Virtual Polls: Simulating and Predicting Public Opinions in Surveys Using Large Language Models', 'Examining the Feasibility of Large Language Models as Survey Respondents', 'LLM-Based Doppelgänger Models: Leveraging Synthetic Data for Human-Like Responses in Survey Simulations', 'Predicting Missing Values in Survey Data Using Prompt Engineering for Addressing Item Non-Response', 'Questioning the Survey Responses of Large Language Models', 'Simulating and Analysing Human Survey Responses with Large Language Models: A Case Study in Energy Stated Preference', 'Synthetic Voices: Evaluating the Fidelity of LLM-Generated Personas in Representing People’s Financial Wellbeing']"
        ],
        [
         "6",
         "savedrecs6.xls",
         "2",
         "13",
         "0.15384615384615385",
         "['AI–Human Hybrids for Marketing Research: Leveraging Large Language Models (LLMs) as Collaborators', 'Synthetic Replacements for Human Survey Data? The Perils of Large Language Models']",
         "['Addressing Systematic Non-response Bias with Supervised Fine-Tuning of Large Language Models: A Case Study on German Voting Behaviour', 'AI-Augmented Surveys: Leveraging Large Language Models and Surveys for Opinion Prediction', 'Are Large Language Models Chameleons? An Attempt to Simulate Social Surveys', 'Delving Into the Psychology of Machines: Exploring the Structure of Self-Regulated Learning via LLM-Generated Survey Responses', 'Donald Trumps in the Virtual Polls: Simulating and Predicting Public Opinions in Surveys Using Large Language Models', 'Examining the Feasibility of Large Language Models as Survey Respondents', 'LLM-Based Doppelgänger Models: Leveraging Synthetic Data for Human-Like Responses in Survey Simulations', 'Predicting Missing Values in Survey Data Using Prompt Engineering for Addressing Item Non-Response', 'Questioning the Survey Responses of Large Language Models', 'Simulating and Analysing Human Survey Responses with Large Language Models: A Case Study in Energy Stated Preference', 'Synthetic Voices: Evaluating the Fidelity of LLM-Generated Personas in Representing People’s Financial Wellbeing']"
        ],
        [
         "7",
         "savedrecs7.xls",
         "2",
         "13",
         "0.15384615384615385",
         "['AI–Human Hybrids for Marketing Research: Leveraging Large Language Models (LLMs) as Collaborators', 'Synthetic Replacements for Human Survey Data? The Perils of Large Language Models']",
         "['Addressing Systematic Non-response Bias with Supervised Fine-Tuning of Large Language Models: A Case Study on German Voting Behaviour', 'AI-Augmented Surveys: Leveraging Large Language Models and Surveys for Opinion Prediction', 'Are Large Language Models Chameleons? An Attempt to Simulate Social Surveys', 'Delving Into the Psychology of Machines: Exploring the Structure of Self-Regulated Learning via LLM-Generated Survey Responses', 'Donald Trumps in the Virtual Polls: Simulating and Predicting Public Opinions in Surveys Using Large Language Models', 'Examining the Feasibility of Large Language Models as Survey Respondents', 'LLM-Based Doppelgänger Models: Leveraging Synthetic Data for Human-Like Responses in Survey Simulations', 'Predicting Missing Values in Survey Data Using Prompt Engineering for Addressing Item Non-Response', 'Questioning the Survey Responses of Large Language Models', 'Simulating and Analysing Human Survey Responses with Large Language Models: A Case Study in Energy Stated Preference', 'Synthetic Voices: Evaluating the Fidelity of LLM-Generated Personas in Representing People’s Financial Wellbeing']"
        ],
        [
         "8",
         "savedrecs8.xls",
         "2",
         "13",
         "0.15384615384615385",
         "['AI–Human Hybrids for Marketing Research: Leveraging Large Language Models (LLMs) as Collaborators', 'Synthetic Replacements for Human Survey Data? The Perils of Large Language Models']",
         "['Addressing Systematic Non-response Bias with Supervised Fine-Tuning of Large Language Models: A Case Study on German Voting Behaviour', 'AI-Augmented Surveys: Leveraging Large Language Models and Surveys for Opinion Prediction', 'Are Large Language Models Chameleons? An Attempt to Simulate Social Surveys', 'Delving Into the Psychology of Machines: Exploring the Structure of Self-Regulated Learning via LLM-Generated Survey Responses', 'Donald Trumps in the Virtual Polls: Simulating and Predicting Public Opinions in Surveys Using Large Language Models', 'Examining the Feasibility of Large Language Models as Survey Respondents', 'LLM-Based Doppelgänger Models: Leveraging Synthetic Data for Human-Like Responses in Survey Simulations', 'Predicting Missing Values in Survey Data Using Prompt Engineering for Addressing Item Non-Response', 'Questioning the Survey Responses of Large Language Models', 'Simulating and Analysing Human Survey Responses with Large Language Models: A Case Study in Energy Stated Preference', 'Synthetic Voices: Evaluating the Fidelity of LLM-Generated Personas in Representing People’s Financial Wellbeing']"
        ],
        [
         "9",
         "savedrecs9.xls",
         "2",
         "13",
         "0.15384615384615385",
         "['AI–Human Hybrids for Marketing Research: Leveraging Large Language Models (LLMs) as Collaborators', 'Synthetic Replacements for Human Survey Data? The Perils of Large Language Models']",
         "['Addressing Systematic Non-response Bias with Supervised Fine-Tuning of Large Language Models: A Case Study on German Voting Behaviour', 'AI-Augmented Surveys: Leveraging Large Language Models and Surveys for Opinion Prediction', 'Are Large Language Models Chameleons? An Attempt to Simulate Social Surveys', 'Delving Into the Psychology of Machines: Exploring the Structure of Self-Regulated Learning via LLM-Generated Survey Responses', 'Donald Trumps in the Virtual Polls: Simulating and Predicting Public Opinions in Surveys Using Large Language Models', 'Examining the Feasibility of Large Language Models as Survey Respondents', 'LLM-Based Doppelgänger Models: Leveraging Synthetic Data for Human-Like Responses in Survey Simulations', 'Predicting Missing Values in Survey Data Using Prompt Engineering for Addressing Item Non-Response', 'Questioning the Survey Responses of Large Language Models', 'Simulating and Analysing Human Survey Responses with Large Language Models: A Case Study in Energy Stated Preference', 'Synthetic Voices: Evaluating the Fidelity of LLM-Generated Personas in Representing People’s Financial Wellbeing']"
        ]
       ],
       "shape": {
        "columns": 6,
        "rows": 10
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file</th>\n",
       "      <th>matches_count</th>\n",
       "      <th>total_gold</th>\n",
       "      <th>recall</th>\n",
       "      <th>matched_titles</th>\n",
       "      <th>missing_titles</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>savedrecs1.xls</td>\n",
       "      <td>2</td>\n",
       "      <td>13</td>\n",
       "      <td>0.153846</td>\n",
       "      <td>[AI–Human Hybrids for Marketing Research: Leve...</td>\n",
       "      <td>[Addressing Systematic Non-response Bias with ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>savedrecs10.xls</td>\n",
       "      <td>2</td>\n",
       "      <td>13</td>\n",
       "      <td>0.153846</td>\n",
       "      <td>[AI–Human Hybrids for Marketing Research: Leve...</td>\n",
       "      <td>[Addressing Systematic Non-response Bias with ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>savedrecs2.xls</td>\n",
       "      <td>2</td>\n",
       "      <td>13</td>\n",
       "      <td>0.153846</td>\n",
       "      <td>[AI–Human Hybrids for Marketing Research: Leve...</td>\n",
       "      <td>[Addressing Systematic Non-response Bias with ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>savedrecs3.xls</td>\n",
       "      <td>2</td>\n",
       "      <td>13</td>\n",
       "      <td>0.153846</td>\n",
       "      <td>[AI–Human Hybrids for Marketing Research: Leve...</td>\n",
       "      <td>[Addressing Systematic Non-response Bias with ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>savedrecs4.xls</td>\n",
       "      <td>2</td>\n",
       "      <td>13</td>\n",
       "      <td>0.153846</td>\n",
       "      <td>[AI–Human Hybrids for Marketing Research: Leve...</td>\n",
       "      <td>[Addressing Systematic Non-response Bias with ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>savedrecs5.xls</td>\n",
       "      <td>2</td>\n",
       "      <td>13</td>\n",
       "      <td>0.153846</td>\n",
       "      <td>[AI–Human Hybrids for Marketing Research: Leve...</td>\n",
       "      <td>[Addressing Systematic Non-response Bias with ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>savedrecs6.xls</td>\n",
       "      <td>2</td>\n",
       "      <td>13</td>\n",
       "      <td>0.153846</td>\n",
       "      <td>[AI–Human Hybrids for Marketing Research: Leve...</td>\n",
       "      <td>[Addressing Systematic Non-response Bias with ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>savedrecs7.xls</td>\n",
       "      <td>2</td>\n",
       "      <td>13</td>\n",
       "      <td>0.153846</td>\n",
       "      <td>[AI–Human Hybrids for Marketing Research: Leve...</td>\n",
       "      <td>[Addressing Systematic Non-response Bias with ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>savedrecs8.xls</td>\n",
       "      <td>2</td>\n",
       "      <td>13</td>\n",
       "      <td>0.153846</td>\n",
       "      <td>[AI–Human Hybrids for Marketing Research: Leve...</td>\n",
       "      <td>[Addressing Systematic Non-response Bias with ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>savedrecs9.xls</td>\n",
       "      <td>2</td>\n",
       "      <td>13</td>\n",
       "      <td>0.153846</td>\n",
       "      <td>[AI–Human Hybrids for Marketing Research: Leve...</td>\n",
       "      <td>[Addressing Systematic Non-response Bias with ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              file  matches_count  total_gold    recall  \\\n",
       "0   savedrecs1.xls              2          13  0.153846   \n",
       "1  savedrecs10.xls              2          13  0.153846   \n",
       "2   savedrecs2.xls              2          13  0.153846   \n",
       "3   savedrecs3.xls              2          13  0.153846   \n",
       "4   savedrecs4.xls              2          13  0.153846   \n",
       "5   savedrecs5.xls              2          13  0.153846   \n",
       "6   savedrecs6.xls              2          13  0.153846   \n",
       "7   savedrecs7.xls              2          13  0.153846   \n",
       "8   savedrecs8.xls              2          13  0.153846   \n",
       "9   savedrecs9.xls              2          13  0.153846   \n",
       "\n",
       "                                      matched_titles  \\\n",
       "0  [AI–Human Hybrids for Marketing Research: Leve...   \n",
       "1  [AI–Human Hybrids for Marketing Research: Leve...   \n",
       "2  [AI–Human Hybrids for Marketing Research: Leve...   \n",
       "3  [AI–Human Hybrids for Marketing Research: Leve...   \n",
       "4  [AI–Human Hybrids for Marketing Research: Leve...   \n",
       "5  [AI–Human Hybrids for Marketing Research: Leve...   \n",
       "6  [AI–Human Hybrids for Marketing Research: Leve...   \n",
       "7  [AI–Human Hybrids for Marketing Research: Leve...   \n",
       "8  [AI–Human Hybrids for Marketing Research: Leve...   \n",
       "9  [AI–Human Hybrids for Marketing Research: Leve...   \n",
       "\n",
       "                                      missing_titles  \n",
       "0  [Addressing Systematic Non-response Bias with ...  \n",
       "1  [Addressing Systematic Non-response Bias with ...  \n",
       "2  [Addressing Systematic Non-response Bias with ...  \n",
       "3  [Addressing Systematic Non-response Bias with ...  \n",
       "4  [Addressing Systematic Non-response Bias with ...  \n",
       "5  [Addressing Systematic Non-response Bias with ...  \n",
       "6  [Addressing Systematic Non-response Bias with ...  \n",
       "7  [Addressing Systematic Non-response Bias with ...  \n",
       "8  [Addressing Systematic Non-response Bias with ...  \n",
       "9  [Addressing Systematic Non-response Bias with ...  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6834447e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Per-file recall summary:\n"
     ]
    },
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "file",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "matches_count",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "total_gold",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "recall",
         "rawType": "float64",
         "type": "float"
        }
       ],
       "ref": "45754689-88b3-42b5-926e-54fc1adc89b0",
       "rows": [
        [
         "0",
         "savedrecs1.xls",
         "2",
         "13",
         "0.15384615384615385"
        ],
        [
         "1",
         "savedrecs10.xls",
         "2",
         "13",
         "0.15384615384615385"
        ],
        [
         "2",
         "savedrecs2.xls",
         "2",
         "13",
         "0.15384615384615385"
        ],
        [
         "3",
         "savedrecs3.xls",
         "2",
         "13",
         "0.15384615384615385"
        ],
        [
         "4",
         "savedrecs4.xls",
         "2",
         "13",
         "0.15384615384615385"
        ],
        [
         "5",
         "savedrecs5.xls",
         "2",
         "13",
         "0.15384615384615385"
        ],
        [
         "6",
         "savedrecs6.xls",
         "2",
         "13",
         "0.15384615384615385"
        ],
        [
         "7",
         "savedrecs7.xls",
         "2",
         "13",
         "0.15384615384615385"
        ],
        [
         "8",
         "savedrecs8.xls",
         "2",
         "13",
         "0.15384615384615385"
        ],
        [
         "9",
         "savedrecs9.xls",
         "2",
         "13",
         "0.15384615384615385"
        ]
       ],
       "shape": {
        "columns": 4,
        "rows": 10
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file</th>\n",
       "      <th>matches_count</th>\n",
       "      <th>total_gold</th>\n",
       "      <th>recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>savedrecs1.xls</td>\n",
       "      <td>2</td>\n",
       "      <td>13</td>\n",
       "      <td>0.153846</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>savedrecs10.xls</td>\n",
       "      <td>2</td>\n",
       "      <td>13</td>\n",
       "      <td>0.153846</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>savedrecs2.xls</td>\n",
       "      <td>2</td>\n",
       "      <td>13</td>\n",
       "      <td>0.153846</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>savedrecs3.xls</td>\n",
       "      <td>2</td>\n",
       "      <td>13</td>\n",
       "      <td>0.153846</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>savedrecs4.xls</td>\n",
       "      <td>2</td>\n",
       "      <td>13</td>\n",
       "      <td>0.153846</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>savedrecs5.xls</td>\n",
       "      <td>2</td>\n",
       "      <td>13</td>\n",
       "      <td>0.153846</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>savedrecs6.xls</td>\n",
       "      <td>2</td>\n",
       "      <td>13</td>\n",
       "      <td>0.153846</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>savedrecs7.xls</td>\n",
       "      <td>2</td>\n",
       "      <td>13</td>\n",
       "      <td>0.153846</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>savedrecs8.xls</td>\n",
       "      <td>2</td>\n",
       "      <td>13</td>\n",
       "      <td>0.153846</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>savedrecs9.xls</td>\n",
       "      <td>2</td>\n",
       "      <td>13</td>\n",
       "      <td>0.153846</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              file  matches_count  total_gold    recall\n",
       "0   savedrecs1.xls              2          13  0.153846\n",
       "1  savedrecs10.xls              2          13  0.153846\n",
       "2   savedrecs2.xls              2          13  0.153846\n",
       "3   savedrecs3.xls              2          13  0.153846\n",
       "4   savedrecs4.xls              2          13  0.153846\n",
       "5   savedrecs5.xls              2          13  0.153846\n",
       "6   savedrecs6.xls              2          13  0.153846\n",
       "7   savedrecs7.xls              2          13  0.153846\n",
       "8   savedrecs8.xls              2          13  0.153846\n",
       "9   savedrecs9.xls              2          13  0.153846"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Which of the 13 are missing per file:\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(\"Per-file recall summary:\")\n",
    "display(summary_df[[\"file\", \"matches_count\", \"total_gold\", \"recall\"]])\n",
    "\n",
    "print(\"\\nWhich of the 13 are missing per file:\")\n",
    "missing_df = pd.DataFrame(missing_rows)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
